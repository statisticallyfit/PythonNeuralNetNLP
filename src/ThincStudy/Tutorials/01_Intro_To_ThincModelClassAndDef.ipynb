{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "Source: https://github.com/explosion/thinc/blob/master/examples/01_intro_model_definition_methods.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "# Intro to Thinc's `Model` class, model definition, and methods\n",
    "\n",
    "Thinc uses a functional-programming approach to model definition, effective for:\n",
    "* complicated network architectures and,\n",
    "* use cases where different data types need to be passed through the network to reach specific subcomponents.\n",
    "\n",
    "This notebook shows how to compose Thinc models and use the `Model` class and its methods.\n",
    "\n",
    "*Principles:*\n",
    "* Thinc provides layers (functions to create `Model` instances)\n",
    "* Thinc tries to avoid inheritance, preferring function composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from thinc.api import Linear, zero_init\n",
    "\n",
    "nI: int = 16\n",
    "nO: int = 10\n",
    "NUM_HIDDEN: int = 128\n",
    "\n",
    "\n",
    "nIn = numpy.zeros((NUM_HIDDEN, nI), dtype=\"f\")\n",
    "nOut = numpy.zeros((NUM_HIDDEN, nO), dtype=\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nIn.shape\n",
    "nOut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with input dimension nI=16 and output dimension nO=10.\n"
     ]
    }
   ],
   "source": [
    "model = Linear(nI = nI, nO = nO, init_W = zero_init)\n",
    "model\n",
    "\n",
    "model.get_dim(\"nI\")\n",
    "model.get_dim(\"nO\")\n",
    "\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "*Key Point*: Models support dimension inference from data. You can defer some or all of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with no input/ouput dimensions.\n"
     ]
    }
   ],
   "source": [
    "modelDeferDims = Linear(init_W = zero_init)\n",
    "modelDeferDims\n",
    "print(f\"Initialized model with no input/ouput dimensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with input dimension nI=16 and output dimension nO=10.\n"
     ]
    }
   ],
   "source": [
    "X = numpy.zeros((NUM_HIDDEN, nI), dtype=\"f\")\n",
    "Y = numpy.zeros((NUM_HIDDEN, nO), dtype=\"f\")\n",
    "\n",
    "# Here is where the dimension inference happens: during initialization of the model\n",
    "modelDeferDims.initialize(X = X, Y = Y)\n",
    "modelDeferDims\n",
    "\n",
    "# We can see that dimension inference has occurred:\n",
    "modelDeferDims.get_dim(\"nI\")\n",
    "modelDeferDims.get_dim(\"nO\")\n",
    "\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "## [Combinators](https://thinc.ai/docs/api-layers#combinators)\n",
    "\n",
    "There are functions like `chain` and `concatenate` which are called [`combinators`](https://thinc.ai/docs/api-layers#combinators). *Combinators* take one or more models as arguments, and return another model instance, without introducing any new weight parameters.\n",
    "\n",
    "Combinators are layers that express higher-order functions: they take one or more layers as arguments and express some relationship or perform some additional logic around the child layers.\n",
    "\n",
    "### [`chain()`](https://thinc.ai/docs/api-layers#chain)\n",
    "**Purpose of `chain`**: The `chain` function wires two models together with a feed-forward relationship. Composes two models `f` and `g` such that they become layers of a single feed-forward model that computes `g(f(x))`.\n",
    "\n",
    "Also supports chaining more than 2 layers.\n",
    "* NOTE: dimension inference is useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7efefad64730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import chain, glorot_uniform_init\n",
    "\n",
    "NUM_HIDDEN: int = 128\n",
    "X = numpy.zeros((NUM_HIDDEN, nI), dtype=\"f\")\n",
    "Y = numpy.zeros((NUM_HIDDEN, nO), dtype=\"f\")\n",
    "\n",
    "# Linear layer multiplies inputs by a weights matrix and adds a bias vector\n",
    "# layer 1: Linear layer wih only the output dimension provided\n",
    "# layer 2: Linear layer with all dimensions deferred\n",
    "modelChained = chain(layer1 = Linear(nO = NUM_HIDDEN, init_W = glorot_uniform_init),\n",
    "                     layer2 = Linear(init_W = zero_init), )\n",
    "modelChained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thinc.model.Model at 0x7effb03f98c8>, <thinc.model.Model at 0x7effb03f96a8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing model\n",
    "modelChained.initialize(X = X, Y = Y)\n",
    "modelChained\n",
    "\n",
    "modelChained.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with input dimension nI=16 and output dimension nO=10.\n",
      "The size of the hidden layer is 128.\n"
     ]
    }
   ],
   "source": [
    "nI: int = modelChained.get_dim(\"nI\")\n",
    "nI\n",
    "nO: int = modelChained.get_dim(\"nO\")\n",
    "nO\n",
    "\n",
    "nO_hidden = modelChained.layers[0].get_dim(\"nO\")\n",
    "nO_hidden\n",
    "\n",
    "\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")\n",
    "print(f\"The size of the hidden layer is {nO_hidden}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "## [`concatenate()`](https://thinc.ai/docs/api-layers#concatenate)\n",
    "\n",
    "**Purpose of `concatenate()`**: the `concatenate` combinator function produces a layer that *runs the child layer separately* and then *concatenates their outputs together*. Useful for combining features from different sources. (Thinc uses this to build spacy's embedding layers).  Composes two or more models `f`, `g`, etc, such that their outputs are concatenated, i.e. `concatenate(f, g)(x)` computes `hstack(f(x), g(x))`.\n",
    "* NOTE: functional approach here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with input dimension nI=16 and output dimension nO=256.\n"
     ]
    }
   ],
   "source": [
    "from thinc.api import concatenate\n",
    "\n",
    "modelConcat = concatenate(Linear(nO = NUM_HIDDEN), Linear(nO = NUM_HIDDEN))\n",
    "modelConcat\n",
    "modelConcat.layers\n",
    "\n",
    "# Initializing model, and this is where dimension inference occurs (for nI)\n",
    "modelConcat.initialize(X = X)\n",
    "\n",
    "# Can see that dimension nI was inferred\n",
    "nI: int = modelConcat.get_dim(\"nI\")\n",
    "nI\n",
    "\n",
    "# Can see that dimension nO is now twice the NUM_HIDDEN which we passed in: 256 = 128 + 128 since concatenation occurred.\n",
    "nO: int = modelConcat.get_dim(\"nO\")\n",
    "nO\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "## [`clone()`](https://thinc.ai/docs/api-layers#clone)\n",
    "Some combinators work on a layer and a numeric argument. The `clone` combinator creates a number of copies of a layer and chains them together into a deep feed-forward network.\n",
    "\n",
    "**Purpose of `clone`**: Construct `n` copies of a layer with distinct weights. For example, `clone(f, 3)(x)` computes `f(f'(f''(x)))`\n",
    "\n",
    "* NOTE: shape inference is useful here: we want the first and last layers to have different shapes so we can avoid giving any dimensions into the layer we clone. Then we just have to specify the first layer's output size and let the res of the dimensions be inferred from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thinc.model.Model at 0x7efefad64ea0>,\n",
       " <thinc.model.Model at 0x7efefad64f28>,\n",
       " <thinc.model.Model at 0x7efefad647b8>,\n",
       " <thinc.model.Model at 0x7efefad64598>,\n",
       " <thinc.model.Model at 0x7efefad64510>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import clone\n",
    "\n",
    "modelClone = clone(orig = Linear(), n = 5)\n",
    "modelClone\n",
    "modelClone.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with input dimension nI=16 and output dimension nO=10.\n"
     ]
    }
   ],
   "source": [
    "modelClone.layers[0].set_dim(\"nO\", NUM_HIDDEN)\n",
    "modelClone.layers[0].get_dim(\"nO\")\n",
    "\n",
    "# Initializing the model here\n",
    "modelClone.initialize(X = X, Y = Y)\n",
    "\n",
    "nI: int = model.get_dim(\"nI\")\n",
    "nI\n",
    "nO: int = model.get_dim(\"nO\")\n",
    "nO\n",
    "\n",
    "# num hidden is still 128\n",
    "modelClone.layers[0].get_dim(\"nO\")\n",
    "\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Can apply `clone` to model instances that have child layers, making it easier to define complex architectures. For instance: usually we want to attach an activation and dropout to a linear layer and then repeat that substructure a number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7efefad0a9d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import Relu, Dropout\n",
    "\n",
    "def hiddenLayer(dropout: float = 0.2):\n",
    "    return chain(Linear(), Relu(),  Dropout(dropout))\n",
    "\n",
    "modelCloneHidden = clone(hiddenLayer(), 5)\n",
    "modelCloneHidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "## [`with_array()`](https://thinc.ai/docs/api-layers#with_array)\n",
    "Some combinators are unary functions (they take only one model). These are usually **input and output transformations*. For instance:\n",
    "**Purpose of `with_array`:** produce a model that flattens lists of arrays into a single array and then calls the child layer to get the flattened output. Then, it reverses the transformation on the output. (In other words: Transforms sequence of data into a continguous two-dim array on the way into and out of a model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (10, 4).\n"
     ]
    }
   ],
   "source": [
    "from thinc.api import with_array, Model\n",
    "\n",
    "modelWithArray: Model = with_array(layer = Linear(nO = 4, nI = 2))\n",
    "modelWithArray\n",
    "\n",
    "Xs = [modelWithArray.ops.alloc2f(d0 = 10, d1 = 2, dtype = \"f\")]\n",
    "Xs\n",
    "Xs[0].shape\n",
    "\n",
    "modelWithArray.initialize(X = Xs)\n",
    "modelWithArray\n",
    "\n",
    "# predict(X: InT) -> OutT: call the model's `forward` function with `is_train = False` and return the output instead of the tuple `(output, callback)`.\n",
    "Ys = modelWithArray.predict(X = Xs)\n",
    "Ys\n",
    "\n",
    "print(f\"Prediction shape: {Ys[0].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "## Example of Concise Model Definition with Combinators\n",
    "Combinators allow you to wire complex models very concisely.\n",
    "\n",
    "Can take advantage of Thinc's **operator overloading** which lets you use infox notation. Must be careful to use **in a contextmananger** to avoid unexpected results.\n",
    "\n",
    "**Example network**:\n",
    "\n",
    "1. Below, the network expects a list of arrays as input, where each array has two columns with different numeric identifier features.\n",
    "2. The two arrays are embedded using separate embedding tables\n",
    "3. The two resulting vectors are added\n",
    "4. Then passed through the `Maxout` layer with layer normalization and dropout.\n",
    "5. The vectors pass through two pooling functions (`reduce_max` and `reduce_mean`) and the results are concatenated.\n",
    "6. The concatenated results are passed through two `Relu` layers with dropout and residual connections.\n",
    "7. The vectors are passed through an output layer, which has a `Softmax` activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.to_dict of <thinc.model.Model object at 0x7efefad20b70>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import add, chain, concatenate, clone\n",
    "from thinc.api import with_array, reduce_max, reduce_mean, residual\n",
    "from thinc.api import Model, Embed, Maxout, Softmax\n",
    "\n",
    "nH: int = 5 # num hidden layers\n",
    "\n",
    "with Model.define_operators({\">>\": chain, \"|\":concatenate, \"+\":add, \"**\":clone}):\n",
    "    modelOp: Model = (\n",
    "        with_array(layer =\n",
    "                   # Embed: map integers to vectors using fixed-size lookup table.\n",
    "                   (Embed(nO = 128, column = 0) + Embed(nO = 64, column=1))\n",
    "        >> Maxout(nO = nH, normalize = True, dropout = 0.2)\n",
    "    )\n",
    "    >> (reduce_max() | reduce_mean())\n",
    "    >> residual(layer = Relu() >> Dropout(rate = 0.2)) ** 2\n",
    "    >> Softmax()\n",
    ")\n",
    "\n",
    "modelOp\n",
    "modelOp.layers\n",
    "modelOp.attrs\n",
    "modelOp.param_names\n",
    "modelOp.grad_names\n",
    "modelOp.dim_names\n",
    "modelOp.ref_names\n",
    "modelOp.define_operators\n",
    "modelOp.walk\n",
    "modelOp.to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "## Using A Model\n",
    "Defining the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from thinc.api import Linear, Adam\n",
    "import numpy\n",
    "\n",
    "nI, nO, nH = 10, 10, 128\n",
    "nI, nO, nH\n",
    "\n",
    "X = numpy.zeros((nH, nI), dtype=\"f\")\n",
    "dY = numpy.zeros((nH, nO), dtype=\"f\")\n",
    "\n",
    "modelBackpropExample: Model = Linear(nO = nO, nI = nI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Initialize the model with a sample of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7efefad20bf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBackpropExample.initialize(X=X, Y=dY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Run some data through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = modelBackpropExample.predict(X = X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Get a callback to backpropagate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " <function thinc.layers.linear.forward.<locals>.backprop(dY:thinc.types.Floats2d) -> thinc.types.Floats2d>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# begin_update(X: InT) -> Tuple[OutT, Callable[[InT], OutT]]\n",
    "# Purpose: Run the model over a batch of data, returning the output and a callback to complete the backward pass.\n",
    "# Return: tuple (Y, finish_update), where Y = batch of output data, and finish_update = callback that takes the gradient with respect to the output and an optimizer function to return the gradient with respect to the input.\n",
    "Y, backprop = modelBackpropExample.begin_update(X = X)\n",
    "Y, backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "\n",
    "Run the callback to calculate the gradient with respect to the inputs.\n",
    "\n",
    "`backprop()`:\n",
    "* is a callback to calculate gradient with respect to inputs.\n",
    "* only increments the parameter gradients, doesn't actually change the weights. To increment the weights, call `model.finish_update()` and pass an optimizer\n",
    "* If the model has trainable parameters, gradients for the parameters are accumulated internally, as a side-effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX = backprop(dY)\n",
    "dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Incrementing the weights now by calling `model.finish_update()` and by passing an optimizer.\n",
    "\n",
    "`finish_update(optimizer: Optimizer) -> None`\n",
    "* update parameters with current gradients\n",
    "* the optimizer is called with each parameter and gradient of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7efefad20bf8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adamOptimizer = Adam()\n",
    "\n",
    "modelBackpropExample.finish_update(optimizer = adamOptimizer)\n",
    "modelBackpropExample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Get and set dimensions, parameters, attributes, by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bar'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBackpropExample.get_dim(\"nO\")\n",
    "# weights matrix\n",
    "W = modelBackpropExample.get_param(\"W\")\n",
    "W\n",
    "\n",
    "modelBackpropExample.attrs[\"something\"] = \"here\"\n",
    "\n",
    "modelBackpropExample.attrs.get(\"foo\", \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Get parameter gradients and increment them explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1],\n",
       "       [1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW = modelBackpropExample.get_grad(\"W\")\n",
    "dW\n",
    "\n",
    "modelBackpropExample.inc_grad(name = \"W\", value = 1 + 0.1)\n",
    "modelBackpropExample.get_grad(\"W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Can serialize model to bytes and to dist and load them back with `from_bytes` and `from_disk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x84\\xa5nodes\\x91\\x84\\xa5index\\x00\\xa4name\\xa6linear\\xa4dims\\x82\\xa2nO\\n\\xa2nI\\n\\xa4refs\\x80\\xa5attrs\\x91\\x81\\xa9something\\xc4\\x05\\xa4here\\xa6params\\x91\\x82\\xa1W\\x85\\xc4\\x02nd\\xc3\\xc4\\x04type\\xa3<f4\\xc4\\x04kind\\xc4\\x00\\xc4\\x05shape\\x92\\n\\n\\xc4\\x04data\\xc5\\x01\\x90\\x19\\xc0~\\xbe2gk\\xbe\\x9c\\xbd\\xa2\\xbe\\xbf\\xabs\\xbd\\x986\\x86<\\xfcx\\x1a=\\xa8\\xc2\\x8c\\xbe3Y\\xcd>qt\\xde>\\x06\\x8b\\xd7=m\\xf9;\\xbe\\x04i\\x83\\xbeZ\\x93\\xba>\\xabU\\xf2>t\\xd9Q\\xbe&1r\\xbcWA\\x98\\xbe)\\xd8\\x90>\\xf0\\x95\\x9c=A\\xaf\\xad\\xbc\\xf9uo>\\x8a\\x14\\xaa>\\x87\\x0f\\x9e\\xbe\\xf5\\x10\\x81\\xbeFo>\\xbe\\x96tm\\xbd\\xc7T\\xf1>[\\xc4\\x96>\\xba#\\xd7\\xbe\\xc1.W\\xbe\\xa8\\xefM>+2\\xa7\\xbe;n\\x97\\xbd\\x14\\x8b\\xb0>\\xb9>\\x97>x\\xa5\\xcc>\\x13\\xc5j\\xbe;\\x97\\xa7=\\xde\\xbc\\xe0\\xbe\\x16:\\xb2>K\\xf01\\xbd2\\xaa\\xe1\\xbc8Y\\x19=U\\rQ>\\x89\\xb6\\xe8\\xbe\\xe2h\\xf4\\xbd>\\x9a\\x96\\xbe\\'7\\xd9\\xbe\\x0e\\xb6\\xbc\\xbc\\x12\\x1b\\x04?\\x07\\xdd\\xae>\\xb8\\x885\\xbcH\\x9d\\xb1\\xbe\\xfa\\xcb\\x03\\xbeO\\xcb\\xd6>\\x88\\x1b\\xef\\xbee\\x18\\x13\\xbe<\\x07\\xe4\\xbe\\x0b\\xd1\\xa9\\xbe\\x00\\x07\\x96\\xbe0\\x8d\\'>\\x17\\xf8\\xe3>`@\\xee\\xbeH\\x94\\x98>p\\xbd\"<3;\\xdb>c\\xd7\\xf3\\xbeU\\x11Y\\xbe\\x90\\x8c2\\xbe\\xb4\\x0fV>\\xecl\\xde\\xbe\\xbb\\x88\\x8d\\xbe\\x90K4>\\xf5\\xe2}>\\xdee\\xc7>\\x91>\\x80;\\x95.;>\\xc8\\xe9\\x00>\\xa9\\xccb\\xbd\\x9aC3\\xbeM\\xf7\\x83\\xbe\\xa9g\\xef\\xbeg\\xbd\\xe7\\xbe\\xb8\\x98\\xa3>\\xdal\\xd4>H\\x91\\xc2>=\\xd4\\xd2>(\\xc8\\xa3>\\x98\\xc5\\xde>UER>f6\\x0f\\xbe\\xa5\\xc4V=\\xcbw\\x1c\\xbe9r\\x02\\xbfE\\xb1\\x9e>=cX>82\\xcb>La\\xb7\\xbe\\x7f\\xf8\\xf2\\xbeT\\xcc\\xb4>\\xa1b\\x85\\xc4\\x02nd\\xc3\\xc4\\x04type\\xa3<f4\\xc4\\x04kind\\xc4\\x00\\xc4\\x05shape\\x91\\n\\xc4\\x04data\\xc4(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa5shims\\x91\\x90'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBytes = modelBackpropExample.to_bytes()\n",
    "modelBytes"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all"
  },
  "kernelspec": {
   "display_name": "pythinc_env",
   "language": "python",
   "name": "pythinc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
