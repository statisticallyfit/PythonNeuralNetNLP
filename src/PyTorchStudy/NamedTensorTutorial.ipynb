{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### Conda Environment: pymatrix_env \n",
    "\n",
    "#### Tutorial Sources:\n",
    "* [(experimental) Named Tensors Introduction)](https://pytorch.org/tutorials/intermediate/named_tensor_tutorial.html#annotations:VOh11nKBEeqlHi8b3rPBxg)\n",
    "* [Named Tensors (API doc)](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to)\n",
    "\n",
    "#### API Documentation Sources:\n",
    "* [Named Tensor Operator Coverage](https://pytorch.org/docs/stable/name_inference.html)\n",
    "* [PyTorch Tensors (API Doc)](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "\n",
    "# Tutorial: Named Tensors and Named Inference in PyTorch\n",
    "### Definition: Named Tensor\n",
    "Named Tensors aim to make tensors easier to use by allowing users to associate explicit names with tensor dimensions. In most cases, operations that take dimension parameters will accept dimension names, avoiding the need to track dimensions by position. In addition, named tensors use names to automatically check that APIs are being used correctly at runtime, providing extra safety. Names can also be used to rearrange dimensions, for example, to support **“broadcasting by name” rather than “broadcasting by position”.**\n",
    "\n",
    "### Name Inference Rules\n",
    "1. [Keeps Input Names](https://pytorch.org/docs/stable/name_inference.html#keeps-input-names)\n",
    "2. [Removes Dimensions](https://pytorch.org/docs/stable/name_inference.html#removes-dimensions)\n",
    "3. [Unifies Names from Inputs](https://pytorch.org/docs/stable/name_inference.html#unifies-names-from-inputs)\n",
    "4. [Permutes Dimensions](https://pytorch.org/docs/stable/name_inference.html#permutes-dimensions)\n",
    "5. [Contracts away Dims](https://pytorch.org/docs/stable/name_inference.html#contracts-away-dims)\n",
    "6. [Factory Functions Take Names](https://pytorch.org/docs/stable/name_inference.html#factory-functions)\n",
    "7. [Out Function and In-Place Variant Rules](https://pytorch.org/docs/stable/name_inference.html#out-function-and-in-place-variants)\n",
    "\n",
    "\n",
    "#### Workaround for Operations Not Supported by Named Tensors:\n",
    "As a workaround, drop names via `tensor = tensor.rename(None)` before using any function that does not yet support named tensors.\n",
    "\n",
    "\n",
    "### Currently Supported:\n",
    "* [named tensors operator coverage](https://pytorch.org/docs/stable/name_inference.html#name-inference-reference-doc)\n",
    "\n",
    "\n",
    "## Goal of Tutorial:\n",
    "This tutorial is intended as a guide to the functionality that will be included with the 1.3 launch. By the end of it, you will be able to:\n",
    "\n",
    "1. Create Tensors with named dimensions, as well as remove or rename those dimensions.\n",
    "2. Understand the basics of how operations propagate dimension names.\n",
    "3. See how naming dimensions enables clearer code in two key areas:\n",
    "      * Broadcasting operations\n",
    "      * Flattening and unflattening dimensions\n",
    "4. Put these ideas into practice by writing a multi-head attention module using named tensors.\n",
    "\n",
    "\n",
    "# Basics\n",
    "\n",
    "## Named Dimensions\n",
    "PyTorch allows `Tensor`s to have named dimensions; factory functions take a new *names* argument that associates a name with each dimension. This works with most factory functions such as: `tensor, empty, ones, zeros, randn, rand`. Here we construct a `Tensor` with names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:19.172160Z",
     "iopub.status.busy": "2020-11-18T13:59:19.171104Z",
     "iopub.status.idle": "2020-11-18T13:59:20.355139Z",
     "shell.execute_reply": "2020-11-18T13:59:20.356745Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pymatrix_env/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/c10/core/TensorImpl.h:840.)\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1948,  0.6330, -0.3372],\n",
       "          [ 0.4894, -1.9075, -1.8045]],\n",
       "\n",
       "         [[-2.2237,  0.6878,  0.7949],\n",
       "          [ 1.8014,  0.1535, -0.9875]]]], names=('N', 'C', 'H', 'W'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.tensor as Tensor\n",
    "\n",
    "\n",
    "from typing import *\n",
    "\n",
    "tensor: Tensor = torch.randn(1, 2, 2, 3, names = ('N', 'C', 'H', 'W'))\n",
    "assert tensor.names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Unlike in the [original named tensors blogpost](http://nlp.seas.harvard.edu/NamedTensor), named dimensions are ordered: `tensor.names[i]` is the name of the `i`th dimension of `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.364641Z",
     "iopub.status.busy": "2020-11-18T13:59:20.360806Z",
     "iopub.status.idle": "2020-11-18T13:59:20.368159Z",
     "shell.execute_reply": "2020-11-18T13:59:20.369307Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "assert tensor.names[0] == 'N' and \\\n",
    "       tensor.names[1] == 'C' and \\\n",
    "       tensor.names[2] == 'H' and \\\n",
    "       tensor.names[3] == 'W'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Renaming a `Tensor`'s dimensions:\n",
    "**Method 1:** Set the `.names` attribute directly, as equal to a list. This changes the name in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.377085Z",
     "iopub.status.busy": "2020-11-18T13:59:20.373301Z",
     "iopub.status.idle": "2020-11-18T13:59:20.385590Z",
     "shell.execute_reply": "2020-11-18T13:59:20.386688Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1948,  0.6330, -0.3372],\n",
       "          [ 0.4894, -1.9075, -1.8045]],\n",
       "\n",
       "         [[-2.2237,  0.6878,  0.7949],\n",
       "          [ 1.8014,  0.1535, -0.9875]]]],\n",
       "       names=('batch', 'channel', 'width', 'height'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.names: List[str] = ['batch', 'channel', 'width', 'height']\n",
    "\n",
    "assert tensor.names == ('batch', 'channel', 'width', 'height')\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Method 2:** Specify new names, changing the names out-of-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.396745Z",
     "iopub.status.busy": "2020-11-18T13:59:20.390554Z",
     "iopub.status.idle": "2020-11-18T13:59:20.408407Z",
     "shell.execute_reply": "2020-11-18T13:59:20.409544Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1948,  0.6330, -0.3372],\n",
       "          [ 0.4894, -1.9075, -1.8045]],\n",
       "\n",
       "         [[-2.2237,  0.6878,  0.7949],\n",
       "          [ 1.8014,  0.1535, -0.9875]]]], names=('batch', 'C', 'W', 'H'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tensor: Tensor = tensor.rename(channel = 'C', width = 'W', height = 'H')\n",
    "\n",
    "assert tensor.names == ('batch', 'C', 'W', 'H')\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Removing Names\n",
    "The preferred way to remove names is to call `tensor.rename(None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.415202Z",
     "iopub.status.busy": "2020-11-18T13:59:20.413232Z",
     "iopub.status.idle": "2020-11-18T13:59:20.425374Z",
     "shell.execute_reply": "2020-11-18T13:59:20.426485Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1948,  0.6330, -0.3372],\n",
       "          [ 0.4894, -1.9075, -1.8045]],\n",
       "\n",
       "         [[-2.2237,  0.6878,  0.7949],\n",
       "          [ 1.8014,  0.1535, -0.9875]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor: Tensor = tensor.rename(None)\n",
    "assert tensor.names == (None, None, None, None)\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## About Unnamed Tensors\n",
    "Unnamed tensors (with no named dimensions) still work normally and do not have names in their `repr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.431934Z",
     "iopub.status.busy": "2020-11-18T13:59:20.430309Z",
     "iopub.status.idle": "2020-11-18T13:59:20.441806Z",
     "shell.execute_reply": "2020-11-18T13:59:20.443036Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9413, -1.0718, -0.3864]],\n",
       "\n",
       "        [[-2.1056,  0.5908,  0.0851]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnamedTensor: Tensor = torch.randn(2, 1, 3)\n",
    "assert unnamedTensor.names == (None, None, None)\n",
    "\n",
    "unnamedTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Named tensors (or partially named tensors) do not require that all dimensions are named. Some dimensions can be `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.448092Z",
     "iopub.status.busy": "2020-11-18T13:59:20.446554Z",
     "iopub.status.idle": "2020-11-18T13:59:20.459276Z",
     "shell.execute_reply": "2020-11-18T13:59:20.460439Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.2379,  0.4843]]],\n",
       "\n",
       "\n",
       "        [[[-0.7665, -2.1652]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2950, -0.8505]]]], names=('B', None, None, None))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partiallyNamedTensor: Tensor = torch.randn(3,1,1,2, names = ('B', None, None, None))\n",
    "assert partiallyNamedTensor.names == ('B', None, None, None)\n",
    "\n",
    "partiallyNamedTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Refining Dimensions\n",
    "Because named tensors can co-exist with unnamed tensors, we need a nice way to write named tensor-aware code that **works with both named and unnamed tensors.** The function [`tensor.refine_names(*names)`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.refine_names) works to refine dimensions and lift unnamed dims to named dims. Refining a dimension is like a \"rename\" but also with the following additional constraints:\n",
    "\n",
    "* A `None` dimension can be refined to have **any** name.\n",
    "* A named dimension can **only** be refined to have the same name (so a dimension named \"apples\" cannot be renamed to \"oranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.466040Z",
     "iopub.status.busy": "2020-11-18T13:59:20.464427Z",
     "iopub.status.idle": "2020-11-18T13:59:20.475715Z",
     "shell.execute_reply": "2020-11-18T13:59:20.477407Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "tensor: Tensor = torch.randn(3,1,1,2)\n",
    "namedTensor: Tensor = tensor.refine_names('N', 'C', 'H', 'W')\n",
    "\n",
    "# Refine the last two dimensions to `H` and `W`\n",
    "partiallyNamedTensor: Tensor = tensor.refine_names(..., 'H', 'W')\n",
    "\n",
    "assert tensor.names == (None, None, None, None)\n",
    "assert namedTensor.names == ('N', 'C', 'H', 'W')\n",
    "assert partiallyNamedTensor.names == (None, None, 'H', 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.489702Z",
     "iopub.status.busy": "2020-11-18T13:59:20.482858Z",
     "iopub.status.idle": "2020-11-18T13:59:20.494795Z",
     "shell.execute_reply": "2020-11-18T13:59:20.495922Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Function to catch the errors from the passed function argument\n",
    "def catchError(func):\n",
    "    try:\n",
    "        func() # execute the function passed as argument\n",
    "        # assert False # TODO what is the point of this? If the function works, this assertion fails, so it messes up the partiallyNamedTensor test below...\n",
    "    except RuntimeError as err:\n",
    "        err: str = str(err) # make the error into string form\n",
    "        if (len(err) > 180): # then shorten the printout\n",
    "            err = err[0:180] + \" ... (truncated)\"\n",
    "        print(f\"ERROR!: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Seeing how we cannot \"rename\" dimensions when refining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.501371Z",
     "iopub.status.busy": "2020-11-18T13:59:20.499793Z",
     "iopub.status.idle": "2020-11-18T13:59:20.515625Z",
     "shell.execute_reply": "2020-11-18T13:59:20.516776Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: refine_names: cannot coerce Tensor['N', 'C', 'H', 'W'] to Tensor['N', 'C', 'H', 'width'] because 'W' is different from 'width' at index 3\n"
     ]
    }
   ],
   "source": [
    "catchError(lambda: namedTensor.refine_names('N', 'C', 'H', 'width'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Seeing how we can refine the unnamed dimensions, which is the purpose of the [`refine_names()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.refine_names) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.521996Z",
     "iopub.status.busy": "2020-11-18T13:59:20.520441Z",
     "iopub.status.idle": "2020-11-18T13:59:20.534410Z",
     "shell.execute_reply": "2020-11-18T13:59:20.535656Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0203, -1.1861]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0363,  0.1335]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1725, -0.6879]]]], names=('batchSize', 'channelSize', 'H', 'W'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorRefinedTwoDims = partiallyNamedTensor.refine_names('batchSize', 'channelSize', ...)\n",
    "\n",
    "catchError(lambda: tensorRefinedTwoDims)\n",
    "\n",
    "assert tensorRefinedTwoDims.names == ('batchSize', 'channelSize', 'H', 'W')\n",
    "\n",
    "tensorRefinedTwoDims"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Accessors and Reduction\n",
    "One can use dimension names to refer to dimensions instead of the positional dimension. These operations also propagate names.\n",
    "* NOTE: Indexing (basic and advanced) has not yet been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.544952Z",
     "iopub.status.busy": "2020-11-18T13:59:20.539371Z",
     "iopub.status.idle": "2020-11-18T13:59:20.549221Z",
     "shell.execute_reply": "2020-11-18T13:59:20.550398Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "assert torch.equal( namedTensor.softmax(dim = 'N'), namedTensor.softmax(dim = 0))\n",
    "assert torch.equal(namedTensor.sum(dim = 'C'), namedTensor.sum(dim = 1))\n",
    "\n",
    "# Slicing (get one image)\n",
    "assert torch.equal(namedTensor.select(dim = 0, index = 0), namedTensor.select(dim = 'N', index = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Another test to show significance of using `select()` versus simple array accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.556798Z",
     "iopub.status.busy": "2020-11-18T13:59:20.554186Z",
     "iopub.status.idle": "2020-11-18T13:59:20.577865Z",
     "shell.execute_reply": "2020-11-18T13:59:20.579136Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = torch.arange(7*8*2*4*5).reshape(2,8,5,7,4)\n",
    "X.names = ['two', 'eight', 'five', 'seven', 'four']\n",
    "\n",
    "assert torch.equal( X[:,:,:,3,:], X.select('seven', 3) )\n",
    "assert torch.equal( X[:,:,:,:,2], X.select('four', 2) )\n",
    "assert torch.equal( X[0,:,:,:,:], X.select('two', 0) )\n",
    "assert torch.equal( X[1,:,:,:,:], X.select('two', 1) )\n",
    "assert torch.equal( X[:,7,:,:,:], X.select('eight', 7) )\n",
    "\n",
    "assert torch.equal( X[0,:,3,:,:], X.select('two', 0).select('five', 3) )\n",
    "assert torch.equal( X[0,6,2,1,3], X.select('two', 0).select('eight', 6).select('five', 2).select('seven', 1).select('four', 3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Size Accessing\n",
    "Can check the size of the entire tensor and even of a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.586670Z",
     "iopub.status.busy": "2020-11-18T13:59:20.583022Z",
     "iopub.status.idle": "2020-11-18T13:59:20.594891Z",
     "shell.execute_reply": "2020-11-18T13:59:20.596076Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.arange(7*8*2*4*5).reshape(2,8,5,7,4)\n",
    "X.names = ['two', 'eight', 'five', 'seven', 'four']\n",
    "\n",
    "assert X.size() == X.shape == torch.Size([2, 8, 5, 7, 4])\n",
    "\n",
    "assert X.size('two') == 2\n",
    "assert X.size('eight') == 8\n",
    "assert X.size('five') == 5\n",
    "assert X.size('seven') == 7\n",
    "assert X.size('four') == 4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Name Inference\n",
    "Names are propagated on operations in a two-step process called **name inference:**\n",
    "\n",
    "1. **Check names:** an operator may perform automatic checks at runtime that check that certain dimension names must match.\n",
    "2. **Propagate names:** name inference propagates output names to output tensors.\n",
    "\n",
    "\n",
    "## Rules of Name Inference\n",
    "\n",
    "### 1/ Propagation of Names (Keeps input names)\n",
    "Most simple operations propagate names. The ultimate goal for named tensors is for all operations to propagate names in a reasonable, intuitive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.602271Z",
     "iopub.status.busy": "2020-11-18T13:59:20.600320Z",
     "iopub.status.idle": "2020-11-18T13:59:20.743481Z",
     "shell.execute_reply": "2020-11-18T13:59:20.744870Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "assert namedTensor.abs().names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "assert namedTensor.transpose(0, 1).names == ('C', 'N', 'H', 'W')\n",
    "# Transposing dims later on:\n",
    "assert namedTensor.transpose(2, 3).names == ('N', 'C', 'W', 'H')\n",
    "\n",
    "assert namedTensor.align_to('W', 'N', 'H', 'C').names == ('W', 'N', 'H', 'C')\n",
    "\n",
    "assert namedTensor.atan().names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "assert namedTensor.bool().names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "assert namedTensor.byte().names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "# namedTensor.cholesky() # not supported\n",
    "\n",
    "assert namedTensor.conj().names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "# Chunk result on dim = 0\n",
    "# TODO: pytorch library needs to update its methods so they do their operations according to NAMED DIMENSIONS, so we don't have to use the dimension numbers. Here would say dim = 'N' or something.\n",
    "c1, c2 = namedTensor.chunk(chunks = 2, dim = 0)\n",
    "assert c1.names == ('N', 'C', 'H', 'W')\n",
    "assert c2.names == ('N', 'C', 'H', 'W')\n",
    "assert c1.shape == (2, 1, 1, 2)\n",
    "assert c2.shape == (1, 1, 1, 2)\n",
    "assert namedTensor.shape == (3, 1, 1, 2)\n",
    "assert c1.shape[0] + c2.shape[0] == namedTensor.shape[0]\n",
    "\n",
    "# Another chunk example on a dim, where numChunks > dimSize\n",
    "t = namedTensor.chunk(chunks = 2, dim = 1)\n",
    "assert t[0].shape == (3,1,1,2)\n",
    "assert t[0].names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "# Checking names of the .data information\n",
    "assert namedTensor.data.names == ('N', 'C', 'H', 'W')\n",
    "# namedTensor.det() # det() not supported with named tensors\n",
    "# namedTensor.argmin(dim = 1) # argmin not supported with named tensors\n",
    "# namedTensor.diag(diagonal = 0) # not supported\n",
    "# namedTensor.grad # does nothing\n",
    "\n",
    "# Check can refer to named dims instead of the numbers\n",
    "assert torch.equal(namedTensor.mean('N'), namedTensor.mean(dim = 0))\n",
    "# Checking mean result shape on all dimensions\n",
    "assert namedTensor.mean().names == ()\n",
    "assert namedTensor.mean('N').names == ('C', 'H', 'W')\n",
    "assert namedTensor.mean('C').names == ('N', 'H', 'W')\n",
    "assert namedTensor.mean('H').names == ('N', 'C', 'W')\n",
    "assert namedTensor.mean('W').names == ('N', 'C', 'H')\n",
    "\n",
    "# Checking min() shape on first dimensions, similar to mean()\n",
    "assert namedTensor.min('N').values.names == ('C', 'H', 'W')\n",
    "\n",
    "# namedTensor.permute(0,2,1) # permute() not supported with named tensors\n",
    "\n",
    "assert namedTensor.pow(exponent = 2).names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "# Check can refer to named dimensions instead of number dims\n",
    "assert (namedTensor.softmax('C') == namedTensor.softmax(dim = 1)).all()\n",
    "# Checking softmax shape on all dimensions\n",
    "# assert namedTensor.softmax(dim = 0).names == ('N', 'C', 'H', 'W')\n",
    "assert namedTensor.softmax('N').names == ('N', 'C', 'H', 'W')\n",
    "assert namedTensor.softmax('C').names == ('N', 'C', 'H', 'W')\n",
    "assert namedTensor.softmax('H').names == ('N', 'C', 'H', 'W')\n",
    "assert namedTensor.softmax('W').names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "\n",
    "# Checking what `squeeze()` does on different dimensions to the names:\n",
    "assert namedTensor.names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "# Confirm can refer to named dims instead of numbers for squeeze()\n",
    "assert torch.equal(namedTensor.squeeze('N'), namedTensor.squeeze(0))\n",
    "\n",
    "# On dims 0, 3 there is no size 1-dim tensor to squeeze out, so shapes stay the same (however names get renamed to None unfortunately, they shouldn't!!)\n",
    "assert namedTensor.squeeze('N').names == namedTensor.squeeze('W').names == (None, None, None, None)\n",
    "assert namedTensor.squeeze('N').shape == namedTensor.squeeze('W').shape == namedTensor.shape == (3,1,1,2)\n",
    "\n",
    "# Now squeezing on either dim = 1 or dim = 2 we get a different shape because on those dims, the tensor of size 1 so the squeeze() method squeezes it out. The names get changed likewise.\n",
    "assert namedTensor.squeeze('C').names == ('N', 'H', 'W') and namedTensor.squeeze('C').shape == (3,1,2)\n",
    "assert namedTensor.squeeze('H').names == ('N', 'C', 'W') and namedTensor.squeeze('H').shape == (3,1,2)\n",
    "\n",
    "# NOTE: squeeze() just removes the 1-dim tensors everywhere\n",
    "t1: Tensor = torch.arange(2*5*3).reshape(2,3,5)\n",
    "t1.names = ['A', 'B', 'C']\n",
    "\n",
    "# No shape or name was changed for t1 because it has no tensors of dim size == 1\n",
    "assert t1.shape == t1.squeeze().shape == (2,3,5) and t1.names == t1.squeeze().names == ('A', 'B', 'C')\n",
    "# But namedTensor has ALL its dim-1 tensors removed after calling squeeze()\n",
    "assert namedTensor.names == ('N', 'C', 'H', 'W') \\\n",
    "       and namedTensor.shape == (3,1,1,2) \\\n",
    "       and namedTensor.squeeze().shape == (3,2) \\\n",
    "       and namedTensor.squeeze().names == ('N', 'W')\n",
    "\n",
    "# namedTensor.unsqueeze(dim = 0) # unsqueeze NOT supported with named tensors!\n",
    "\n",
    "# namedTensor.trace() # not supported with named tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2/ Removes Dimensions\n",
    "\n",
    "A general rule: Wheneover integer dimensions can be passed as indices to ano operator, one can also pass a dimension name instead of that integer index. Same goes for lists of dimension indices that can be replaced for lists of dimension names.\n",
    "\n",
    "**How the Remove Dimensions Rule is Obeyed:**\n",
    "\n",
    "* **Check Names:** if `dim` or `dims` is passed in as a list of names, check that those names exist in `self`.\n",
    "* **Propagate names:** if the dimensions of the input tensor specified by `dim` or `dims` are not present in the output tensor, then the corresponding names of those dimensions do not appear in `output.names`.\n",
    "\n",
    "\n",
    "Reduction operations like [`sum()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.sum) remove dimensions by reducing over the desired dimensions. Other operations like [`select()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.select) and [`squeeze()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.squeeze) simply remove dimensions by returning the other relevant parts of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.751351Z",
     "iopub.status.busy": "2020-11-18T13:59:20.748708Z",
     "iopub.status.idle": "2020-11-18T13:59:20.763274Z",
     "shell.execute_reply": "2020-11-18T13:59:20.764659Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.arange(7*1*2*4*5).reshape(2,1,5,7,4)\n",
    "X.names = ['two', 'one', 'five', 'seven', 'four']\n",
    "\n",
    "\n",
    "assert X.squeeze('one').names == ('two', 'five', 'seven', 'four')\n",
    "assert 'one' not in X.squeeze('one').names\n",
    "\n",
    "assert X.sum(['five', 'four']).names == ('two', 'one', 'seven')\n",
    "assert 'five' not in X.sum(['five', 'four']).names and \\\n",
    "    'four' not in X.sum(['five', 'four']).names\n",
    "assert X.sum(['five', 'four']).shape != X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Reduction operations with `keepdim=True` don't actually remove dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.772892Z",
     "iopub.status.busy": "2020-11-18T13:59:20.769087Z",
     "iopub.status.idle": "2020-11-18T13:59:20.781293Z",
     "shell.execute_reply": "2020-11-18T13:59:20.783191Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.arange(7*8*2*4*5).reshape(2,8,5,7,4)\n",
    "X.names = ['two', 'eight', 'five', 'seven', 'four']\n",
    "\n",
    "assert X.sum(['eight', 'four'], keepdim=True).names == X.names\n",
    "# Showing that the shape has tensors of size 1 in place wher ethe summing occurred:\n",
    "assert X.sum(['eight', 'four'], keepdim=True).shape == torch.Size([2,1,5,7,1])\n",
    "assert X.sum(['eight', 'four'], keepdim=True).shape != X.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3/ Unifies Names from Inputs\n",
    "All binary arithmetic operations follow the rule of \"unifying names from inputs\".\n",
    "\n",
    "Operations that instead broadcast will broadcast positionally from the right to preserve compatibility with unnamed tensors.\n",
    "\n",
    "**How the Unify Names Rule is Obeyed:**\n",
    "\n",
    "* **Check names:** \n",
    "  1. for names to be unified, the names of the tensors pre-operation must match positionally from the right. For instance: in `tensor + other`, the condition `match(tensor.names[i], other.names[i])` must be true for all `i` in `(-min(tensor.dim(), other.dim()) + 1,   -1]`.\n",
    "\n",
    "$\\color{red}{\\text{TODO: how to test this, below tries are NOT working ...}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.791579Z",
     "iopub.status.busy": "2020-11-18T13:59:20.787044Z",
     "iopub.status.idle": "2020-11-18T13:59:20.808510Z",
     "shell.execute_reply": "2020-11-18T13:59:20.809675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Small example of how names are checked:\n",
    "X = torch.arange(12*7*8*2*4*5).reshape(12,2,8,5,7,4)\n",
    "X.names = ['twelve', 'two', 'eight', 'five', 'seven', 'four']\n",
    "\n",
    "Y = torch.arange(7*8*2*4*5*3*6*1).reshape(3,6,1,2,8,5,7,4)\n",
    "Y.names = ['three', 'six', 'one', 'two', 'eight', 'five', 'seven', 'four']\n",
    "\n",
    "getIndicesRange = lambda A, B: list(range(-min(A.dim(), B.dim()) + 1, -1))\n",
    "rs = getIndicesRange(X, Y)\n",
    "assert rs == [-5, -4, -3, -2]\n",
    "\n",
    "# Getting the dimensions that correspond to the indices in the range rs\n",
    "xrs = tuple([X.names[i] for i in rs] )\n",
    "yrs = tuple([Y.names[i] for i in rs] )\n",
    "\n",
    "assert xrs == yrs == ('two', 'eight', 'five', 'seven')\n",
    "\n",
    "assert xrs != X.names\n",
    "assert ('twelve', ) + xrs + ('four', ) == X.names\n",
    "\n",
    "assert yrs != Y.names\n",
    "assert ('three', 'six', 'one') + yrs + ('four', ) == Y.names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.815840Z",
     "iopub.status.busy": "2020-11-18T13:59:20.813167Z",
     "iopub.status.idle": "2020-11-18T13:59:20.827375Z",
     "shell.execute_reply": "2020-11-18T13:59:20.828609Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# The above indices show how to fix X and Y so they can be summed:\n",
    "#Xs = torch.arange(12*7*8*2*4*5).reshape(12,2,8,5,7,4)\n",
    "Xs = torch.arange(12*7*8*2*5).reshape(12,2,8,5,7)\n",
    "Xs.names = ['twelve', 'two', 'eight', 'five', 'seven']\n",
    "\n",
    "Ys = torch.arange(7*8*2*5*3*6).reshape(3,6,2,8,5,7)\n",
    "Ys.names = ['three', 'six', 'two', 'eight', 'five', 'seven']\n",
    "\n",
    "rs = getIndicesRange(Xs, Ys)\n",
    "\n",
    "# TODO why is the last dimension always missing? What does that mean???\n",
    "xrs = tuple([Xs.names[i] for i in rs] )\n",
    "yrs = tuple([Ys.names[i] for i in rs] )\n",
    "\n",
    "# TODO now I want to find a way to add X and Y because things should be alright / legal by rules 1) and 2) but for some reason it doesn't work: why??\n",
    "# Xs + Ys"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "* **Check names:**\n",
    "  2. Also, all named dimensions must be aligned from the right. Durin gmatching, if we match a named dimension `A` with an unnamed dimension `None` then `A` must not appear in the tensor with the unnamed dimension. \n",
    "\n",
    "\n",
    "* **Propagate names:** unify pairs of names from the right from both tensors to produce output names. \n",
    "\n",
    "\n",
    "**Example: Of Dimensions Matching Positionally from the Right:** in the below example, since we matched `None` in `tensor` with `C` in `other`, then `C` should not be present in `tensor`, and since we matched `other`'s `N` against `tensor`'s `None`, then `N` should not be present in `other`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.836415Z",
     "iopub.status.busy": "2020-11-18T13:59:20.833332Z",
     "iopub.status.idle": "2020-11-18T13:59:20.842537Z",
     "shell.execute_reply": "2020-11-18T13:59:20.843629Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(3, 3, names=('N', None))\n",
    "other = torch.randn(3, 3, names=(None, 'C'))\n",
    "\n",
    "rs = getIndicesRange(tensor, other)\n",
    "assert rs == []\n",
    "\n",
    "# So it is safe to add them:\n",
    "assert (tensor + other).names == ('N', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Example 1: How Dimensions do not Match Positionally from the Right:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.848982Z",
     "iopub.status.busy": "2020-11-18T13:59:20.847434Z",
     "iopub.status.idle": "2020-11-18T13:59:20.872936Z",
     "shell.execute_reply": "2020-11-18T13:59:20.874556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: Error when attempting to broadcast dims ['N', 'C'] and dims ['N']: dim 'C' and dim 'N' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3, 3, names=('N', 'C'))\n",
    "other = torch.randn(3, names=('N',))\n",
    "\n",
    "rs = getIndicesRange(tensor, other)\n",
    "assert rs == []\n",
    "\n",
    "catchError(lambda: (tensor + other).names )\n",
    "#RuntimeError: Error when attempting to broadcast dims ['N', 'C'] and dims ['N']: dim 'C' and dim 'N' are at the same position from the right but do not match."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Example 1: Of How Dimensions Aren't Aligned When Matching from the Right:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.879979Z",
     "iopub.status.busy": "2020-11-18T13:59:20.878345Z",
     "iopub.status.idle": "2020-11-18T13:59:20.898428Z",
     "shell.execute_reply": "2020-11-18T13:59:20.899666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: Misaligned dims when attempting to broadcast dims ['N'] and dims ['N', None]: dim 'N' appears in a different position from the right across both lists.\n"
     ]
    }
   ],
   "source": [
    "# Dimensions aren't aligned when matching tensor.names[-1] and other.names[-1]:\n",
    "# tensor: Tensor[N, None]\n",
    "# other:  Tensor[      N]\n",
    "tensor = torch.randn(3, 3, names=('N', None))\n",
    "other = torch.randn(3, names=('N',))\n",
    "\n",
    "catchError(lambda:  (tensor + other).names )\n",
    "# RuntimeError: Misaligned dims when attempting to broadcast dims ['N'] and dims ['N', None]: dim 'N' appears in a different position from the right across both lists."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Example 2: How Dimensions do not Match Positionally from the Right:**\n",
    "\n",
    "* **Check names:** Two names match if and only if they are equal (by string equality) or at least one is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.906183Z",
     "iopub.status.busy": "2020-11-18T13:59:20.903424Z",
     "iopub.status.idle": "2020-11-18T13:59:20.934859Z",
     "shell.execute_reply": "2020-11-18T13:59:20.936754Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: Error when attempting to broadcast dims ['X'] and dims ['Z']: dim 'X' and dim 'Z' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "x: Tensor = torch.randn(3, names = ('X', ))\n",
    "y: Tensor = torch.randn(3)\n",
    "z: Tensor = torch.randn(3, names = ('Z',))\n",
    "\n",
    "catchError(lambda: x + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Propagate names:** *unify* the two names by returning the most refined name of the two. With `x + y`, the name `X` is more refined than `None` and addition works while above it does not because `X` and `Z` have different names on the same axis while the names of `X` and `Y` do not conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.947004Z",
     "iopub.status.busy": "2020-11-18T13:59:20.945475Z",
     "iopub.status.idle": "2020-11-18T13:59:20.951255Z",
     "shell.execute_reply": "2020-11-18T13:59:20.952549Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "assert (x + y).names == ('X',)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4/ Contracting Away Dims (Name Inference for Matrix Multiplication)\n",
    "\n",
    "#### Case 1: Matrix Multiplication ([`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm))\n",
    "\n",
    "The function [`torch.mm(A, B)`](https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm) performs matrix multiplication of two given matrices `A` and `B`, and so the outer dimension of `A` must equal the inner dimension of `B`: `A.shape[-2] == B.shape[-1]`. The result is a two-dimensional tensor (matrix) which has shape `torch.Size([A.shape[0], B.shape[1])`. \n",
    "\n",
    "* **Key point:** matrix multiplication does NOT check if the contracted dimensions (in this case `D` and `in`) have the same name.\n",
    "* **NOTE THE DIFFERENCE:** the function [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm) for matrices does NOT broadcast while [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul) for higher-order tensors does broadcast. \n",
    "\n",
    "\n",
    "For [`torch.mm(tensor, other)`](https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm), here are the name inference checks that occur: \n",
    "* **Check names:** None\n",
    "* **Propagate names:** resulting tensor names are (`tensor.names[0], other.names[1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.960054Z",
     "iopub.status.busy": "2020-11-18T13:59:20.956606Z",
     "iopub.status.idle": "2020-11-18T13:59:20.968525Z",
     "shell.execute_reply": "2020-11-18T13:59:20.969801Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "markovStates: Tensor = torch.randn(128, 5, names = ('batch', 'D'))\n",
    "transitionMatrix: Tensor = torch.randn(5, 7, names = ('in', 'out'))\n",
    "\n",
    "# Apply one transition\n",
    "newState: Tensor = markovStates.mm(transitionMatrix)\n",
    "\n",
    "# Asserting multiplication still allowed on `D` and `in` even though they are not the same name.\n",
    "assert newState.names == ('batch', 'out')\n",
    "assert newState.shape == (128, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 26,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Case 2: Matrix-Vector Multiplication ([`torch.mv()`](https://pytorch.org/docs/stable/generated/torch.mv.html#torch.mv))\n",
    "This function does a matrix-vector product of matrix `input` with vector `vec`, where it must be true that `input.shape[1] == vec.shape[0]`. \n",
    "\n",
    "Any matrix multiplication does a dot product over two dimensions (ignoring any batch dimensions) and collapses the two dimensions it has done dot product over. When two tensors are matrix-multiplied, the contracted dimensions disappear and do not show up in the output tensor. \n",
    "\n",
    "\n",
    "[`torch.mv()`](https://pytorch.org/docs/stable/generated/torch.mv.html#torch.mv)  and [`torch.dot()`](https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot) work similarly: name inference does not check input names and removes the dimensions that are involved in the dot product. \n",
    "\n",
    "For `torch.mv(input, vec)`, here is how name inference rules are obeyed: \n",
    "* **Check names:** None\n",
    "* **Propagate names:** the resulting tensor has name equal to `input.names[0]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.975565Z",
     "iopub.status.busy": "2020-11-18T13:59:20.973627Z",
     "iopub.status.idle": "2020-11-18T13:59:20.982977Z",
     "shell.execute_reply": "2020-11-18T13:59:20.984169Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4, 3, names = ('N', 'D'))\n",
    "y = torch.randn(3, names = ('something',))\n",
    "\n",
    "assert x.mv(y).shape == torch.Size([4])\n",
    "assert x.mv(y).names == ('N', )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Case 3: Batch Matrix Multiplication ([`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul))\n",
    "In this case, for `torch.matmul(tensor, other)`, we have `tensor.dim() >= 2` and `other.dim() >= 2`. \n",
    "\n",
    "Here is how name inference rules are obeyed: \n",
    "* ** Check names: ** check that the batch dimensions of the inputs are aligned and broadcastable. \n",
    "* **Propagate names:** result names are obtained by unifying the batch dimensions and removing the contracted dimensions: `unify(tensor.names[:-2], other.names[:-2]) + (tensor.names[-2], other.names[-1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:20.992222Z",
     "iopub.status.busy": "2020-11-18T13:59:20.987829Z",
     "iopub.status.idle": "2020-11-18T13:59:21.001701Z",
     "shell.execute_reply": "2020-11-18T13:59:21.002864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Batch matrix multiply of matrices where the first three dims are batch dims in x and the first two are batch dims in y\n",
    "x = torch.randn(7,2,1,4,3, names = ('batch_one', 'batch_two', 'batch_three', 'A', 'B'))\n",
    "y = torch.randn(  1,5,3,2, names = ('batch_two', 'batch_three', 'C', 'D'))\n",
    "\n",
    "# Showing what names will be UNIFIED: \n",
    "assert x.names[:-2] == ('batch_one', 'batch_two', 'batch_three')\n",
    "assert y.names[:-2] == (             'batch_two', 'batch_three')\n",
    "\n",
    "# Showing what the new matrix result will take its name from: (note: the non-matrix)\n",
    "assert x.names[-2] == 'A'\n",
    "assert y.names[-1] == 'D'\n",
    "\n",
    "\n",
    "# Calculating the result of the multiplication: \n",
    "result = torch.matmul(x, y)\n",
    "\n",
    "\n",
    "assert result.names == ('batch_one', 'batch_two', 'batch_three', 'A', 'D')\n",
    "# Showing how the non-matrix dimensions (batch dimensions) were broadcasted: \n",
    "assert result.shape == torch.Size([7, 2, 5, 4, 2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## [Broadcasting](https://hyp.is/-9CpUCmCEeuGN98Fny_dTw/pytorch.org/docs/stable/notes/broadcasting.html)\n",
    "The rules of broadcasting are described as follows. \n",
    "\n",
    "Two tensors are \"broadcastable\" if the following rules hold: \n",
    "* Each tensor has at least one dimension\n",
    "* When iterating over the dimension sizes, starting at the trailing dimension, \n",
    "  1. the dimension sizes must either be equal, or ..\n",
    "  2. one of them is equal `1`, or ..\n",
    "  3. one of them does not exist.\n",
    "\n",
    "For example: \n",
    "\n",
    "Same shapes are always broadcastable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.008152Z",
     "iopub.status.busy": "2020-11-18T13:59:21.006561Z",
     "iopub.status.idle": "2020-11-18T13:59:21.014390Z",
     "shell.execute_reply": "2020-11-18T13:59:21.015708Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = torch.empty(5, 7, 3)\n",
    "y = torch.empty(5, 7, 3)\n",
    "assert (x + y).size() == torch.Size([5,7,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 29,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "`x` and `y` are NOT broadcastable because `x` does not have at least one dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.020774Z",
     "iopub.status.busy": "2020-11-18T13:59:21.019130Z",
     "iopub.status.idle": "2020-11-18T13:59:21.039877Z",
     "shell.execute_reply": "2020-11-18T13:59:21.041064Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: The size of tensor a (0) must match the size of tensor b (2) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty((0),)\n",
    "y = torch.empty(2, 2)\n",
    "\n",
    "catchError(lambda: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "`x` and `y` are broadcastable: \n",
    "* 1st trailing dimension: both have size 1\n",
    "* 2nd trailing dimension: `y` has size 1\n",
    "* 3rd trailing dimension: `x` size == `y` size == 3\n",
    "* 4th trailing dimension: `y` dimension doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.046383Z",
     "iopub.status.busy": "2020-11-18T13:59:21.044833Z",
     "iopub.status.idle": "2020-11-18T13:59:21.053091Z",
     "shell.execute_reply": "2020-11-18T13:59:21.054195Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.empty(5, 3, 4, 1)\n",
    "y = torch.empty(   3, 1, 1)\n",
    "\n",
    "assert (x + y).size() == torch.Size([5, 3, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 31,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Broadcasting Rules\n",
    "\n",
    "If two tensors `x` and `y` are \"broadcastable\" the resulting tensor size is calculated as follows: \n",
    "\n",
    "1. **Step 1:** If the number of dimensions of `x` and `y` are not equal (`x.ndim != y.ndim`), then *prepend* 1 to the dimensions of the tensor with fewer dimensions to make the tensors equal length. \n",
    "2. **Step 2:** then for each dimension size of `x` and `y`, the resulting dimension size of the broadcasted tensor is the max of the sizes of `x` and `y` along that dimension (`max`($x_{\\text{dim}_i}$), $y_{\\text{dim}_i}$)\n",
    "\n",
    "\n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.059264Z",
     "iopub.status.busy": "2020-11-18T13:59:21.057683Z",
     "iopub.status.idle": "2020-11-18T13:59:21.065939Z",
     "shell.execute_reply": "2020-11-18T13:59:21.066998Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.empty(5, 1, 4, 1)\n",
    "y = torch.empty(   3, 1, 1)\n",
    "\n",
    "assert (x + y).size() == torch.Size([5, 3, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.075226Z",
     "iopub.status.busy": "2020-11-18T13:59:21.071111Z",
     "iopub.status.idle": "2020-11-18T13:59:21.078651Z",
     "shell.execute_reply": "2020-11-18T13:59:21.079721Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.empty(      1)\n",
    "y = torch.empty(3, 1, 7)\n",
    "\n",
    "assert (x + y).size() == torch.Size([3, 1, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.084760Z",
     "iopub.status.busy": "2020-11-18T13:59:21.083049Z",
     "iopub.status.idle": "2020-11-18T13:59:21.103812Z",
     "shell.execute_reply": "2020-11-18T13:59:21.105047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 2, 4, 1)\n",
    "y = torch.empty(   3, 1, 1)\n",
    "\n",
    "catchError(lambda : (x + y).size() )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "More about broadcasting from numpy page: \n",
    "* [https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 34,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Broadcasting and Name Inference\n",
    "Named tensors do not change broadcasting behavior, they still broadcast by position. But when checking two dimensions if they can be broadcasted, PyTorch also checks that the names of those dimensions match. In other words PyTorch does broadcasting by checking for two things:\n",
    "\n",
    "1. Checks if the two dimensions can be broadcasted (structurally)\n",
    "2. Checks the names of those dimensions are equal (else it doesn't broadcast)\n",
    "\n",
    "This results in named tensors preventing unintended alignment during operations that broadcast.\n",
    "\n",
    "\n",
    "\n",
    "**Example: Apply a `perBatchScale` to the `tensor`:** Below, without `names` the `perBatchScale` tensor is aligned with the last dimension of `tensor`, which is `W` but an error is thrown since this doesn't match the name of the dimension `N` of the `perBatchScale` tensor. (Later: will talk about explicit broadcasting by names for how to align tensors by name).\n",
    "But what we wanted instead was to perform the operation by aligning `perBatchScale` with the batch dimension `N` of `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.111232Z",
     "iopub.status.busy": "2020-11-18T13:59:21.109439Z",
     "iopub.status.idle": "2020-11-18T13:59:21.131759Z",
     "shell.execute_reply": "2020-11-18T13:59:21.132951Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!: Error when attempting to broadcast dims ['N', 'C', 'H', 'W'] and dims ['N']: dim 'W' and dim 'N' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "tensor: Tensor = torch.randn(2,2,2,2, names = ('N', 'C', 'H', 'W'))\n",
    "perBatchScale: Tensor = torch.rand(2, names = ('N', ))\n",
    "catchError(lambda : tensor * perBatchScale)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 35,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Explicit Broadcasting by Names\n",
    "Main complaints about working with multiple dimensions is the need to [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) (to introduce / add) dummy dimensions so that operations can occur. For the `perBatchScale` example, to multiply the unnamed versions of the tensors we would [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) as follows.\n",
    "\n",
    "**Old Method: [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.138165Z",
     "iopub.status.busy": "2020-11-18T13:59:21.136623Z",
     "iopub.status.idle": "2020-11-18T13:59:21.150572Z",
     "shell.execute_reply": "2020-11-18T13:59:21.151646Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perBatchScale = tensor([0.3365, 0.5667])\n",
      "\n",
      "\n",
      "tensor = tensor([[[[-0.3691, -0.7739],\n",
      "          [-0.9200, -1.0519]],\n",
      "\n",
      "         [[ 3.0117,  0.0362],\n",
      "          [-0.6905, -0.4717]]],\n",
      "\n",
      "\n",
      "        [[[-2.0286,  0.5466],\n",
      "          [-0.2767,  0.1742]],\n",
      "\n",
      "         [[ 1.2754, -0.1780],\n",
      "          [ 1.1861,  0.7336]]]])\n"
     ]
    }
   ],
   "source": [
    "tensor_: Tensor = torch.randn(2,2,2,2) # N, C, H, W\n",
    "perBatchScale_: Tensor = torch.rand(2) # N\n",
    "\n",
    "assert tensor_.shape == (2,2,2,2)\n",
    "assert perBatchScale_.view(2,1,1,1).shape == (2,1,1,1)\n",
    "\n",
    "print(f\"perBatchScale = {perBatchScale_}\\n\\n\")\n",
    "print(f\"tensor = {tensor_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 36,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "* **NOTE:** Recognize as a sidenote that [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and [`expand_as()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as) are not the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.156749Z",
     "iopub.status.busy": "2020-11-18T13:59:21.155196Z",
     "iopub.status.idle": "2020-11-18T13:59:21.165534Z",
     "shell.execute_reply": "2020-11-18T13:59:21.166606Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3365]]],\n",
       "\n",
       "\n",
       "        [[[0.5667]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perBatchScale_.view(2,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.171434Z",
     "iopub.status.busy": "2020-11-18T13:59:21.169922Z",
     "iopub.status.idle": "2020-11-18T13:59:21.180181Z",
     "shell.execute_reply": "2020-11-18T13:59:21.181361Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3365, 0.5667],\n",
       "          [0.3365, 0.5667]],\n",
       "\n",
       "         [[0.3365, 0.5667],\n",
       "          [0.3365, 0.5667]]],\n",
       "\n",
       "\n",
       "        [[[0.3365, 0.5667],\n",
       "          [0.3365, 0.5667]],\n",
       "\n",
       "         [[0.3365, 0.5667],\n",
       "          [0.3365, 0.5667]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perBatchScale_.expand_as(tensor_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.186425Z",
     "iopub.status.busy": "2020-11-18T13:59:21.184798Z",
     "iopub.status.idle": "2020-11-18T13:59:21.193983Z",
     "shell.execute_reply": "2020-11-18T13:59:21.195058Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Broadcasting so that can multiply along dimension `N`\n",
    "# NOTE: view is semantically the right choice\n",
    "correctResult_: Tensor = tensor_ * perBatchScale_.view(2,1,1,1) # N, C, H, W\n",
    "# NOTE: expand_as is semantically incorrect\n",
    "incorrectResult_: Tensor = tensor_ * perBatchScale_.expand_as(tensor_)\n",
    "\n",
    "assert correctResult_.shape == incorrectResult_.shape == (2,2,2,2)\n",
    "# Even though they have the same shape, they are not the same\n",
    "assert not torch.allclose(correctResult_, incorrectResult_)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 39,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New Method: [`align_as()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as) or [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to)**\n",
    "\n",
    "We can make the multiplication operations safer (and easily agnostic to the number of dimensions) by using names. The new [`tensor.align_as(other)`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as) operations permutes the dimensions of `tensor` to match the order specified in `other.names`, adding one-sized dimensions where appropriate (basically doing the work of [`permute()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute) and [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view)).\n",
    "\n",
    "* $\\color{orange}{\\text{WARNING:}}$ [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) and [`align_as()`]((https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as)) are not necessarily doing the same work as [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). In the below example when some dimensions are missing and we need to fill them in with 1-dim tensors, then using [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) to fill them in results in the same tensor as using [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) or [`align_as()`]((https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as)). But see below in `Manipulation Dimensions` that when permuting (not adding more) dimensions, [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) does not give the same result tensor as [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.199950Z",
     "iopub.status.busy": "2020-11-18T13:59:21.198399Z",
     "iopub.status.idle": "2020-11-18T13:59:21.213370Z",
     "shell.execute_reply": "2020-11-18T13:59:21.214630Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3365]]],\n",
       "\n",
       "\n",
       "        [[[0.5667]]]], names=('N', 'C', 'H', 'W'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor: Tensor = tensor_.refine_names('N', 'C', 'H', 'W')\n",
    "perBatchScale: Tensor = perBatchScale_.refine_names('N')\n",
    "\n",
    "assert tensor.names == ('N', 'C', 'H', 'W')\n",
    "assert perBatchScale.names == ('N',)\n",
    "\n",
    "# Check that view()'s effect on the tensor is the same as align_as()\n",
    "assert torch.equal(perBatchScale.align_as(tensor).rename(None), perBatchScale_.view(2,1,1,1))\n",
    "\n",
    "# Check that align_as() gives the resulting tensor the entire dimension names of the `tensor` we want to align as.\n",
    "assert perBatchScale.align_as(tensor).names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "perBatchScale.align_as(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 40,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now do the calculation with [`align_as()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as) instead of [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.219838Z",
     "iopub.status.busy": "2020-11-18T13:59:21.218245Z",
     "iopub.status.idle": "2020-11-18T13:59:21.226985Z",
     "shell.execute_reply": "2020-11-18T13:59:21.228053Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "scaledResult: Tensor = tensor * perBatchScale.align_as(tensor)\n",
    "\n",
    "# Check scaled result gets the names:\n",
    "assert scaledResult.names == ('N', 'C', 'H', 'W')\n",
    "# Check the previous unnamed result is equal to the named one here:\n",
    "assert torch.equal(scaledResult.rename(None), correctResult_)\n",
    "# Another way to check:\n",
    "assert torch.equal(scaledResult, correctResult_.refine_names('N', 'C', 'H', 'W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 41,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### [Explicit Alignment by Names](https://pytorch.org/docs/stable/named_tensor.html#explicit-alignment-by-names)\n",
    "Use [`align_as()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as) or [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) to align tensor dimensions by name to a specified ordering. Useful for doing broadcasting by names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.233068Z",
     "iopub.status.busy": "2020-11-18T13:59:21.231501Z",
     "iopub.status.idle": "2020-11-18T13:59:21.239084Z",
     "shell.execute_reply": "2020-11-18T13:59:21.240212Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# This function is agnostic to dimension ordering of input, so long as it has a `C` dimension SOMEWHERE\n",
    "def scaleChannels(input: Tensor, scale: Tensor) -> Tensor:\n",
    "    scaleNamed: Tensor = scale.refine_names('C')\n",
    "    return input * scaleNamed.align_as(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.245355Z",
     "iopub.status.busy": "2020-11-18T13:59:21.243743Z",
     "iopub.status.idle": "2020-11-18T13:59:21.263241Z",
     "shell.execute_reply": "2020-11-18T13:59:21.264572Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Initializing the variables:\n",
    "B, H, C, W, D = 5, 4, 3, 2, 7 # C = num channels\n",
    "scale: Tensor = torch.randn(C, names = ('C',))\n",
    "scale_: Tensor = scale.rename(None)\n",
    "imgs: Tensor = torch.rand(B, H, W, C, names = ('B', 'H', 'W', 'C'))\n",
    "imgs_: Tensor = imgs.rename(None)\n",
    "moreImgs: Tensor = torch.rand(B, C, H, W, names = ('B', 'C', 'H', 'W'))\n",
    "moreImgs_: Tensor = moreImgs.rename(None)\n",
    "videos: Tensor = torch.randn(B, C, H, W, D, names = ('B', 'C', 'H', 'W', 'D'))\n",
    "videos_: Tensor = videos.rename(None)\n",
    "\n",
    "assert scale.shape == (C,) and scale.names == ('C',)\n",
    "\n",
    "# NOTE: when writing view_as result is not same as align_as when the tensors added are not each 1-dim\n",
    "assert scale.align_as(imgs).names == imgs.names\n",
    "assert scale.align_as(imgs).shape == (1,1,1,C)\n",
    "# scale_.view(imgs.shape) # assertion error\n",
    "# scale_.view_as(imgs).shape == (1,1,1,C) #RuntimeError: shape '[5, 4, 2, 3]' is invalid for input of size 3\n",
    "\n",
    "assert scale.align_as(moreImgs).shape == (1,C,1,1)\n",
    "assert scale.align_as(moreImgs).names == moreImgs.names\n",
    "\n",
    "assert scale.align_as(videos).shape == (1,C,1,1, 1)\n",
    "assert scale.align_as(videos).names == videos.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.273393Z",
     "iopub.status.busy": "2020-11-18T13:59:21.267907Z",
     "iopub.status.idle": "2020-11-18T13:59:21.279362Z",
     "shell.execute_reply": "2020-11-18T13:59:21.280486Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "resImgs: Tensor = scaleChannels(input = imgs, scale = scale)\n",
    "assert resImgs.shape == (B, H, W, C)\n",
    "assert resImgs.names == imgs.names\n",
    "\n",
    "resMore: Tensor = scaleChannels(input = moreImgs, scale = scale)\n",
    "assert resMore.shape == (B, C, H, W)\n",
    "assert resMore.names == moreImgs.names\n",
    "\n",
    "resVideos: Tensor = scaleChannels(input = videos, scale = scale)\n",
    "assert resVideos.shape == (B, C, H, W, D)\n",
    "assert resVideos.names == videos.names"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 44,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Flattening and Unflattening Dimensions by Names\n",
    "\n",
    "**Old Method: [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view), [`reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html):**\n",
    "\n",
    "One common operation is flattening and unflattening dimensions. Right now, users perform this using either [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view), [`reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), or [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html). Use cases include flattening batch dimensions to send tensors into operators that are forced to take inputs with a certain number of dimensions (for instance `Conv2D` takes 4D input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": 44,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New Method 1: [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html):**\n",
    "\n",
    "To make the operations more semantically meaningful  than [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and [`reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), we must introduce new [`tensor.unflatten(dim, namedshape)`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.unflatten) method and update [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html) to work with names: [`tensor.flatten(dims, new_dim)`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html)\n",
    "\n",
    "[`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html) can only flatten adjacent dimensions but also works on non-contiguous dimensions (in memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.285884Z",
     "iopub.status.busy": "2020-11-18T13:59:21.284324Z",
     "iopub.status.idle": "2020-11-18T13:59:21.296372Z",
     "shell.execute_reply": "2020-11-18T13:59:21.297488Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 2,  3],\n",
       "          [ 4,  5],\n",
       "          [ 6,  7]],\n",
       "\n",
       "         [[ 8,  9],\n",
       "          [10, 11],\n",
       "          [12, 13],\n",
       "          [14, 15]],\n",
       "\n",
       "         [[16, 17],\n",
       "          [18, 19],\n",
       "          [20, 21],\n",
       "          [22, 23]]]], names=('N', 'C', 'H', 'W'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor: Tensor = torch.arange(2*3*4*1).reshape(1,3,4,2) # N, C, H, W\n",
    "tensor.names = ('N', 'C', 'H', 'W')\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.305463Z",
     "iopub.status.busy": "2020-11-18T13:59:21.300885Z",
     "iopub.status.idle": "2020-11-18T13:59:21.314153Z",
     "shell.execute_reply": "2020-11-18T13:59:21.315523Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# NOTE: the dimensions to be flattened must be consecutive\n",
    "\n",
    "# Flattening C, H, W into one dimension titled 'features'\n",
    "flatTensor: Tensor = tensor.flatten(dims = ['C', 'H', 'W'], out_dim = 'features')\n",
    "assert flatTensor.shape == (1, 24)\n",
    "assert flatTensor.names == ('N', 'features')\n",
    "\n",
    "\n",
    "flatTensor2: Tensor = tensor.flatten(dims = ['C', 'H'], out_dim = 'CH')\n",
    "assert flatTensor2.shape == (1, 12, 2)\n",
    "assert flatTensor2.names == ('N', 'CH', 'W')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 46,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New Method 2: [`unflatten()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.unflatten)**\n",
    "\n",
    "Unflattens the named dimension `dim`, viewing it in the shape specified by `namedshape`.\n",
    "\n",
    " One must pass into [`unflatten()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.unflatten) a **named shape**, which is a list of `(dim, size)` tuples, to specify how to unflatten the dim.\n",
    "* NOTE: work in progress for pytorch to save the sizes during a [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html) for [`unflatten()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.unflatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.320764Z",
     "iopub.status.busy": "2020-11-18T13:59:21.319149Z",
     "iopub.status.idle": "2020-11-18T13:59:21.329961Z",
     "shell.execute_reply": "2020-11-18T13:59:21.331053Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "\n",
    "tensorRemade: Tensor = flatTensor.unflatten(dim='features', namedshape=(('C', 3), ('H', 4), ('W', 2)))\n",
    "assert torch.equal(tensor, tensorRemade)\n",
    "assert tensorRemade.names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "tensorRemade2: Tensor = flatTensor2.unflatten(dim = 'CH', namedshape=(('C', 3), ('H', 4)))\n",
    "assert torch.equal(tensor, tensorRemade2)\n",
    "assert tensorRemade2.names == ('N', 'C', 'H', 'W')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 47,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### [Manipulating Dimensions](https://pytorch.org/docs/stable/named_tensor.html#explicit-alignment-by-names)\n",
    "\n",
    "# $\\color{red}{\\text{TODO: compare the effects of } \\texttt{align_as, view, unflatten, flatten} \\text{ to verify if  they are the same, and then compare the effects of } \\texttt{align_to, permute} \\text{to see if they are the same} }$\n",
    "\n",
    "**CASE: Permuting (unnamed) vs. Aligning (named)**\n",
    "\n",
    "Use [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) to permute large amounts of dimensions without menionting all of them as in required by [`permute()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.337100Z",
     "iopub.status.busy": "2020-11-18T13:59:21.335296Z",
     "iopub.status.idle": "2020-11-18T13:59:21.349900Z",
     "shell.execute_reply": "2020-11-18T13:59:21.351096Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "A, B, C, D, E, F = 0, 1, 2, 3, 4, 5\n",
    "tensor_: Tensor = torch.randn(A, B, C, D, E, F)\n",
    "tensor: Tensor = tensor_.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
    "\n",
    "assert tensor.shape == tensor_.shape == (A, B, C, D, E, F)\n",
    "\n",
    "# Move F (5th dim) and dimension E (4th dim) to the front while keeping the rest in the same order.\n",
    "# Old way: (non-named)\n",
    "assert tensor_.permute(5,4,0,1,2,3).shape == (F, E, A, B, C, D)\n",
    "# Better way: (named)\n",
    "assert tensor.align_to('F', 'E', ...).names == ('F', 'E', 'A', 'B', 'C', 'D')\n",
    "# Sanity check: permute == align results:\n",
    "assert (tensor_.permute(5,4,0,1,2,3) == tensor.align_to('F', 'E', ...)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 48,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**CASE: Flattening (named) vs. View (unnamed)**\n",
    "\n",
    "Use [`flatten()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.flatten) and [`unflatten()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.unflatten) to flatten and unflatten dimensions, respectively. These have more semantic meaning than [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and [`reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.356669Z",
     "iopub.status.busy": "2020-11-18T13:59:21.354705Z",
     "iopub.status.idle": "2020-11-18T13:59:21.506467Z",
     "shell.execute_reply": "2020-11-18T13:59:21.507797Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "N, C, H, W = 32, 3, 128, 128\n",
    "imgs_: Tensor = torch.randn(N, C, H, W)\n",
    "imgs: Tensor = imgs_.refine_names('N', 'C', 'H', 'W')\n",
    "\n",
    "# Flattening C, H, W into one dimension of size C*H*W\n",
    "flatImgs_: Tensor = imgs_.view(N, -1)\n",
    "assert flatImgs_.shape == (N, C*H*W)\n",
    "\n",
    "# Flattening via named dimensions\n",
    "flatImgs: Tensor = imgs.flatten(dims = ['C', 'H', 'W'], out_dim = 'features')\n",
    "assert flatImgs.names == ('N', 'features')\n",
    "assert flatImgs.shape == (N, C*H*W)\n",
    "\n",
    "# Unflattening  the non-named tensor\n",
    "unflattenedImgs_: Tensor = flatImgs_.view(N, C, H, W)\n",
    "assert unflattenedImgs_.shape == imgs.shape\n",
    "\n",
    "# Unflattening the named tensor\n",
    "unflattenedImgs: Tensor = flatImgs.unflatten(dim = 'features', namedshape = [('C', 3), ('H', 128), ('W', 128)])\n",
    "assert unflattenedImgs.shape == imgs.shape\n",
    "assert unflattenedImgs.names == imgs.names"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 49,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**COMPARISON: Permute, Align, Reshape, Transpose, View:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.514936Z",
     "iopub.status.busy": "2020-11-18T13:59:21.512076Z",
     "iopub.status.idle": "2020-11-18T13:59:21.528550Z",
     "shell.execute_reply": "2020-11-18T13:59:21.529685Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26, 27],\n",
       "         [28, 29, 30, 31],\n",
       "         [32, 33, 34, 35],\n",
       "         [36, 37, 38, 39],\n",
       "         [40, 41, 42, 43],\n",
       "         [44, 45, 46, 47]]], names=('S', 'P_plus_S', 'B'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, p, b = 2, 3, 4\n",
    "x = torch.arange(s*(p+s+1)*b).reshape(s, p+s+1, b).refine_names('S', 'P_plus_S', 'B')\n",
    "x_ = x.rename(None)\n",
    "\n",
    "# Sanity basic check:\n",
    "assert (x_.view(s, p+s+1, b) == x_).all() # sanity check\n",
    "assert (x.align_as(x) == x).all() # sanity check\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.534889Z",
     "iopub.status.busy": "2020-11-18T13:59:21.533345Z",
     "iopub.status.idle": "2020-11-18T13:59:21.545297Z",
     "shell.execute_reply": "2020-11-18T13:59:21.546373Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7]],\n",
       "\n",
       "        [[ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]],\n",
       "\n",
       "        [[32, 33, 34, 35],\n",
       "         [36, 37, 38, 39]],\n",
       "\n",
       "        [[40, 41, 42, 43],\n",
       "         [44, 45, 46, 47]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### View\n",
    "tensorView_ = x_.view(p+s+1,s,b)\n",
    "tensorView_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.551220Z",
     "iopub.status.busy": "2020-11-18T13:59:21.549700Z",
     "iopub.status.idle": "2020-11-18T13:59:21.556840Z",
     "shell.execute_reply": "2020-11-18T13:59:21.558167Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "### Reshape\n",
    "tensorReshape_ = x_.reshape(p+s+1, s, b)\n",
    "tensorReshape_\n",
    "\n",
    "assert (tensorReshape_ == tensorView_).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.564718Z",
     "iopub.status.busy": "2020-11-18T13:59:21.562941Z",
     "iopub.status.idle": "2020-11-18T13:59:21.571688Z",
     "shell.execute_reply": "2020-11-18T13:59:21.572949Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "### Transpose\n",
    "tensorTranspose = x.transpose('S', 'P_plus_S')\n",
    "tensorTranspose\n",
    "assert not (tensorTranspose == tensorView_).all()\n",
    "assert not (tensorTranspose == tensorReshape_).all()\n",
    "# NOTE: confirms that view() and transpose() are not necessarily the same, as in the below link:\n",
    "# https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.579813Z",
     "iopub.status.busy": "2020-11-18T13:59:21.576281Z",
     "iopub.status.idle": "2020-11-18T13:59:21.584074Z",
     "shell.execute_reply": "2020-11-18T13:59:21.585181Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "### Align To:\n",
    "tensorAlign = x.align_to('P_plus_S', 'S', ...) # 6,2,4\n",
    "tensorAlign\n",
    "\n",
    "assert (tensorAlign == tensorTranspose).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.590245Z",
     "iopub.status.busy": "2020-11-18T13:59:21.588699Z",
     "iopub.status.idle": "2020-11-18T13:59:21.595600Z",
     "shell.execute_reply": "2020-11-18T13:59:21.596727Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "### Permute\n",
    "tensorPermute_ = x_.permute(1,0,2)\n",
    "tensorPermute_\n",
    "assert (tensorPermute_ == tensorAlign).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.601553Z",
     "iopub.status.busy": "2020-11-18T13:59:21.600024Z",
     "iopub.status.idle": "2020-11-18T13:59:21.607890Z",
     "shell.execute_reply": "2020-11-18T13:59:21.609210Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Checking relations between align_to(), permute(), and transpose()\n",
    "assert (tensorAlign == tensorTranspose).all()\n",
    "assert (tensorAlign == tensorPermute_).all()\n",
    "assert (tensorPermute_ == tensorTranspose).all()\n",
    "\n",
    "assert not (tensorAlign == tensorReshape_).all()\n",
    "# THEREFORE: align_to() == permute() == transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 56,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Autograd (Not yet supported)\n",
    "Autograd currently ignores names on all tensors and treats them like regular tensors. Gradient computation is correct but we lose the safety that names give us.\n",
    "* NOTE: this is a work in progress to handle names in autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.614593Z",
     "iopub.status.busy": "2020-11-18T13:59:21.612718Z",
     "iopub.status.idle": "2020-11-18T13:59:21.624925Z",
     "shell.execute_reply": "2020-11-18T13:59:21.626061Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pymatrix_env/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x: Tensor = torch.randn(3, names = ('D',))\n",
    "weight: Tensor = torch.randn(3, names = ('D', ), requires_grad = True)\n",
    "\n",
    "# Checking that weight gradient is empty\n",
    "assert str(weight.grad) == 'None'\n",
    "\n",
    "loss: Tensor = (x - weight).abs()\n",
    "assert str(loss.grad) == 'None'\n",
    "\n",
    "# Create a random value for grad loss as argument to loss backward()\n",
    "gradLoss: Tensor = torch.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.631175Z",
     "iopub.status.busy": "2020-11-18T13:59:21.629625Z",
     "iopub.status.idle": "2020-11-18T13:59:21.643806Z",
     "shell.execute_reply": "2020-11-18T13:59:21.645053Z"
    },
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pymatrix_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "loss.backward(gradLoss)\n",
    "\n",
    "assert str(loss.grad) == 'None' # remains the same\n",
    "\n",
    "assert str(weight.grad) != 'None' # not empty anymore after backward()\n",
    "assert weight.grad.shape == (3,) # see, tensor exists in grad\n",
    "assert weight.grad.names == (None,) # note not yet named, will be named in future\n",
    "\n",
    "# Record the correct gradient\n",
    "# NOTE: this is not yet named, will be named in the future\n",
    "correctGrad: Tensor = weight.grad.clone()\n",
    "correctGrad\n",
    "\n",
    "weight.grad.zero_() #set to zero\n",
    "assert torch.equal(weight.grad, Tensor([0,0,0],dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.651275Z",
     "iopub.status.busy": "2020-11-18T13:59:21.649716Z",
     "iopub.status.idle": "2020-11-18T13:59:21.662182Z",
     "shell.execute_reply": "2020-11-18T13:59:21.664524Z"
    },
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pymatrix_env/lib/python3.7/site-packages/torch/autograd/__init__.py:127: UserWarning: Autograd was passed a named grad tensor with dims ['C']. Autograd does not yet support named tensor semantics, so all names will be ignored. In practice all computed gradients will still be correct according to regular tensor semantics. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/autograd/python_engine.cpp:172.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    }
   ],
   "source": [
    "gradLoss: Tensor = gradLoss.refine_names('C') # set the only dimension as name C\n",
    "loss: Tensor = (x - weight).abs()\n",
    "loss.backward(gradLoss)\n",
    "\n",
    "# Stil unnamed even though the gradLoss was named\n",
    "assert weight.grad.names == (None, )\n",
    "assert torch.allclose(weight.grad, correctGrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 59,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Application Example: [Multi-Head Attention](https://synergo.atlassian.net/wiki/spaces/KnowRes/pages/1446445463/multi-head+attention+mechanism)\n",
    "Going through a complete example of implementing a common PyTorch `nn.Module`: [multi-head attention](https://synergo.atlassian.net/wiki/spaces/KnowRes/pages/1446445463/multi-head+attention+mechanism).\n",
    "\n",
    "Adapting implementation: We adapt the implementation of [multi-head attention](https://synergo.atlassian.net/wiki/spaces/KnowRes/pages/1446445463/multi-head+attention+mechanism) in [this code resource at ParlAI. ](https://github.com/facebookresearch/ParlAI/blob/f7db35cba3f3faf6097b3e6b208442cd564783d9/parlai/agents/transformer/modules.py#L907). Note there are four places labeled (I), (II), (III), and (IV) where using named tensors enables more readable code, and we will dive into each of these after the code block.\n",
    "\n",
    "* (I) **Refining the input tensor dims: ** the [`query = query.refine_names(..., 'T', 'D')`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.refine_names) serves as enforcable documentation and lifts input dimensions to being named. Checks that the last two dimensions can be refined to `['T', 'D']`, preventing potentially silent or confusing size mismatch errors later down the line.\n",
    "* (II) **Manipulating dimensions in `_prepareHead()`: **CLEARLY state sth einput and output dimensions. The input tensor must end with the `T` and `D` dims and the output tensor ends in `H`, `T`, and `D_head` dims. Secondly, it is clear to see what is going on: `_prepareHead()` takes the key, query and value and splits the embedding dimension `D` into multiple heads, finally rearranging embedding dim `D` order to be `[..., 'H', 'T', 'D_head']`. To contrast, the [original implementation](https://github.com/facebookresearch/ParlAI/blob/f7db35cba3f3faf6097b3e6b208442cd564783d9/parlai/agents/transformer/modules.py#L947-L957) uses the non-semantically clear [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and [`transpose()`](https://pytorch.org/docs/stable/torch.html#torch.transpose) operations.\n",
    "* (III) **Explicit Broadcasting by names:** To make `mask` broadcast correctly with `dotProd`, we would usually [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) dims 1 (for `H`) and `-1` (for `T_key`) in the case of self attention or [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) dim `1` in the case of encoder attention (to stand in for the dimension called `H`). But using named tensors, we simply align the `attnMask` to the shape and names of `dotProd` using [`align_as()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_as) so no need to worry about where to [`unsqueeze()`](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) dims.\n",
    "* (IV) **More Dimension manipulation using [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) and [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html):** Here as in (II), the [`align_to()`](https://pytorch.org/docs/stable/named_tensor.html#torch.Tensor.align_to) and [`flatten()`](https://hyp.is/P03oZHQMEeqVWnehE0Axew/pytorch.org/docs/stable/named_tensor.html) are more semantically meaningful than [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) and [`transpose()`](https://pytorch.org/docs/stable/torch.html#torch.transpose) despite being more verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.670586Z",
     "iopub.status.busy": "2020-11-18T13:59:21.668632Z",
     "iopub.status.idle": "2020-11-18T13:59:21.737840Z",
     "shell.execute_reply": "2020-11-18T13:59:21.739140Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "import torch.tensor as Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout, Linear, LayerNorm\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, numHeads: int, dim: int, dropout = 0):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.numHeads: int = numHeads\n",
    "        self.dim: int = dim\n",
    "\n",
    "        self.attnDropout: Dropout = Dropout(p = dropout)\n",
    "\n",
    "        # The linear layers through which we pass the word embedding matrix in order to create the query (Q),\n",
    "        # key (K) and value (V) matrices.\n",
    "        self.linearQ: Linear = Linear(in_features=dim, out_features=dim)\n",
    "        self.linearK: Linear = Linear(in_features=dim, out_features=dim)\n",
    "        self.linearV: Linear = Linear(in_features=dim, out_features=dim)\n",
    "\n",
    "        # Initializing the weight matrices of these linear layers\n",
    "        nn.init.xavier_normal_(self.linearQ.weight)\n",
    "        nn.init.xavier_normal_(self.linearK.weight)\n",
    "        nn.init.xavier_normal_(self.linearV.weight)\n",
    "\n",
    "        # The linear layer for the output\n",
    "        self.linearOut: Linear = Linear(in_features=dim, out_features=dim)\n",
    "\n",
    "        # Initializing the weight matrix in the linear output layer\n",
    "        nn.init.xavier_normal_(self.linearOut.weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, queryNamed: Tensor, key: Tensor = None, value: Tensor = None,\n",
    "                mask: Tensor = None) -> Tensor:\n",
    "\n",
    "        # (I) ------------------------------------------------------------------------------------\n",
    "\n",
    "        # Renaming the tensor's last two dimensions from None to T and D\n",
    "        queryNamed: Tensor = queryNamed.refine_names(..., 'T', 'D')\n",
    "        # queryNamed shape == (B, T, D)\n",
    "        # NOTE: this marks whether the attention to calculate is of the type 1) self attention, or 2) encoder  attention.\n",
    "        isSelfAttnType: Tensor = key is None and value is None\n",
    "        # It is self attention if both key, value are None\n",
    "        if isSelfAttnType: # then last dim has dim T\n",
    "            mask: Tensor = mask.refine_names(..., 'T')\n",
    "            # mask shape == (B, T)\n",
    "        else: # if attention is of type encoder attention, last dims are T, T_key\n",
    "            mask: Tensor = mask.refine_names(..., 'T', 'T_key')\n",
    "            # make shape == (B, T, T_key)\n",
    "\n",
    "\n",
    "        dim: int = queryNamed.size('D')\n",
    "        assert dim == self.dim, f\"Dimensions do not match: {dim} query vs {self.dim} configured\"\n",
    "        assert mask is not None, \"Mask is None, please specify a mask\"\n",
    "\n",
    "        numHeads: int = self.numHeads\n",
    "        dimPerHead: int = dim // numHeads\n",
    "        scale: float = math.sqrt(dimPerHead)\n",
    "\n",
    "\n",
    "        # (II) ------------------------------------------------------------------------------------\n",
    "        # Manipulating dimensions in prepareHead\n",
    "        def _prepareHead(tensor: Tensor) -> Tensor:\n",
    "            tensorNamed: Tensor = tensor.refine_names(..., 'T', 'D')\n",
    "            return (tensorNamed # shape == (B, T, H, D_head)\n",
    "                    .unflatten(dim = 'D', namedshape = (('H', numHeads), ('D_head', dimPerHead)))\n",
    "                    .align_to(..., 'H', 'T', 'D_head')) # shape == (B, H, T, D_head)\n",
    "\n",
    "\n",
    "        assert value is None # TODO why?\n",
    "\n",
    "        if isSelfAttnType:\n",
    "            key = value = queryNamed # this places query's value into both key and value matrices.\n",
    "            # key shape == value shape == (B, T, D)\n",
    "        elif value is None:\n",
    "            # Then key and value are the same, but query differs\n",
    "            key: Tensor = key.refine_names(..., 'T', 'D')\n",
    "            # key shape == TODO\n",
    "            value: Tensor = key\n",
    "            # value shape == TODO\n",
    "\n",
    "        #dim: int = key.size('D')\n",
    "\n",
    "\n",
    "        ### Distinguish between queryLen (T) and keyLen (T_key) dims.\n",
    "\n",
    "        # if self attention: weightsKey (D (None),D (None)) * key (B, T, D) ---> (B, T, None)\n",
    "        # if encoder attention: TODO weightsKey (D (None),D (None)) * key () ---> ()\n",
    "        K: Tensor = _prepareHead(self.linearK(key)).rename(T = 'T_key') # key shape == (B, T, D)\n",
    "        # K shape == (B, H, T_key, D_head)\n",
    "\n",
    "        # if self attention: weightsValue (D (None),D (None)) * value (B, T, D) ---> (B, T, None)\n",
    "        # if encoder attention: TODO # weightsValue (D (None),D (None)) * value (B, T, D) ---> (B, T, None)\n",
    "        V: Tensor = _prepareHead(self.linearV(value)).rename(T = 'T_key')\n",
    "        # V shape == (B, H, T_key, D_head)\n",
    "\n",
    "        # if self attention: weightsQuery (D (None),D (None)) * query (B, T, D) --> (B, T, None)\n",
    "        # if encoder attention: TODO weightsQuery (D (None),D (None)) * query (B, T, D) --> (B, T, None)\n",
    "        Q: Tensor = _prepareHead(self.linearQ(queryNamed)) # the T dim stays the same\n",
    "        # Q shape == (B, H, T, D_head)\n",
    "\n",
    "\n",
    "        # if self attention: Q matrix (B, H, T, D_head) * K.aligned (B, H, D_head, T_key) ---> (B, H, T, T_key)\n",
    "        # TODO if encoder attention: Q matrix (B, H, T, D_head) * K.aligned (B, H, D_head, T_key) ---> (B, H, T, T_key)\n",
    "        dotProd: Tensor = Q.div_(scale).matmul(K.align_to(..., 'D_head', 'T_key'))\n",
    "        # for self attention: dotProd shape == (B, H, T, T_key)\n",
    "        # for encoder attention: TODO dotProd shape == (B, H, T, T_key)\n",
    "\n",
    "        dotProd.refine_names(..., 'H', 'T', 'T_key') # just a check\n",
    "        # for self attention: dotProd shape == (B, H, T, T_key)\n",
    "        # for encoder attention: TODO\n",
    "\n",
    "        # (III) ------------------------------------------------------------------------------------\n",
    "\n",
    "        # mask: shape == (B, T) for self attention or (B, T, T_key) for encoder attention\n",
    "        attnMask: Tensor = (mask == 0).align_as(dotProd)\n",
    "        # attnMask shape == (B, H, T, T_key)\n",
    "\n",
    "        # Mask dot product according to the attention mask\n",
    "        dotProd.masked_fill_(mask = attnMask, value = -float(1e20))\n",
    "        # dotProd shape == (B, H, T, T_key)\n",
    "\n",
    "        attnWeights: Tensor = self.attnDropout(F.softmax(dotProd / scale, dim = 'T_key'))\n",
    "        # attnWeights shape == (B, H, T, T_key)\n",
    "\n",
    "        # (IV) ------------------------------------------------------------------------------------\n",
    "        # Step: multiplying the softmaxed results with the value matrix V, as in the attention formula. Then reshaping the result.\n",
    "        attentioned: Tensor = (\n",
    "            # attnWeights (B, H, T, T_key) * VALUES V (B, H, T_key, D_head) ---> (B, H, T, D_head)\n",
    "            attnWeights\n",
    "                .matmul(V).refine_names(..., 'H', 'T', 'D_head') # shape == (B, H, T, D_head)\n",
    "                .align_to(..., 'T', 'H', 'D_head') # shape == (B, T, H, D_head)\n",
    "                .flatten(dims = ['H', 'D_head'], out_dim = 'D') # shape == (B, T, D)\n",
    "        )\n",
    "        # attentioned shape == (B, T, D)\n",
    "\n",
    "        # Creating output by passing attentions through linear layer, then making sure of the result's name shape.\n",
    "        # weightsOut (D (None), D (None)) * attentioned (B, T, D) ---> (B, T, None)\n",
    "        output: Tensor = self.linearOut(attentioned).refine_names(..., 'T', 'D')\n",
    "        # output shape == (B, T, D)\n",
    "\n",
    "        return output # output shape == (B, T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.745756Z",
     "iopub.status.busy": "2020-11-18T13:59:21.742798Z",
     "iopub.status.idle": "2020-11-18T13:59:21.757343Z",
     "shell.execute_reply": "2020-11-18T13:59:21.759405Z"
    },
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (attnDropout): Dropout(p=0, inplace=False)\n",
       "  (linearQ): Linear(in_features=6, out_features=6, bias=True)\n",
       "  (linearK): Linear(in_features=6, out_features=6, bias=True)\n",
       "  (linearV): Linear(in_features=6, out_features=6, bias=True)\n",
       "  (linearOut): Linear(in_features=6, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, D, H = 7, 5, 2*3, 3\n",
    "query: Tensor = torch.randn(B, T, D, names = ('B', 'T', 'D'))\n",
    "mask: Tensor = torch.ones(B, T, names = ('B', 'T'))\n",
    "attn = MultiHeadAttention(numHeads = H, dim = D)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.765014Z",
     "iopub.status.busy": "2020-11-18T13:59:21.763138Z",
     "iopub.status.idle": "2020-11-18T13:59:21.772946Z",
     "shell.execute_reply": "2020-11-18T13:59:21.774029Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "output = attn(query, mask = mask)\n",
    "assert output.shape == (B, T, D) and output.names == ('B', 'T', 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T13:59:21.779248Z",
     "iopub.status.busy": "2020-11-18T13:59:21.777706Z",
     "iopub.status.idle": "2020-11-18T13:59:21.789377Z",
     "shell.execute_reply": "2020-11-18T13:59:21.790598Z"
    },
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Showing MultiHeadAttention module is agnostic to the existence of batch dimensions.\n",
    "query = torch.randn(T, D, names=('T', 'D'))\n",
    "mask = torch.ones(T, names=('T',))\n",
    "output = attn(query, mask=mask)\n",
    "assert output.names == ('T', 'D') and output.shape == (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all"
  },
  "kernelspec": {
   "display_name": "pymatrix_env",
   "language": "python",
   "name": "pymatrix_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
