{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: http://seba1511.net/tutorials/beginner/pytorch_with_examples.html#annotations:E9HdvPynEemYwidYvwe30g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "dtype\n",
    "# dtype = torch.cuda.FloatTensor # runs on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = batch size\n",
    "# D_int = input dimension\n",
    "# H = hidden dimension\n",
    "# D_out = output dimension\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1675, -0.4527, -0.9208,  ...,  1.0614, -0.3339,  0.5946],\n        [ 0.4021,  0.4474, -1.0594,  ...,  0.5445, -0.7479, -0.2916],\n        [ 0.6288,  0.1940,  0.2597,  ..., -0.3439, -1.2232, -2.1103],\n        ...,\n        [-0.4914,  0.7785,  0.8024,  ..., -0.5987,  1.7178,  0.5253],\n        [ 0.4617, -0.4007,  0.1861,  ..., -0.9392,  2.7120, -0.3662],\n        [ 0.6180,  0.8857,  0.1021,  ..., -1.0482, -0.2398, -0.4196]])\n"
     ]
    }
   ],
   "source": [
    "# Create random input and output data\n",
    "X = torch.randn(N, D_in).type(dtype)\n",
    "print(X)\n",
    "Y = torch.randn(N, D_out).type(dtype)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weight matrices\n",
    "W1 = torch.randn(D_in, H).type(dtype)\n",
    "W2 = torch.randn(H, D_out).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n2\ntensor([[-0.5380,  0.4833,  0.6213,  ..., -0.4132,  0.3660,  1.5991],\n        [-1.3334, -1.1652,  0.4646,  ...,  1.5600,  1.4049, -0.8707],\n        [ 0.3988, -1.2311,  1.3196,  ..., -0.5987,  0.4663, -0.6961],\n        ...,\n        [ 0.3230, -0.1637, -1.0977,  ..., -0.1050, -0.4228,  1.2100],\n        [ 0.7177,  0.9279, -0.0791,  ..., -1.3486, -0.3268,  0.7336],\n        [ 0.5702,  1.0242, -1.4474,  ..., -0.2947, -2.3491, -0.1002]])\n"
     ]
    }
   ],
   "source": [
    "print(W1.size())\n",
    "print(W1.dim())\n",
    "\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n2\n"
     ]
    }
   ],
   "source": [
    "print(W2.size())\n",
    "print(W2.dim())\n",
    "\n",
    "#print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 0.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  0 ; loss =  tensor(0.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  50 ; loss =  tensor(0.0000)\niter =  100 ; loss =  tensor(0.0000)\niter =  150 ; loss =  tensor(0.0000)\niter =  200 ; loss =  tensor(0.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  250 ; loss =  tensor(8.2971e-06)\niter =  300 ; loss =  tensor(7.0176e-06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  350 ; loss =  tensor(5.9737e-06)\niter =  400 ; loss =  tensor(5.2713e-06)\niter =  450 ; loss =  tensor(4.6440e-06)\n"
     ]
    }
   ],
   "source": [
    "learningRate = 1e-6\n",
    "NUM_ITER = 500\n",
    "\n",
    "\n",
    "# note: manually implementing the forward and \n",
    "# backward passes of the neural network. \n",
    "\n",
    "for t in range(NUM_ITER):\n",
    "    # Forward pass: compute predicted outputs y\n",
    "    # note: torch.mm(m1, m2) is matrix multiplication\n",
    "    h = X.mm(W1) # activation for hidden layer\n",
    "    hRELU = h.clamp(min = 0)\n",
    "    yPred = hRELU.mm(W2) # activation for output layer\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (yPred - Y).pow(2).sum()\n",
    "    if t % 50 == 0:\n",
    "        print(\"iter = \", t, \"; loss = \", loss)\n",
    "\n",
    "    # Backprop to compute gradients of W1, W2 with\n",
    "    #  respect to loss (objective function)\n",
    "    gradYPred = 2.0 * (yPred - Y)\n",
    "    gradW2 = hRELU.t().mm(gradYPred)\n",
    "    gradHiddenRELU = gradYPred.mm(W2.t())\n",
    "    gradH = gradHiddenRELU.clone()\n",
    "    gradH[h < 0] = 0\n",
    "    gradW1 = X.t().mm(gradH)\n",
    "\n",
    "    # Learning rule: Update weights\n",
    "    W1 -= learningRate * gradW1\n",
    "    W2 -= learningRate * gradW2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
