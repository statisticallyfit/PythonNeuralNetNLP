{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Source:\n",
    "http://seba1511.net/tutorials/beginner/nlp/advanced_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Making Dynamic Decisions and the Bi-LSTM CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting paper on CRFs:\n",
    "http://www.cs.columbia.edu/~mcollins/crf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f74e762af10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to make code more readable\n",
    "\n",
    "def toScalar(var):\n",
    "    # given: tensor variable\n",
    "    # returns a python float\n",
    "    return var.view(-1).data.tolist()[0]\n",
    "\n",
    "def argmax(vec):\n",
    "    # given: tensor (variable?)\n",
    "    # returns: argmax, or index of maximum value in tensor\n",
    "    _, index = torch.max(vec, 1) # along dim=1\n",
    "    return toScalar(index)\n",
    "\n",
    "def prepareSequence(seq, toIndex):\n",
    "    # given: dict toIndex, seq (tensor?)\n",
    "    # return variable of indices\n",
    "    indices = [toIndex[w] for w in seq]\n",
    "    tensor = torch.LongTensor(indices)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "# Compute log sum exp in stable way for the forward algo\n",
    "def logSumExp(vec):\n",
    "    maxScore = vec[0, argmax(vec)]\n",
    "    maxScoreBroadcast = maxScore.view(1,-1).expand(1, vec.size()[1])\n",
    "    return maxScore + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - maxScoreBroadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    " # need some global variables here, but also declared below\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabSize, tagToIndex, embeddingDim, hiddenDim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.vocabSize = vocabSize\n",
    "        self.tagToIndex = tagToIndex\n",
    "        self.tagsetSize = len(tagToIndex)\n",
    "        \n",
    "        self.wordEmbed = nn.Embedding(vocabSize, embeddingDim)\n",
    "        self.lstm = nn.LSTM(embeddingDim, hiddenDim // 2, \n",
    "                            num_layers=1, bidirectional=True)\n",
    "        \n",
    "        # Maps the output of LSTM into tag space\n",
    "        self.hiddenToTagLayer = nn.Linear(hiddenDim, self.tagsetSize)\n",
    "        \n",
    "        # Matrix of transition parameters. \n",
    "        # Entry i, j is the score of transition *to* i *from* j\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagsetSize, self.tagsetSize)\n",
    "        )\n",
    "        \n",
    "        # These two statements enforce the constraint that we never\n",
    "        # transfer to the start tag and never transfer from\n",
    "        # the stop tag\n",
    "        self.transitions.data[tagToIndex[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tagToIndex[STOP_TAG]] = -10000\n",
    "        \n",
    "        self.hiddenLayer = self.initHiddenLayer()\n",
    "        \n",
    "        \n",
    "    def initHiddenLayer(self):\n",
    "        return (autograd.Variable(torch.randn(2, 1, self.hiddenDim // 2)), \n",
    "                autograd.Variable(torch.randn(2, 1, self.hiddenDim // 2)))\n",
    "    \n",
    "    \n",
    "    def forwardAlgo(self, features):\n",
    "        # Do the forward algorithm to compute the partition funcion\n",
    "        initAlphas = torch.Tensor(1, self.tagsetSize).fill_(-10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        initAlphas[0][self.tagToIndex[START_TAG]] = 0.0\n",
    "        \n",
    "        # Wrap in a variable to get automatic backprop later on\n",
    "        forwardVar = autograd.Variable(initAlphas)\n",
    "        \n",
    "        # Iterate through the sentence\n",
    "        for currFeature in features:\n",
    "            alphas_t = [] # the forward variables at this timestep\n",
    "            \n",
    "            for nextTag in range(self.tagsetSize):\n",
    "                # broadcast the emission score: it is the same\n",
    "                # regardless of the previous tag\n",
    "\n",
    "                emissionScore = currFeature[nextTag].view(1,-1) \\\n",
    "                    .expand(1, self.tagsetSize)\n",
    "                \n",
    "                # the ith entry of transScore is the score of transitioning\n",
    "                # the nextTag from i\n",
    "                transScore = self.transitions[nextTag].view(1, -1)\n",
    "                \n",
    "                # The ith entry of nextTagVar is the value for the\n",
    "                # edge (i -> nextTag) before we do log-sum-exp\n",
    "                nextTagVar = forwardVar + transScore + emissionScore\n",
    "                \n",
    "                # The forward variable for this tag is the log-sum-exp \n",
    "                # for all the scores\n",
    "                alphas_t.append(logSumExp(nextTagVar))\n",
    "                \n",
    "            forwardVar = torch.cat(alphas_t).view(1, -1)\n",
    "            # error: forwardVar = torch.stack(alphas_t).view(1, -1)\n",
    "            \n",
    "        terminalVar = forwardVar + self.transitions[self.tagToIndex[STOP_TAG]]\n",
    "        \n",
    "        alpha = logSumExp(terminalVar)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getLSTMFeatures(self, sentence):\n",
    "        self.hiddenLayer = self.initHiddenLayer()\n",
    "        sentenceEmbedding = self.wordEmbed(sentence).view(len(sentence), 1, -1)\n",
    "        lstmOutLayer, self.hiddenLayer = self.lstm(sentenceEmbedding, self.hiddenLayer)\n",
    "        lstmOutLayer = lstmOutLayer.view(len(sentence), self.hiddenDim)\n",
    "        lstmFeatures = self.hiddenToTagLayer(lstmOutLayer)\n",
    "        \n",
    "        return lstmFeatures\n",
    "    \n",
    "    def scoreSentence(self, features, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = autograd.Variable(torch.Tensor([0]))\n",
    "        tags = torch.cat([torch.LongTensor([self.tagToIndex[START_TAG]]), tags])\n",
    "        # tags = torch.stack([torch.LongTensor([self.tagToIndex[START_TAG]]), tags])\n",
    "        \n",
    "        for i, currFeature in enumerate(features):\n",
    "            trs = self.transitions[tags[i+1], tags[i]] + currFeature[tags[i+1]]\n",
    "            score = score + trs\n",
    "            \n",
    "        score = score + self.transitions[self.tagToIndex[STOP_TAG], tags[-1]]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def viterbiDecode(self, features):\n",
    "        backpointers = []\n",
    "        \n",
    "        # Initialize the viterbi variables in log space\n",
    "        vVarsInit = torch.Tensor(1, self.tagsetSize).fill_(-10000.0)\n",
    "        vVarsInit[0][self.tagToIndex[START_TAG]] = 0\n",
    "        \n",
    "        # forwardvar at step i holds the viterbi variables for step i-1\n",
    "        forwardVar = autograd.Variable(vVarsInit)\n",
    "        \n",
    "        for currFeature in features:\n",
    "            bptrs_t = [] # holds the backpointers for this step\n",
    "            viterbiVars_t = [] # holds viterbi variables for this step\n",
    "            \n",
    "            for nextTag in range(self.tagsetSize):\n",
    "                # nexttagvar[i] holds the viterbi variable for tag i at\n",
    "                # the previous step, plus the score of transitioning\n",
    "                # from tag i to nexttag. \n",
    "                # We don't include the emission scores here because\n",
    "                # the max does not depend on them. (we add them in below)\n",
    "                nextTagVar = forwardVar + self.transitions[nextTag]\n",
    "                iBestTag = argmax(nextTagVar)\n",
    "                bptrs_t.append(iBestTag)\n",
    "                viterbiVars_t.append(nextTagVar[0][iBestTag])\n",
    "                \n",
    "            # Now add in the emission scores, and assign forwardvar\n",
    "            # to the set of viterbi variables we just computed\n",
    "            forwardVar = (torch.cat(viterbiVars_t) + currFeature).view(1, -1)\n",
    "            # error: forwardVar = (torch.stack(viterbiVars_t) + currFeature).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "            \n",
    "        # Transition to STOP_TAG\n",
    "        terminalVar = forwardVar + self.transitions[self.tagToIndex[STOP_TAG]]\n",
    "        iBestTag = argmax(terminalVar)\n",
    "        pathScore = terminalVar[0][iBestTag]\n",
    "        \n",
    "        \n",
    "        # Follow the back pointers to decode the best path\n",
    "        bestPath = [iBestTag]\n",
    "        \n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            iBestTag = bptrs_t[iBestTag]\n",
    "            bestPath.append(iBestTag)\n",
    "            \n",
    "        # Pop off the start tag ( we don't want to return that to caller)\n",
    "        start = bestPath.pop()\n",
    "        assert start == self.tagToIndex[START_TAG] # Sanity check\n",
    "        \n",
    "        bestPath.reverse()\n",
    "        \n",
    "        return pathScore, bestPath\n",
    "    \n",
    "    \n",
    "    def negLogLikelihood(self, sentence, tags):\n",
    "        features = self.getLSTMFeatures(sentence)\n",
    "        forwardScore = self.forwardAlgo(features)\n",
    "        goldScore = self.scoreSentence(features, tags)\n",
    "        \n",
    "        return forwardScore - goldScore \n",
    "    \n",
    "    def forward(self, sentence): # don't confuse this with forwardAlgo() above\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstmFeatures = self.getLSTMFeatures(sentence)\n",
    "        \n",
    "        # Find the best path, given the features.\n",
    "        score, tagSeq = self.viterbiDecode(lstmFeatures)\n",
    "        \n",
    "        return score, tagSeq\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL: \n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "# Make up some training data\n",
    "trainingData = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "wordToIndex = {}\n",
    "for sentence, tags in trainingData:\n",
    "    for word in sentence:\n",
    "        if word not in wordToIndex:\n",
    "            wordToIndex[word] = len(wordToIndex)\n",
    "\n",
    "tagToIndex = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BiLSTM_CRF(len(wordToIndex), tagToIndex, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precheckSentence:  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nprecheckTags:  tensor([0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2a92602d0e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precheckTags: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecheckTags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecheckSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d29124315d31>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Find the best path, given the features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbiDecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstmFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagSeq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d29124315d31>\u001b[0m in \u001b[0;36mviterbiDecode\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Now add in the emission scores, and assign forwardvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# to the set of viterbi variables we just computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mforwardVar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviterbiVars_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrFeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# error: forwardVar = (torch.stack(viterbiVars_t) + currFeature).view(1, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mbackpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbptrs_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "\n",
    "precheckSentence = prepareSequence(trainingData[0][0], wordToIndex)\n",
    "precheckTags = torch.LongTensor([tagToIndex[t] for t in trainingData[0][1]])\n",
    "\n",
    "print(\"precheckSentence: \", precheckSentence)\n",
    "print(\"precheckTags: \", precheckTags)\n",
    "\n",
    "print(model(precheckSentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-817ada1247a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Step 3: run forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnegLogLik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegLogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenceIndices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Step 4: compute loss, gradients, and update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d29124315d31>\u001b[0m in \u001b[0;36mnegLogLikelihood\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnegLogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLSTMFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mforwardScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardAlgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mgoldScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoreSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d29124315d31>\u001b[0m in \u001b[0;36mforwardAlgo\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0malphas_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogSumExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextTagVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mforwardVar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;31m# error: forwardVar = torch.stack(alphas_t).view(1, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Training here: \n",
    "\n",
    "NUM_ITER = 300\n",
    "\n",
    "for epoch in range(NUM_ITER):\n",
    "    \n",
    "    for sentence, tags in trainingData:\n",
    "        # Step 1: zero the accumulated gradient\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Step 2: get inputs ready for the network: means to turn them into\n",
    "        # Variables of word indices\n",
    "        sentenceIndices = prepareSequence(sentence, wordToIndex)\n",
    "        targets = torch.LongTensor([tagToIndex[t] for t in tags])\n",
    "        \n",
    "        # Step 3: run forward pass\n",
    "        negLogLik = model.negLogLikelihood(sentenceIndices, targets)\n",
    "        \n",
    "        # Step 4: compute loss, gradients, and update parameters\n",
    "        negLogLik.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TODO: help error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
