{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "markdown"
   },
   "source": [
    "# LSTM Part-of-Speech Tagger with AllenNLP\n",
    "## The Problem:\n",
    "\n",
    "Given a sentence like \"The dog ate the apple\" we want to predict part-of-speech tags for each word, like [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]\n",
    "\n",
    "### DEFINITION: [POS Tagging](https://synergo.atlassian.net/wiki/spaces/KnowRes/pages/109838612):\n",
    "Part of Speech Tagging (POS tagging) is the process of determining the part of speech of every token (word) in a document, and then tagging it as such. We can tag a token with a part of speech like proper or common noun, or as a verb, or adjective (etc).\n",
    "\n",
    "### BASIC STEPS:\n",
    "1. Embed each word in a low-dimensional vector space\n",
    "2. Poass each numericalized word through an LSTM to get a sequence of encodings.\n",
    "3. Use a feedforward layer in the LSTM to transform those into a sequence of logits, corresponding to the possible part-of-speech tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "In AllenNLP we use type annotations for just about everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "AllenNLP is built on top of PyTorch, so we use its code freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.tensor as Tensor\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Each training example is represented in AllenNLP as an `Instance` containing `Field`s of various types.\n",
    "\n",
    "Each example (`Instance`) will be composed of two things:\n",
    "\n",
    "1. a `TextField` containing the sentence, and\n",
    "2. a `SequenceLabelField` containing the corresponding part of speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Usually will always need to implement two classes, one of which is the `DatasetReader`, which contains the logic for reading a file of data and producing a stream of `Instance`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Frequently we need to load datasets or models from URLs.\n",
    "The `cached_path` helper downloads such files, then caches them locally, and then returns the local path. It also accepts local file paths (which it just returns as -is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.common.file_utils import cached_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "There are various ways to represent a word as one or more indices. For example, you might maintain a vocabulary of unique words and give each word a corresponding id. Or you might have one id per character in the word and represent each word as a sequence of ids. AllenNLP uses a has a `TokenIndexer` abstraction for this representation.\n",
    "\n",
    "So the `TokenIndexer` abstraction represents a rule for converting a token (word) into indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "While the `TokenIndexer` represents a rule for converting a token into indices, a `Vocabulary` contains the corresponding mappings (dictionary) from strings to integers.\n",
    "\n",
    "For instance, the token indexer might specify to represent a token as a sequence of character ids.\n",
    "\n",
    "This implies the `Vocabulary` would contain the dictionary mapping `{character -> id}`.\n",
    "\n",
    "In this case right now, we use a `SingleIdTokenIndexer` that assigns each token a unique id, and so the `Vocabulary` will just contain a mapping `{token -> id}` as well as the reverse mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "After `DatasetReader` the other class we would typically need to implement in AllenNLP is `Model`, which is a PyTorch `Module` that takes tensor inputs and produces a `dict` of tensor outputs (including the training `loss` that must be optimized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "The model consists of components:\n",
    "* embedding layer\n",
    "* LSTM model\n",
    "* feed forward layer\n",
    "\n",
    "in this order.\n",
    "\n",
    "AllenNLP includes abstractions for all of these components (imported as below) that handle padding and batching and various utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "This is for tracking accuracy on training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.training.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "In our training we will need a `DataIterator` that can intelligently batch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "This is the `Trainer` that trains the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "The `SentenceTaggerPredictor` is for making predictions on new inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "from allennlp.predictors import SentenceTaggerPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Setting the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "# Step 1: Create the `DatasetReader` for POS Tagging\n",
    "The first step is to create the `DatasetReader` for our particular POS tagging task.\n",
    "\n",
    "### `__init__()` method:\n",
    "The only parameter our `DatasetReader` needs is a dict of `TokenIndexer`s that specify how to convert tokens into indices.\n",
    "\n",
    "By default we generate a single index for each token (which we also call \"tokens\") that is a unique id for each distinct token. (This is jus the standard \"word to index\" mapping used in most NLP tasks).\n",
    "\n",
    "### `text_to_instance()` method:\n",
    "The `DatasetReader.text_to_instance` takes the inputs corresponding to a training example (in this case, the tokens of the sentence and corresponding part-of-speech tags), and instantiates the corresponding `Field`s:\n",
    "* a `TextField` for the sentence, and\n",
    "* a `SequenceLabelField` for its tags.\n",
    "\n",
    "and returns the `Instance` containing those fields.\n",
    "\n",
    "The tags are optional since we should have the option of creating instances from unlabeled data to make predictions on them.\n",
    "\n",
    "### `_read()` method:\n",
    "Takes a filename and produces a stream of `Instance`s, harnessing the `text_to_instance()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class PosDatasetReader(DatasetReader):\n",
    "\n",
    "    def __init__(self, tokenIndexers: Dict[str, TokenIndexer] = None) -> None:\n",
    "        super().__init__(lazy = False)\n",
    "\n",
    "        self.tokenIndexers = tokenIndexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "\n",
    "    def text_to_instance(self, tokens: List[Token], tags: List[str] = None) -> Instance:\n",
    "\n",
    "        sentenceField = TextField(tokens = tokens,\n",
    "                                  token_indexers= self.tokenIndexers)\n",
    "\n",
    "        fields = {\"sentence\": sentenceField}\n",
    "\n",
    "        if tags:\n",
    "            labelField = SequenceLabelField(labels = tags,\n",
    "                                            sequence_field= sentenceField)\n",
    "            fields[\"labels\"] = labelField\n",
    "\n",
    "\n",
    "        return Instance(fields = fields)\n",
    "\n",
    "\n",
    "    def _read(self, filePath: str) -> Iterator[Instance]:\n",
    "        with open(filePath) as f:\n",
    "            for line in f:\n",
    "                pairs = line.strip().split()\n",
    "                sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n",
    "                yield self.text_to_instance([Token(word) for word in sentence], tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "title": "markdown"
   },
   "source": [
    "# Step 2: Create the LstmTagger Class\n",
    "In general we always must implement classes inheriting from `DatasetReader` and `Model` class.\n",
    "\n",
    "This `LstmTagger` class inherits from the `Model` class.\n",
    "\n",
    "The `Model` class is a subclass of `torch.nn.Module`. It  needs a `forward` method that takes tensor inputs and produces a dict of tensor outputs that incldues the loss to train the model.\n",
    "\n",
    "The model consists of an embedding layer, sequence encoder, and feedforward network.\n",
    "\n",
    "### `__init__()` method:\n",
    "One thing that might seem unusual is that we're going pass in the embedder and the sequence encoder as constructor parameters. This allows us to experiment with different embedders and encoders without having to change the model code.\n",
    "* `wordEmbeddings: TextFieldEmbedder`: the embedding layer is specified as an AllenNLP `TextFieldEmbedder` which represents a general way of turning tokens into tensors.  (Here we know that we want to represent each unique word with a learned tensor, but using the general class allows us to easily experiment with different types of embeddings, for example ELMo.)\n",
    "* `encoder: Seq2SeqEncoder`: Similarly, the encoder is specified as a general `Seq2SeqEncoder` even though we know we want to use an LSTM. Again, this makes it easy to experiment with other sequence encoders, for example a Transformer.\n",
    "* `vocab: Vocabulary`: Every AllenNLP model also expects a `Vocabulary`, which contains the namespaced mappings of tokens to indices and labels to indices.\n",
    "\n",
    "### `forward()` method\n",
    "Actual computation happens here.\n",
    "Each `Instance` in the data set will get batched with other `Instance`s and fed into `forward`.\n",
    "Arguments: dicts of tensors, with names equal to the names of the fields in the `Instance`.\n",
    "* NOTE: In this case we have a sentence field and possibly a labels field so we will construct the `forward` method accordingly.\n",
    "\n",
    "### `get_metrics()` method:\n",
    "We included an accuracy metric that gets updated each forward pass. That means we need to override a get_metrics method that pulls the data out of it. Behind the scenes, the `CategoricalAccuracy` metric is storing the number of predictions and the number of correct predictions, updating those counts during each call to forward. Each call to `get_metric` returns the calculated accuracy and (optionally) resets the counts, which is what allows us to track accuracy anew for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class LstmTagger(Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 wordEmbeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2SeqEncoder,\n",
    "                 vocab: Vocabulary) -> None:\n",
    "\n",
    "        # Notice: we have to pass the vocab to the base class constructor\n",
    "        super().__init__(vocab)\n",
    "\n",
    "        self.wordEmbeddings: TextFieldEmbedder = wordEmbeddings\n",
    "        self.encoder: Seq2SeqEncoder = encoder\n",
    "\n",
    "        # The feed forward layer is not passed in as parameter.\n",
    "        # Instead we construct it here.\n",
    "        # It gets encoder's output dimension as the feedforward layer's input dimension\n",
    "        # and uses vocab's size as the feedforward layer's output dimension.\n",
    "        self.hiddenToTagLayer = torch.nn.Linear(in_features = encoder.get_output_dim(),\n",
    "                                                out_features= vocab.get_vocab_size(namespace = 'labels'))\n",
    "\n",
    "        # Instantiate an accuracy metric to track it during training\n",
    "        # and validation epochs.\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                sentence: Dict[str, Tensor],\n",
    "                labels: Tensor = None) -> Dict[str, Tensor]:\n",
    "\n",
    "\n",
    "        # Step 1: Create the masks\n",
    "\n",
    "        # AllenNLP is designed to operate on batched inputs, but\n",
    "        # different input sequences have different lengths. Behind the scenes AllenNLP is\n",
    "        # padding the shorter inputs so that the batch has uniform shape, which means our\n",
    "        # computations need to use a mask to exclude the padding. Here we just use the utility\n",
    "        # function get_text_field_mask, which returns a tensor of 0s and 1s corresponding to\n",
    "        # the padded and unpadded locations.\n",
    "        mask: Tensor = get_text_field_mask(text_field_tensors= sentence)\n",
    "\n",
    "\n",
    "        # Step 2: create the tensor embeddings\n",
    "\n",
    "        # We start by passing the sentence tensor (each sentence a sequence of token ids)\n",
    "        # to the word_embeddings module, which converts each sentence into a sequence\n",
    "        # of embedded tensors.\n",
    "\n",
    "        # Does forward pass of word embeddings layer\n",
    "        embeddings: Tensor = self.wordEmbeddings(sentence)\n",
    "\n",
    "\n",
    "        # Step 3: Encode the embeddings using mask\n",
    "\n",
    "        # We next pass the embedded tensors (and the mask) to the LSTM,\n",
    "        # which produces a sequence of encoded outputs.\n",
    "\n",
    "        # Does forward pass of encoder layer\n",
    "        encoderOutputs: Tensor = self.encoder(embeddings, mask)\n",
    "\n",
    "\n",
    "        # Step 4: Finally, we pass each encoded output tensor to the feedforward\n",
    "        # layer to produce logits corresponding to the various tags.\n",
    "\n",
    "        # Does forward pass of the linear layer\n",
    "        tagLogits = self.hiddenToTagLayer(encoderOutputs)\n",
    "        output = {\"tagLogits\": tagLogits}\n",
    "\n",
    "\n",
    "        # As before, the labels were optional, as we might want to run this model to\n",
    "        # make predictions on unlabeled data. If we do have labels, then we use them\n",
    "        # to update our accuracy metric and compute the \"loss\" that goes in our output.\n",
    "        if labels is not None:\n",
    "            self.accuracy(predictions = tagLogits, gold_labels = labels, mask = mask)\n",
    "            output[\"loss\"] = sequence_cross_entropy_with_logits(logits = tagLogits,\n",
    "                                                                targets = labels,\n",
    "                                                                weights = mask)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "# Step 3: Start Training\n",
    "Now that we've implemented a `DatasetReader` and `Model`, we're ready to train.\n",
    "\n",
    "### Step 4 Training: Create a data set reader for POS tagging:\n",
    "We first need an instance of our dataset reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "reader = PosDatasetReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 5 Training: Download the data\n",
    "We can use the `PosDatasetReader`  to read in the training data and validation data. Here we read them in from a URL, but you could read them in from local files if your data was local. We use cached_path to cache the files locally (and to hand reader.read the path to the local cached version.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "trainDataset = reader.read(cached_path(\n",
    "    'https://raw.githubusercontent.com/allenai/allennlp'\n",
    "    '/master/tutorials/tagger/training.txt'))\n",
    "\n",
    "validationDataset = reader.read(cached_path(\n",
    "    'https://raw.githubusercontent.com/allenai/allennlp'\n",
    "    '/master/tutorials/tagger/validation.txt'))\n",
    "trainDataset\n",
    "validationDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 6 Training: Create the Vocabulary\n",
    "Once we've read in the datasets, we use them to create our Vocabulary (that is, the mapping[s] from tokens / labels to ids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "vocab = Vocabulary.from_instances(instances = trainDataset + validationDataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 7 Training: Choose embedding and hidden layer sizes\n",
    "Now we need to construct the model. We'll choose a size for our embedding layer and for the hidden layer of our LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 8 Training: Create the Embeddings\n",
    "For embedding the tokens we'll just use the `BasicTextFieldEmbedder`.\n",
    "\n",
    "This takes a mapping from index names to embeddings.\n",
    "\n",
    "The default parameters for `DatasetReader` included a single index called \"tokens\", so our mapping just needs an embedding corresponding to that index.\n",
    "\n",
    "The number of embeddings is set to be equal to the `Vocabulary` size.\n",
    "\n",
    "The output dimension is set to equal the `EMBEDDING_DIM`\n",
    "\n",
    "It is also possible to start with pre-trained embeddings (for example, GloVe vectors), but there's no need to do that on this tiny toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "tokenEmbedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                           embedding_dim=EMBEDDING_DIM)\n",
    "wordEmbeddings = BasicTextFieldEmbedder({\"tokens\": tokenEmbedding})\n",
    "\n",
    "tokenEmbedding\n",
    "wordEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 9 Training: Specify the Sequence Encoder\n",
    "The `PytorchSeq2SeqWrapper` is needed here to add some extra functionality and cleaner interface to the built-in PyTorch module.\n",
    "\n",
    "Also specify `batch_first = True` (always the case in AllenNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "lstmEncoder = PytorchSeq2SeqWrapper(module =\n",
    "                             torch.nn.LSTM(input_size = EMBEDDING_DIM,\n",
    "                                           hidden_size = HIDDEN_DIM,\n",
    "                                           batch_first = True\n",
    "                                           )\n",
    "                                    )\n",
    "lstmEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 10 Training: Instantiate the POS Tagger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "posTagModel = LstmTagger(wordEmbeddings = wordEmbeddings,\n",
    "                         encoder = lstmEncoder,\n",
    "                         vocab = vocab)\n",
    "posTagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Checking for GPU\n",
    "if torch.cuda.is_available():\n",
    "    cudaDevice = 0\n",
    "    posTagModel = posTagModel.cuda(cudaDevice)\n",
    "else:\n",
    "    cudaDevice = -1\n",
    "\n",
    "cudaDevice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 11 Training: Create Optimizer\n",
    "Using stochastic gradient descent here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(posTagModel.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 12 Training: Create Iterator\n",
    "Need a `DataIterator` that handles batching for the datasets.\n",
    "\n",
    "The `BucketIterator` sorts instances by the specified fields in order to create batches with similar sequence lengths.\n",
    "\n",
    "Below, we sort the instances by the number of tokens in the sentence field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=2, sorting_keys=[(\"sentence\", \"num_tokens\")])\n",
    "\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 13 Training: Create the `Trainer`\n",
    "Instantiating the `Trainer` and running it.\n",
    "\n",
    "Setting the `patience = 10`: Here we run for 1000 epochs and stop training early if it ever spends 10 epochs without the validation metric improving.\n",
    "\n",
    "* NOTE: Default validation metric is the loss, which improves by getting smaller, but can also specify a different metric and direction (like accuracy, which should increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model = posTagModel,\n",
    "                  optimizer = optimizer,\n",
    "                  iterator = iterator,\n",
    "                  train_dataset = trainDataset,\n",
    "                  validation_dataset = validationDataset,\n",
    "                  patience = 10,\n",
    "                  num_epochs = 1000,\n",
    "                  cuda_device = cudaDevice)\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "When we launch it it will print a progress bar for each epoch that includes both the \"loss\" and the \"accuracy\" metric. If our model is good, the loss should go down and the accuracy up as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 14 Training: Generate Model Predictions\n",
    "AllenNLP contains a `Predictor` abstraction that takes inputs, converts them to instances, and feeds them through\n",
    "the model and returns JSON-serializabel results.\n",
    "\n",
    "Often must implement a custom `Predictor` but here we can use `SentenceTaggerPredictor`. It takes in as parameters\n",
    "a `DatasetReader` for creating data instances, and our model, for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "predictor = SentenceTaggerPredictor(posTagModel, dataset_reader=reader)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "The predictor object It has a `predict` method that just needs a sentence and returns (a JSON-serializable version of)\n",
    "the output dict from forward. Here `tagLogits` will be a (5, 3) array of logits, corresponding to the 3 possible tags\n",
    "for each of the 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "tagLogits = predictor.predict(\"The dog ate the apple\")['tagLogits']\n",
    "tagLogits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "To get the actual \"predictions\" we can just take the `argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "tagIndices = np.argmax(tagLogits, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Using the `Vocabulary` find the predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "print([posTagModel.vocab.get_token_from_index(i, 'labels') for i in tagIndices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### Step 15: Save the Model\n",
    "Here's how to save the model.\n",
    "First we save the model weights, then the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# Saving the model weights\n",
    "with open(\"/tmp/model.th\", 'wb') as f:\n",
    "    torch.save(posTagModel.state_dict(), f)\n",
    "\n",
    "# Saving the vocabulary\n",
    "vocab.save_to_files(\"/tmp/vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "### How to Reload the Model:\n",
    "We only saved the model weights, so we actually have to recreate the same model structure using code if we want to reuse them. First, let's reload the vocabulary into a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "vocabRE = Vocabulary.from_files(\"/tmp/vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "And then let's recreate the model (if we were doing this in a different file we would of course have to re-instantiate the word embeddings and lstm as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "posTagModelRE = LstmTagger(wordEmbeddings, lstmEncoder, vocabRE)\n",
    "\n",
    "# Must load the model state\n",
    "with open(\"/tmp/model.th\", 'rb') as f:\n",
    "    posTagModelRE.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Here we move the loaded model to the GPU that we used previously. This is necessary because we moved `wordEmbeddings`\n",
    "and `lstmEncoder` with the original model earlier. All of a model's parameters need to be on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "if cudaDevice > -1:\n",
    "    posTagModelRE.cuda(cudaDevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "markdown"
   },
   "source": [
    "Getting the predictions and testing that the reloaded ones are close to the original predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "predictorRE = SentenceTaggerPredictor(posTagModelRE, dataset_reader=reader)\n",
    "tagLogitsRE = predictorRE.predict(\"The dog ate the apple\")['tagLogits']\n",
    "\n",
    "# Testing that the predictions are almost the same as the reloaded ones.\n",
    "np.testing.assert_array_almost_equal(tagLogitsRE, tagLogits)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
