{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "\n",
    "from typing import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data/brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an LSTM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be building our own LSTM and delving into why it performs so well across a wide range of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of the LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we actually build the LSTM, we'll need to understand its basic mechansim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below diagram shows the flow of information in an LSTM cell (image from Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": [
    "#![image](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1920px-The_LSTM_cell.png)\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for the LSTM looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{ll} \\\\\n",
    "            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "            c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "            h_t = o_t * \\tanh(c_t) \\\\\n",
    "        \\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems complex, but when you pick it apart, the LSTM is actually very simple. The core of the LSTM is the following equation:\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "            c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick this equation apart: $ c_t $ is the new cell state, which is basically the memory of the LSTM. \n",
    "\n",
    "$ f_t $ is called the \"forget gate\": it dictates how much of the previous cell state to **retain** (but is slightly confusingly named the forget gate). \n",
    "\n",
    "$ i_t $ is the \"input gate\" and dictates how much to update the cell state with new information.\n",
    "\n",
    "Finally, $ g_t $ is the information we use to update the cell state.\n",
    "\n",
    "Basically, an LSTM chooses to keep a certain portion of its previous cell state and add a certain amount of new information. These proportions are controlled using gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's contrast this update rule with the update rule of a simpler RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c_t = \\tanh(W_hc_{t-1} + W_ix_t) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To make the contrast clearer, I'm representing the hidden state of the RNN as $ c_t $.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a huge difference between the simple RNN's update rule and the LSTM's update rule. Whereas the RNN computes the new hidden state from scratch based on the previous hidden state and the input, the LSTM computes the new hidden state by choosing what to **add** to the current state. This is similar to how ResNets learn: they learn what to add to the current state/block instead of directly learning the new state. In other words, LSTMs are great primarily because they are **additive**. We'll formalize this intuition later when we examine the gradient flow, but this is the basic idea behind the LSTM.\n",
    "\n",
    "Now that we have a basic understanding, let's start coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side Note: One thing that is slightly confusing about the LSTM is that it has two \"hidden states\": $ c_t $ and $ h_t $. Intuitively, $ c_t $ is the \"internal\" hidden state that retains important information for longer timesteps, whereas $ h_t $ is the \"external\" hidden state that exposes that information to the outside world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side Note: If you're looking carefully, you'll notice that the bias terms are redundant. The reason they are there is for compatibility with the CuDNN backend. Until we touch on CuDNN, we'll use a single bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using PyTorch to write our own LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        # input gate\n",
    "        self.W_ii = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hi = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = Parameter(torch.Tensor(hidden_sz))\n",
    "        # forget gate\n",
    "        self.W_if = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hf = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = Parameter(torch.Tensor(hidden_sz))\n",
    "        # ???\n",
    "        self.W_ig = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hg = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_g = Parameter(torch.Tensor(hidden_sz))\n",
    "        # output gate\n",
    "        self.W_io = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_ho = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states: Optional[Tuple[torch.Tensor, torch.Tensor]]=None\n",
    "               ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_if + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_ig + h_t @ self.W_hg + self.b_g)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_io + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)\n",
    "lstm = NaiveLSTM(feat_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs, (hn, cn) = lstm(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we've covered the basics and have a minimally working LSTM, we'll put our model into action. Our testbed will be a character-level language modeling task. We'll be using the Brown Corpus which you can get via the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {DATA_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://www.sls.hawaii.edu/bley-vroman/brown.txt -o {DATA_ROOT / \"brown.txt\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll let AllenNLP handle the complexity of training the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:02 - INFO - allennlp.data.dataset_readers.language_modeling -   Creating dataset from all text in file: /development/projects/statisticallyfit/github/learningmathstat/PythonNeuralNetNLP/src/NLPstudy/LSTMModel/data/brown.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/11994 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 19%|█▉        | 2280/11994 [00:00<00:00, 22707.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 33%|███▎      | 3939/11994 [00:00<00:00, 19995.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 48%|████▊     | 5807/11994 [00:00<00:00, 19581.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 74%|███████▎  | 8833/11994 [00:00<00:00, 18989.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 11994/11994 [00:00<00:00, 22490.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\r1it [00:13, 13.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r471it [00:13,  9.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r802it [00:13,  6.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1217it [00:13,  4.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1571it [00:13,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2043it [00:13,  2.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2452it [00:14,  1.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2870it [00:14,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3335it [00:14,  1.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3765it [00:14,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4176it [00:14,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4586it [00:14,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4921it [00:14,  5.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5287it [00:14,  7.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5619it [00:15, 10.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5947it [00:15, 15.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6274it [00:15, 22.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6579it [00:15, 31.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6862it [00:15, 44.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7143it [00:15, 63.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7400it [00:15, 89.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7655it [00:15, 126.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7973it [00:15, 177.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8275it [00:16, 246.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8555it [00:16, 339.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8966it [00:16, 467.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9392it [00:16, 638.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9808it [00:16, 855.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10177it [00:16, 1041.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10593it [00:16, 1343.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10991it [00:16, 1676.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11441it [00:16, 2064.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11837it [00:17, 2409.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11994it [00:17, 694.61it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n11/19/2019 08:30:06 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/10794 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  1%|          | 115/10794 [00:00<00:09, 1148.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  2%|▏         | 218/10794 [00:00<00:09, 1108.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  3%|▎         | 333/10794 [00:00<00:09, 1119.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  4%|▍         | 467/10794 [00:00<00:08, 1177.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  6%|▌         | 632/10794 [00:00<00:07, 1288.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  7%|▋         | 801/10794 [00:00<00:07, 1386.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  9%|▉         | 947/10794 [00:00<00:07, 1406.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 10%|█         | 1082/10794 [00:00<00:09, 981.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|█         | 1194/10794 [00:01<00:10, 927.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 12%|█▏        | 1297/10794 [00:01<00:10, 873.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 13%|█▎        | 1392/10794 [00:01<00:12, 724.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 14%|█▎        | 1475/10794 [00:01<00:13, 670.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 14%|█▍        | 1550/10794 [00:01<00:13, 679.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 15%|█▌        | 1627/10794 [00:01<00:13, 696.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 16%|█▌        | 1701/10794 [00:01<00:15, 598.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 16%|█▋        | 1766/10794 [00:02<00:15, 592.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 17%|█▋        | 1837/10794 [00:02<00:14, 622.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 18%|█▊        | 1912/10794 [00:02<00:13, 654.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 19%|█▊        | 2014/10794 [00:02<00:11, 733.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2178/10794 [00:02<00:09, 878.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 22%|██▏       | 2325/10794 [00:02<00:08, 999.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 23%|██▎       | 2457/10794 [00:02<00:07, 1077.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 24%|██▍       | 2593/10794 [00:02<00:07, 1147.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 25%|██▌       | 2719/10794 [00:02<00:06, 1161.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 26%|██▋       | 2845/10794 [00:02<00:06, 1187.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 28%|██▊       | 2970/10794 [00:03<00:06, 1134.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 29%|██▊       | 3097/10794 [00:03<00:06, 1171.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3252/10794 [00:03<00:05, 1262.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 32%|███▏      | 3421/10794 [00:03<00:05, 1365.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 33%|███▎      | 3569/10794 [00:03<00:05, 1396.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 35%|███▍      | 3742/10794 [00:03<00:04, 1481.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 36%|███▋      | 3932/10794 [00:03<00:04, 1585.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 38%|███▊      | 4115/10794 [00:03<00:04, 1651.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|███▉      | 4285/10794 [00:03<00:04, 1368.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 41%|████      | 4433/10794 [00:04<00:04, 1302.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 42%|████▏     | 4572/10794 [00:04<00:04, 1254.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 44%|████▎     | 4704/10794 [00:04<00:05, 1173.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 45%|████▍     | 4832/10794 [00:04<00:04, 1203.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 46%|████▌     | 4963/10794 [00:04<00:04, 1233.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 47%|████▋     | 5090/10794 [00:04<00:04, 1216.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 49%|████▊     | 5249/10794 [00:04<00:04, 1307.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|████▉     | 5384/10794 [00:04<00:04, 1128.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 51%|█████     | 5528/10794 [00:04<00:04, 1206.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 52%|█████▏    | 5655/10794 [00:05<00:04, 1210.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 54%|█████▎    | 5789/10794 [00:05<00:04, 1245.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 55%|█████▌    | 5946/10794 [00:05<00:03, 1325.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 56%|█████▋    | 6093/10794 [00:05<00:03, 1365.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 58%|█████▊    | 6233/10794 [00:05<00:03, 1320.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 59%|█████▉    | 6368/10794 [00:05<00:03, 1245.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6496/10794 [00:05<00:03, 1171.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 62%|██████▏   | 6667/10794 [00:05<00:03, 1293.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 63%|██████▎   | 6843/10794 [00:05<00:02, 1403.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 65%|██████▌   | 7027/10794 [00:06<00:02, 1509.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 67%|██████▋   | 7191/10794 [00:06<00:02, 1546.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 68%|██████▊   | 7351/10794 [00:06<00:02, 1511.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|██████▉   | 7520/10794 [00:06<00:02, 1558.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 71%|███████   | 7679/10794 [00:06<00:02, 1483.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 73%|███████▎  | 7831/10794 [00:06<00:02, 1479.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 74%|███████▍  | 8006/10794 [00:06<00:01, 1550.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 76%|███████▌  | 8164/10794 [00:06<00:01, 1491.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 77%|███████▋  | 8316/10794 [00:06<00:01, 1496.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 78%|███████▊  | 8469/10794 [00:06<00:01, 1504.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8646/10794 [00:07<00:01, 1574.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 82%|████████▏ | 8826/10794 [00:07<00:01, 1630.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 83%|████████▎ | 8999/10794 [00:07<00:01, 1652.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 85%|████████▌ | 9194/10794 [00:07<00:00, 1731.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 87%|████████▋ | 9370/10794 [00:07<00:00, 1726.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 88%|████████▊ | 9546/10794 [00:07<00:00, 1733.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9730/10794 [00:07<00:00, 1760.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 92%|█████████▏| 9907/10794 [00:07<00:00, 1703.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 93%|█████████▎| 10087/10794 [00:07<00:00, 1728.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 95%|█████████▌| 10261/10794 [00:08<00:00, 1674.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 97%|█████████▋| 10441/10794 [00:08<00:00, 1709.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 98%|█████████▊| 10618/10794 [00:08<00:00, 1726.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 10794/10794 [00:08<00:00, 1297.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data.dataset_readers import LanguageModelingReader\n",
    "from allennlp.data.tokenizers import CharacterTokenizer\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data.iterators import BasicIterator\n",
    "from allennlp.training import Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "char_tokenizer = CharacterTokenizer(lowercase_characters=True)\n",
    "\n",
    "reader = LanguageModelingReader(\n",
    "    tokens_per_instance=500,\n",
    "    tokenizer=char_tokenizer,\n",
    "    token_indexers = {\"tokens\": SingleIdTokenIndexer()},\n",
    ")\n",
    "\n",
    "import os\n",
    "pth = os.getcwd()\n",
    "\n",
    "train_ds = reader.read(pth + \"/LSTMModel/data/brown.txt\")\n",
    "train_ds, val_ds = train_test_split(train_ds, random_state=0, test_size=0.1)\n",
    "\n",
    "vocab = Vocabulary.from_instances(train_ds)\n",
    "\n",
    "iterator = BasicIterator(batch_size=32)\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "def train(model: nn.Module, epochs: int=10):\n",
    "    trainer = Trainer(\n",
    "        model=model.cuda() if torch.cuda.is_available() else model,\n",
    "        optimizer=optim.Adam(model.parameters()),\n",
    "        iterator=iterator, train_dataset=train_ds, \n",
    "        validation_dataset=val_ds, num_epochs=epochs,\n",
    "        cuda_device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    return trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.models import Model\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "\n",
    "class LanguageModel(Model):\n",
    "    def __init__(self, encoder: nn.RNN, vocab: Vocabulary,\n",
    "                 embedding_dim: int=50):\n",
    "        super().__init__(vocab=vocab)\n",
    "        # char embedding\n",
    "        self.vocab_size = vocab.get_vocab_size()\n",
    "        self.padding_idx = vocab.get_token_index(\"@@PADDING@@\")\n",
    "        token_embedding = Embedding(\n",
    "            num_embeddings=vocab.get_vocab_size(),\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_index=self.padding_idx,\n",
    "        )\n",
    "        self.embedding = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.hidden_size, self.vocab_size)\n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_idx)\n",
    "    \n",
    "    def forward(self, input_tokens: Dict[str, torch.Tensor],\n",
    "                output_tokens: Dict[str, torch.Tensor]):\n",
    "        # TODO: Implement\n",
    "        embs = self.embedding(input_tokens)\n",
    "        x, _ = self.encoder(embs)\n",
    "        x = self.projection(x)\n",
    "        if output_tokens is not None:\n",
    "            loss = self.loss(x.view((-1, self.vocab_size)), output_tokens[\"tokens\"].flatten())\n",
    "        else:\n",
    "            loss = None\n",
    "        return {\"loss\": loss, \"logits\": x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:30 - WARNING - allennlp.training.trainer -   You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:30 - INFO - allennlp.training.trainer -   Beginning training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:30 - INFO - allennlp.training.trainer -   Epoch 0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:30 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 1658.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2019 08:30:30 - INFO - allennlp.training.trainer -   Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2394 ||:   0%|          | 1/338 [00:05<32:39,  5.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2369 ||:   1%|          | 2/338 [00:08<28:08,  5.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2340 ||:   1%|          | 3/338 [00:11<24:15,  4.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2307 ||:   1%|          | 4/338 [00:14<21:35,  3.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2278 ||:   1%|▏         | 5/338 [00:17<19:46,  3.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2245 ||:   2%|▏         | 6/338 [00:19<17:39,  3.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2211 ||:   2%|▏         | 7/338 [00:22<17:23,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2172 ||:   2%|▏         | 8/338 [00:25<16:36,  3.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2129 ||:   3%|▎         | 9/338 [00:28<15:59,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2079 ||:   3%|▎         | 10/338 [00:30<15:09,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.2017 ||:   3%|▎         | 11/338 [00:32<14:17,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.1942 ||:   4%|▎         | 12/338 [00:35<13:29,  2.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.1840 ||:   4%|▍         | 13/338 [00:37<13:02,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.1695 ||:   4%|▍         | 14/338 [00:39<13:00,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.1483 ||:   4%|▍         | 15/338 [00:41<12:47,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.1200 ||:   5%|▍         | 16/338 [00:44<12:53,  2.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.0869 ||:   5%|▌         | 17/338 [00:46<12:52,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.0509 ||:   5%|▌         | 18/338 [00:49<12:32,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 4.0137 ||:   6%|▌         | 19/338 [00:51<12:37,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.9757 ||:   6%|▌         | 20/338 [00:53<12:33,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.9389 ||:   6%|▌         | 21/338 [00:56<12:16,  2.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.9022 ||:   7%|▋         | 22/338 [00:58<12:09,  2.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.8681 ||:   7%|▋         | 23/338 [01:00<12:06,  2.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.8359 ||:   7%|▋         | 24/338 [01:02<12:03,  2.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.8042 ||:   7%|▋         | 25/338 [01:05<12:09,  2.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.7747 ||:   8%|▊         | 26/338 [01:07<12:20,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.7475 ||:   8%|▊         | 27/338 [01:10<12:42,  2.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rloss: 3.7216 ||:   8%|▊         | 28/338 [01:13<12:56,  2.51s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d04ae37f3072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlm_naive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_naive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a75ee0914c5b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan loss encountered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "lm_naive = LanguageModel(NaiveLSTM(50, 125), vocab)\n",
    "train(lm_naive, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare with the official LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_comparison = LanguageModel(nn.LSTM(50, 125, batch_first=True), vocab)\n",
    "train(lm_comparison, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out model is a lot slower, but we're getting similar performance, so it looks good! We'll look at how we can optimize the performance later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the performance of the LSTM with a much simpler RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_sz, self.hidden_size = input_sz, hidden_sz\n",
    "        self.weight_ih = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.weight_hh = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.bias_hh = Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.weight_ih)\n",
    "        nn.init.xavier_uniform_(self.weight_hh)\n",
    "        nn.init.zeros_(self.bias_hh)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, init_state=None) -> torch.Tensor:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_state is None:\n",
    "            h_t = torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t = init_state\n",
    "\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            h_t = torch.tanh(x_t @ self.weight_ih + h_t @ self.weight_hh + self.bias_hh)\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_simplernn = LanguageModel(SimpleRNN(50, 125), vocab)\n",
    "train(lm_simplernn, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the dynamics of LSTM learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why exactly do LSTMs learn so well? Let's analyze the dynamics of LSTM learning by checking how the gradients change and comparing them to the gradients of a simple RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iterator(train_ds))\n",
    "test_embeddings = lm_naive.embedding(test_batch[\"input_tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient dynamics of simple RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check how the gradients of a simple RNN change with regards to the initial inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = SimpleRNN(50, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_step(x_t, h_t, weight_ih, weight_hh, bias_hh):\n",
    "    return torch.tanh(x_t @ weight_ih + h_t @ weight_hh + bias_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = torch.zeros(rnn.hidden_size, requires_grad=True).to(test_embeddings.device)\n",
    "h_t = h_0\n",
    "grads = []\n",
    "\n",
    "for t in range(100):\n",
    "    h_t = rnn_step(\n",
    "        test_embeddings[:, t, :], h_t,\n",
    "        rnn.weight_ih, rnn.weight_hh, rnn.bias_hh,\n",
    "    )\n",
    "    loss = h_t.abs().sum() # we'll use the l1 norm of the current hidden state as the loss\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads.append(torch.norm(h_0.grad).item())\n",
    "    h_0.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the gradients decay as time progresses. This is one of the factors that makes simple RNNs more difficult to train compared to LSTMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient dynamics of LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compare the same plot with LSTMs. Though this might not be very well known, the original formulation of the LSTM did not have a forget gate; we'll be using the formulation without the forget gate first and then see how the forget gate changes the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = NaiveLSTM(50, 125)\n",
    "hidden_size = lstm.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_step(x_t, h_t, c_t, W_ii, W_hi, b_i, W_if, W_hf, b_f,\n",
    "              W_ig, W_hg, b_g, W_io, W_ho, b_o, use_forget_gate=False):\n",
    "    i_t = torch.sigmoid(x_t @ W_ii + h_t @ W_hi + lstm.b_i)\n",
    "    if use_forget_gate:\n",
    "        f_t = torch.sigmoid(x_t @ W_if + h_t @ W_hf + lstm.b_f)\n",
    "    g_t = torch.tanh(x_t @ W_ig + h_t @ W_hg + lstm.b_g)\n",
    "    o_t = torch.sigmoid(x_t @ W_io + h_t @ W_ho + lstm.b_o)\n",
    "    if use_forget_gate:\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "    else:\n",
    "        c_t = c_t + i_t * g_t\n",
    "    h_t = o_t * torch.tanh(c_t)\n",
    "    return h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate \n",
    "h_0, c_0 = (torch.zeros(hidden_size, requires_grad=True), \n",
    "            torch.zeros(hidden_size, requires_grad=True))\n",
    "grads = []\n",
    "h_t, c_t = h_0, c_0\n",
    "for t in range(100):\n",
    "    h_t, c_t = lstm_step(\n",
    "        test_embeddings[:, t, :], h_t, c_t,\n",
    "        lstm.W_ii, lstm.W_hi, lstm.b_i,\n",
    "        lstm.W_if, lstm.W_hf, lstm.b_f,\n",
    "        lstm.W_ig, lstm.W_hg, lstm.b_g,\n",
    "        lstm.W_io, lstm.W_ho, lstm.b_o,\n",
    "        use_forget_gate=False,\n",
    "    )\n",
    "    loss = h_t.abs().sum()\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads.append(torch.norm(h_0.grad).item())\n",
    "    h_0.grad.zero_()\n",
    "    lstm.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the gradient keeps on accumulating. The reason the gradient behaves this way is because of the update rule\n",
    "$$ c_t = c_{t-1} + i_t * g_t $$\n",
    "\n",
    "If you're familiar with gradient calculus, you'll see that the gradients for $ c_t $ propagate straight back to the gradients for $ c_{t-1} $. Therefore, the gradient of the initial timestep keeps increasing: since $ c_0 $ influences $ c_1 $, which in turn influences $ c_2 $, and so on, the influence of the initial state never disappears.\n",
    "\n",
    "Of course, this can be a mixed blessing: sometimes we don't want the current timestep to influence the hidden state 200 steps into the future. Sometimes, we want to \"forget\" the information we learned earlier and overwrite it with what we have newly learned. This is where the forget gate comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning the forget gate on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forget gate was originally proposed in the paper [Learning to Forget: Continual Prediction with LSTM](https://www.semanticscholar.org/paper/Learning-to-Forget%3A-Continual-Prediction-with-LSTM-Gers-Schmidhuber/11540131eae85b2e11d53df7f1360eeb6476e7f4). Let's see how the gradients change when we turn the forget gate on. Adhering to best practices, we'll initialize the bias for the forget gate to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.b_f.data = torch.ones_like(lstm.b_f.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate \n",
    "h_0, c_0 = (torch.zeros(hidden_size, requires_grad=True), \n",
    "            torch.zeros(hidden_size, requires_grad=True))\n",
    "grads = []\n",
    "h_t, c_t = h_0, c_0\n",
    "for t in range(100):\n",
    "    h_t, c_t = lstm_step(\n",
    "        test_embeddings[:, t, :], h_t, c_t,\n",
    "        lstm.W_ii, lstm.W_hi, lstm.b_i,\n",
    "        lstm.W_if, lstm.W_hf, lstm.b_f,\n",
    "        lstm.W_ig, lstm.W_hg, lstm.b_g,\n",
    "        lstm.W_io, lstm.W_ho, lstm.b_o,\n",
    "        use_forget_gate=True,\n",
    "    )\n",
    "    loss = h_t.abs().sum()\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads.append(torch.norm(h_0.grad).item())\n",
    "    h_0.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the gradients decay much more slowly than in the case of the Simple RNN. On the other hand, when we don't initialize the forget gate bias to 1... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.b_f.data = torch.zeros_like(lstm.b_f.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0, c_0 = (torch.zeros(hidden_size, requires_grad=True), \n",
    "            torch.zeros(hidden_size, requires_grad=True))\n",
    "grads = []\n",
    "h_t, c_t = h_0, c_0\n",
    "for t in range(100):\n",
    "    h_t, c_t = lstm_step(\n",
    "        test_embeddings[:, t, :], h_t, c_t,\n",
    "        lstm.W_ii, lstm.W_hi, lstm.b_i,\n",
    "        lstm.W_if, lstm.W_hf, lstm.b_f,\n",
    "        lstm.W_ig, lstm.W_hg, lstm.b_g,\n",
    "        lstm.W_io, lstm.W_ho, lstm.b_o,\n",
    "        use_forget_gate=True,\n",
    "    )\n",
    "    loss = h_t.abs().sum()\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads.append(torch.norm(h_0.grad).item())\n",
    "    h_0.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient decays much more quickly now: this is why initializing the forget gate to 1 is a good idea, at least in the initial stages of training. \n",
    "\n",
    "Now, let's see what happens when we initalize the forget gate to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.b_f.data = -torch.ones_like(lstm.b_f.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate \n",
    "h_0, c_0 = (torch.zeros(hidden_size, requires_grad=True), \n",
    "            torch.zeros(hidden_size, requires_grad=True))\n",
    "grads = []\n",
    "h_t, c_t = h_0, c_0\n",
    "for t in range(100):\n",
    "    h_t, c_t = lstm_step(\n",
    "        test_embeddings[:, t, :], h_t, c_t,\n",
    "        lstm.W_ii, lstm.W_hi, lstm.b_i,\n",
    "        lstm.W_if, lstm.W_hf, lstm.b_f,\n",
    "        lstm.W_ig, lstm.W_hg, lstm.b_g,\n",
    "        lstm.W_io, lstm.W_ho, lstm.b_o,\n",
    "        use_forget_gate=True,\n",
    "    )\n",
    "    loss = h_t.abs().sum()\n",
    "    loss.backward(retain_graph=True)\n",
    "    grads.append(torch.norm(h_0.grad).item())\n",
    "    h_0.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights decay even faster now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked at a lot of charts, but the most important point is that the LSTM basically has control over how much of the gradient to allow to flow through each timestep. This is what makes them so easy to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our LSTM Faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how slow our implementation of the LSTM was slow? Let's see how we can speed it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the code for our LSTM carefully, you'll notice that there is a lot of shared processing that could be batched together. For instance, the input and forget gates are both computed based on a linear transformation of the input and the hidden states.\n",
    "\n",
    "\n",
    "We can group these computations into just two matrix multiplications. The code now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_sz = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        self.weight_ih = Parameter(torch.Tensor(input_sz, hidden_sz * 4))\n",
    "        self.weight_hh = Parameter(torch.Tensor(hidden_sz, hidden_sz * 4))\n",
    "        self.bias = Parameter(torch.Tensor(hidden_sz * 4))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states: Optional[Tuple[torch.Tensor]]=None\n",
    "               ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (torch.zeros(self.hidden_size).to(x.device), \n",
    "                        torch.zeros(self.hidden_size).to(x.device))\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        \n",
    "        HS = self.hidden_size\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            gates = x_t @ self.weight_ih + h_t @ self.weight_hh + self.bias\n",
    "            i_t, f_t, g_t, o_t = (\n",
    "                torch.sigmoid(gates[:, :HS]), # input\n",
    "                torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
    "                torch.tanh(gates[:, HS*2:HS*3]),\n",
    "                torch.sigmoid(gates[:, HS*3:]), # output\n",
    "            )\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = OptimizedLSTM(100, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(5 * 10 * 100).view((5, 10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs, _ = lstm(a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how the training speed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_optimized = LanguageModel(OptimizedLSTM(50, 125), vocab)\n",
    "train(lm_optimized, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is faster now, but still not quite as fast as we might want it to be. To really make our LSTM fast, we'll need to pass it over to CuDNN. But that's a topic for another post/notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
