{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports we need.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensor2tensor as t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable TF Eager execution\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other setup\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some directories\n",
    "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
    "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
    "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
    "checkpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\n",
    "tf.gfile.MakeDirs(data_dir)\n",
    "tf.gfile.MakeDirs(tmp_dir)\n",
    "tf.gfile.MakeDirs(train_dir)\n",
    "tf.gfile.MakeDirs(checkpoint_dir)\n",
    "gs_data_dir = \"gs://tensor2tensor-data\"\n",
    "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Problem is a dataset together with some fixed pre-processing.\n",
    "# It could be a translation dataset with a specific tokenization,\n",
    "# or an image dataset with a specific resolution.\n",
    "#\n",
    "# There are many problems available in Tensor2Tensor\n",
    "print(\"\\n\".join(problems.available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST problem\n",
    "mnist_problem = problems.problem(\"image_mnist\")\n",
    "# The generate_data method of a problem will download data and process it into\n",
    "# a standard format ready for training and evaluation.\n",
    "mnist_problem.generate_data(data_dir, tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see the training MNIST data as Tensors.\n",
    "mnist_example = tfe.Iterator(mnist_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
    "image = mnist_example[\"inputs\"]\n",
    "label = mnist_example[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap('gray'))\n",
    "print(\"Label: %d\" % label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSLATE FROM ENGLISH TO GERMAN WITH PRE_TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the problem\n",
    "ende_problem = problems.problem(\"translate_ende_wmt32k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the vocab file locally so we can encode inputs and decode model outputs\n",
    "# All vocabs are stored on GCS\n",
    "vocab_name = \"vocab.translate_ende_wmt32k.32768.subwords\"\n",
    "vocab_file = os.path.join(gs_data_dir, vocab_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: left off here: how to translate this command-line like line into actual code?\n",
    "!gsutil cp {vocab_file} {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1.0
   },
   "outputs": [],
   "source": [
    "# Get the encoders from the problem\n",
    "encoders = ende_problem.feature_encoders(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1.0
   },
   "outputs": [],
   "source": [
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
    "    return {\"inputs\": batch_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
