{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: \n",
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with\n",
    "# %20Neural%20Networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# note about reproducibility in CUDA: \n",
    "# https://hyp.is/dOiOAAuzEeqcu2OxIZfR4w/pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the spacy models via command line:\n",
    "# conda activate pynlp_env\n",
    "# cd /development/.../NLPStudy/data\n",
    "# python -m spacy download en\n",
    "# python -m spacy download de\n",
    "\n",
    "# Then load the models\n",
    "spacyDE = spacy.load('de')\n",
    "spacyEN = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tokenizer functions\n",
    "# NOTE: reversing due to optimization ease\n",
    "\n",
    "def tokenizeGerman(germanText: str):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (as tokens)\n",
    "    and reverses it\n",
    "    :param germanText: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacyDE.tokenizer(germanText)][::-1]\n",
    "\n",
    "def tokenizeEnglish(englishText: str):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (as tokens)\n",
    "    and reverses it\n",
    "    \n",
    "    :param englishText: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacyEN.tokenizer(englishText)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
