{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Source: [xssChauhan/word2vec] (https://github.com/xssChauhan/word2vec/blob/master/pytorch/CBOW.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "import functools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87bae35d70>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CUDA = torch.cuda.is_available()\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabSize, embeddingSize):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocabSize, embeddingSize)\n",
    "        \n",
    "        #if CUDA: \n",
    "         #   self.embedding = self.embedding.cuda()\n",
    "            \n",
    "        self.hidden = nn.Linear(embeddingSize, vocabSize)\n",
    "        self.op = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p = self.embedding(X.long())\n",
    "        q = torch.mean(p, dim=0).view(1, -1)\n",
    "        r = self.hidden(q)\n",
    "        s = self.op(r)\n",
    "        \n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToTrain(text, contextWindowSize):\n",
    "    \"\"\"\n",
    "    Convert text to data for training CBOW model\n",
    "    :param text: \n",
    "    :param contextWindowSize: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for i in range(contextWindowSize, len(text) - contextWindowSize):\n",
    "        # creating context as words around the target\n",
    "        context = [\n",
    "            text[i + e] for e in range(-contextWindowSize, contextWindowSize + 1) \n",
    "            if i+e != i\n",
    "        ]\n",
    "        # target as the word at (i) in text\n",
    "        target = text[i]\n",
    "        \n",
    "        data.append((context, target))\n",
    "        \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for text excerpt: \n",
    "# https://www.advancedwriters.com/blog/descriptive-essay-on-nature/\n",
    "\n",
    "text = '''Man has appreciated nature and still does. He is both challenged \n",
    "and pacified by it. Not only is nature beautiful, it is every changing through \n",
    "different seasons, or timelessly unchanged in it fixed elements such as its \n",
    "great mountain ranges. It has a wild beauty to it. There is a valley in central \n",
    "Africa that when you are there it seems as if you went back in time. This is \n",
    "the Zambezi river valley that starts in the wetlands of the Okavango swamps. \n",
    "The valley is 1500 miles of wilderness, totally unspoiled by man’s encroachment. \n",
    "You see only the wildness of nature. The river flows proudly through the valley. \n",
    "It is a surging force as it goes through rocky rapids, or wide and tranquil where \n",
    "it finds space. On its banks are mud flats and reeds, where crocodiles lie in the sun, \n",
    "and further away dense trees and forests of Mopani trees, interspersed with huge grey \n",
    "prehistoric baobab trees with branches that look like roots. In the day, the sun is a \n",
    "burning yellow fire, and everything wilts under it. Even the wild life finds shade and \n",
    "lies down. As the evening comes the setting sun paints the sky with streaks of pink and \n",
    "orange, and the animals emerge.\n",
    "\n",
    "They come individually or in groups. In the water large hippopotamus frolic, \n",
    "not intimidated by the presence of crocodiles. Nervous buck come dancing to \n",
    "the river.\n",
    "\n",
    "Large tan colored kudu, as tall as a horse, with their white flashes and meter \n",
    "long spiral horns, smaller dark brown impala with short spiked horns, tiny \n",
    "brown duiker.\n",
    "\n",
    "They carefully approach; stopping to be sure, no predators are near. They dip \n",
    "their heads gracefully to drink. Some suddenly will jump and struggle as a \n",
    "crocodile grabs it and drags it under the water. Elephants come and splash \n",
    "around squirting water over themselves with their long trunks, or rolling in \n",
    "the mud, which is to them a treat.\n",
    "\n",
    "Lions eventually arrive in a pride, causing the buck to move nervously away. \n",
    "The dusk gives way to the sudden blackness of the night sky studded with silver \n",
    "stars and a huge silver moon. Soon the animals were gone; the river flows on \n",
    "into the night.\n",
    "\n",
    "Not far away there was a noise like thunder that sounded constantly. In the \n",
    "early morning, flowing the river alive and sparkling in the sun, crocodiles \n",
    "basking in the warmth, animals drinking while it was still cool, the river \n",
    "broadened and flowed in channels around green islands. Then it fell down a \n",
    "100-meter chasm as a magnificent waterfall, 1708 meters wide. As the river \n",
    "fell down the chasm the sound was as thunder, and water spray rose high in \n",
    "the sky, white like the smoke of a bush fire. The bush is like a tropical \n",
    "forest as the spray rains down on it continually, and it is untouched by man. \n",
    "From here, it flows into a great lake and thence to the Indian Ocean.'''\\\n",
    "    .lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(text)\n",
    "wordToIndex = {w:i for i, w in enumerate(vocabulary)}\n",
    "indexToWord = {i:w for i, w in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'struggle': 0, 'under': 1, 'around': 2, 'then': 3, 'man.': 4, 'heads': 5, 'sound': 6, 'man': 7, 'lies': 8, 'setting': 9, 'baobab': 10, 'sky': 11, 'blackness': 12, 'individually': 13, 'wide.': 14, 'does.': 15, 'green': 16, 'went': 17, 'pride,': 18, 'lake': 19, 'dark': 20, 'swamps.': 21, 'rose': 22, 'squirting': 23, 'this': 24, 'mud,': 25, 'as': 26, 'and': 27, 'africa': 28, 'emerge.': 29, 'move': 30, 'presence': 31, 'fixed': 32, 'buck': 33, 'look': 34, 'far': 35, 'yellow': 36, 'changing': 37, 'zambezi': 38, 'further': 39, 'it.': 40, 'drink.': 41, 'wide': 42, 'man’s': 43, 'such': 44, 'smaller': 45, 'jump': 46, 'it': 47, 'horse,': 48, 'sounded': 49, 'water.': 50, 'indian': 51, 'dusk': 52, 'nervously': 53, '100-meter': 54, 'where': 55, 'will': 56, 'gives': 57, 'chasm': 58, 'streaks': 59, 'unchanged': 60, 'mountain': 61, 'rocky': 62, 'white': 63, 'goes': 64, 'comes': 65, 'crocodiles': 66, 'they': 67, 'groups.': 68, 'colored': 69, 'treat.': 70, 'while': 71, 'timelessly': 72, 'from': 73, 'surging': 74, 'silver': 75, 'prehistoric': 76, 'miles': 77, 'even': 78, 'sudden': 79, 'life': 80, 'sky,': 81, 'gone;': 82, 'trunks,': 83, 'arrive': 84, 'moon.': 85, 'drags': 86, 'every': 87, 'thunder': 88, 'branches': 89, 'causing': 90, 'come': 91, 'duiker.': 92, 'still': 93, 'long': 94, 'dancing': 95, 'banks': 96, 'some': 97, 'way': 98, 'reeds,': 99, 'sun': 100, 'through': 101, 'thunder,': 102, 'wildness': 103, 'evening': 104, 'animals': 105, 'wilts': 106, 'bush': 107, 'river': 108, 'early': 109, 'appreciated': 110, 'wilderness,': 111, 'ocean.': 112, 'rains': 113, 'hippopotamus': 114, 'cool,': 115, 'shade': 116, 'was': 117, 'dense': 118, 'wetlands': 119, 'sparkling': 120, 'spiral': 121, 'themselves': 122, 'elephants': 123, 'see': 124, 'gracefully': 125, 'pink': 126, 'time.': 127, 'lions': 128, 'kudu,': 129, 'great': 130, 'intimidated': 131, 'ranges.': 132, 'splash': 133, '1500': 134, 'fire.': 135, 'in': 136, 'drinking': 137, 'are': 138, 'nature': 139, 'near.': 140, 'meters': 141, 'mud': 142, 'approach;': 143, 'rolling': 144, 'to': 145, 'challenged': 146, 'tall': 147, 'flowing': 148, 'crocodile': 149, 'lie': 150, 'or': 151, 'warmth,': 152, 'carefully': 153, 'into': 154, 'down': 155, 'high': 156, 'away.': 157, 'paints': 158, 'flows': 159, 'river.': 160, 'studded': 161, 'trees,': 162, 'no': 163, 'sure,': 164, 'impala': 165, 'not': 166, 'soon': 167, 'mopani': 168, 'alive': 169, 'elements': 170, 'be': 171, 'flowed': 172, 'constantly.': 173, 'is': 174, 'only': 175, 'nature.': 176, 'back': 177, 'wild': 178, 'orange,': 179, 'crocodiles.': 180, 'seasons,': 181, 'horns,': 182, 'fire,': 183, 'their': 184, 'unspoiled': 185, 'a': 186, 'eventually': 187, 'sun,': 188, 'nervous': 189, 'suddenly': 190, 'spray': 191, 'continually,': 192, 'there': 193, 'interspersed': 194, 'beauty': 195, 'burning': 196, 'day,': 197, 'the': 198, 'islands.': 199, 'magnificent': 200, 'untouched': 201, 'starts': 202, 'rapids,': 203, 'seems': 204, 'everything': 205, 'he': 206, 'you': 207, 'stopping': 208, 'here,': 209, 'has': 210, 'tropical': 211, 'them': 212, 'basking': 213, 'encroachment.': 214, 'forests': 215, 'channels': 216, 'forest': 217, 'that': 218, 'flats': 219, 'which': 220, 'huge': 221, 'noise': 222, 'stars': 223, 'okavango': 224, 'meter': 225, 'grey': 226, 'pacified': 227, 'waterfall,': 228, 'brown': 229, 'if': 230, 'short': 231, 'valley.': 232, 'proudly': 233, 'thence': 234, 'like': 235, 'dip': 236, 'over': 237, 'morning,': 238, 'force': 239, 'with': 240, 'frolic,': 241, 'grabs': 242, 'totally': 243, 'both': 244, 'beautiful,': 245, 'on': 246, 'valley': 247, 'central': 248, 'space.': 249, 'down.': 250, 'night': 251, 'water': 252, 'finds': 253, 'of': 254, 'large': 255, 'flashes': 256, 'spiked': 257, 'predators': 258, 'were': 259, 'away': 260, 'roots.': 261, 'broadened': 262, 'fell': 263, 'tranquil': 264, '1708': 265, 'by': 266, 'different': 267, 'its': 268, 'tan': 269, 'tiny': 270, 'smoke': 271, 'night.': 272, 'trees': 273, 'when': 274}\n"
     ]
    }
   ],
   "source": [
    "print(wordToIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = textToTrain(text=text, contextWindowSize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['man', 'has', 'nature', 'and'], 'appreciated'),\n (['has', 'appreciated', 'and', 'still'], 'nature'),\n (['appreciated', 'nature', 'still', 'does.'], 'and'),\n (['nature', 'and', 'does.', 'he'], 'still'),\n (['and', 'still', 'he', 'is'], 'does.'),\n (['still', 'does.', 'is', 'both'], 'he'),\n (['does.', 'he', 'both', 'challenged'], 'is'),\n (['he', 'is', 'challenged', 'and'], 'both'),\n (['is', 'both', 'and', 'pacified'], 'challenged'),\n (['both', 'challenged', 'pacified', 'by'], 'and')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "# these are (context, target) tuples in a list\n",
    "data[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsToTensor(words: list, wordToIndexMap: dict, dtype=torch.FloatTensor):\n",
    "    tensor = dtype([\n",
    "        wordToIndexMap[word] for word in words\n",
    "    ])\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(contextList, model):\n",
    "    model.eval()\n",
    "    prediction = model(wordsToTensor(contextList, wordToIndex))\n",
    "    _, index = torch.max(prediction, 1)\n",
    "\n",
    "    # NOTE: Error resolved by changing loss.data[0] to loss.item(), and replacing\n",
    "    # the .data[0] with .item() everywhere else in the code\n",
    "    # SOURCE: https://github.com/NVIDIA/flownet2-pytorch/issues/113\n",
    "    return indexToWord[index.item()] # indexToWord[index.data[0]]\n",
    "\n",
    "def checkAccuracy(model):\n",
    "    numCorrect = 0\n",
    "    for contextList, targetWord in data:\n",
    "        prediction = getPrediction(contextList, model)\n",
    "        if prediction == targetWord:\n",
    "            numCorrect += 1\n",
    "            \n",
    "    return numCorrect / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['man', 'has', 'nature', 'and'], 'appreciated')\ntensor([  7., 210., 139.,  27.])\ntensor([110])\ntensor([[-6.6626, -7.5048, -6.3472, -8.8201, -6.9979, -8.0495, -7.7435, -7.8967,\n         -5.9469, -7.2949, -7.0512, -7.4076, -7.9928, -8.9345, -6.6752, -6.1814,\n         -9.0166, -6.9659, -6.5144, -6.6812, -9.0080, -7.7968, -7.1836, -8.2614,\n         -7.8087, -7.7930, -5.9665, -4.8754, -7.5667, -8.5778, -8.9795, -8.2457,\n         -7.8315, -7.8619, -8.5298, -8.0343, -7.2662, -7.3466, -7.7854, -5.4574,\n         -6.7498, -8.4609, -6.6493, -7.1231, -8.5144, -8.8930, -6.3118, -1.3392,\n         -7.1463, -6.7795, -7.9025, -7.8686, -8.0860, -8.4196, -7.5942, -5.4370,\n         -7.4890, -7.6500, -8.7163, -8.5615, -7.8602, -9.2361, -7.7226, -5.2372,\n         -7.7405, -8.8564, -7.5169, -7.6705, -8.1726, -9.0716, -8.5006, -9.2522,\n         -7.0452, -8.6023, -8.0439, -5.6648, -7.9925, -8.3382, -7.6922, -9.0511,\n         -7.0260, -8.3863, -8.3005, -7.1287, -8.1380, -7.1253, -6.6792, -8.0237,\n         -7.4358, -7.3635, -8.7728, -7.8642, -9.4549, -4.8625, -6.1363, -9.0810,\n         -8.4673, -8.4292, -8.1445, -6.6173, -8.2940, -7.3369, -6.3167, -6.8614,\n         -7.5214, -6.8460, -5.8583, -8.9914, -4.6838, -7.6270, -0.8138, -8.3400,\n         -8.4966, -7.8882, -8.2730, -8.1945, -6.0910, -8.4748, -6.5363, -7.6372,\n         -5.3902, -7.1454, -7.9329, -5.5120, -6.3671, -7.9437, -7.3085, -7.3307,\n         -9.4126, -8.0127, -7.5637, -8.6660, -6.2739, -6.3454, -7.6671, -8.9017,\n         -7.3216, -9.2980, -7.7193, -4.1568, -8.2573, -7.7865, -5.8444, -8.4951,\n         -8.0312, -7.2743, -5.5254, -8.4508, -8.1468, -7.7011, -7.3236, -5.1958,\n         -7.4162, -8.0447, -8.5835, -8.3270, -7.6322, -8.5622, -9.1342, -7.6303,\n         -8.9333, -7.4510, -8.0109, -8.2809, -8.5328, -8.1926, -9.3291, -7.0899,\n         -8.1123, -5.5992, -7.7245, -8.7180, -5.2787, -7.1079, -8.7052, -6.4641,\n         -7.6471, -8.2748, -6.9821, -5.2265, -8.4821, -7.4945, -7.8969, -5.5824,\n         -7.8113, -9.5383, -4.1243, -8.3597, -6.6971, -8.5079, -8.1067, -5.8837,\n         -7.0770, -8.8737, -7.8047, -8.1046, -8.2886, -7.1581, -7.8587, -8.4327,\n         -7.6603, -9.5107, -7.2079, -7.7046, -8.0021, -5.6474, -7.1073, -6.5230,\n         -7.9413, -8.0755, -9.4959, -8.1125, -8.8021, -7.6883, -7.8837, -5.7686,\n         -7.6498, -7.9028, -5.2589, -6.5891, -7.7497, -4.9494, -8.6232, -5.3116,\n         -7.9666, -5.7100, -7.8715, -7.2793, -6.7145, -8.9384, -7.8027, -7.5729,\n         -7.8905, -7.6985, -6.8872, -8.1020, -7.3889, -7.7342, -8.6498, -8.5224,\n         -8.2844, -9.0322, -7.2552, -8.7627, -6.2115, -6.3543, -7.9024, -8.1707,\n         -7.2461, -8.6175, -5.2348, -8.2440, -7.0263, -7.1937, -6.7200, -7.9818,\n         -5.9080, -8.1102, -7.9973, -7.4165, -6.9318, -7.7399, -6.0932, -8.2426,\n         -6.0600, -7.4512, -8.0324, -8.1086, -7.6251, -7.8946, -7.0750, -8.5069,\n         -8.9796, -5.3289, -7.2722]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "contextList_0, targetWord_0 = data[0]\n",
    "print(data[0])\n",
    "\n",
    "ids_0 = wordsToTensor(contextList_0, wordToIndex)\n",
    "print(ids_0)\n",
    "\n",
    "tensorTarget_0 = wordsToTensor([targetWord_0], wordToIndex, dtype=torch.LongTensor)\n",
    "print(tensorTarget_0)\n",
    "\n",
    "output_0 = model(ids_0)\n",
    "print(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 0 is 0.006134969325153374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 100 is 0.310838445807771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 200 is 0.7300613496932515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 300 is 0.9325153374233128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 400 is 0.9713701431492843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 500 is 0.9897750511247444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 600 is 0.9918200408997955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 700 is 0.9979550102249489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 800 is 0.9979550102249489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 900 is 1.0\n"
     ]
    }
   ],
   "source": [
    "### Training the model\n",
    "\n",
    "learningRate = 0.001\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "model = CBOW(vocabSize = len(vocabulary), embeddingSize=100)\n",
    "\n",
    "lossFunction = torch.nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learningRate)\n",
    "losses = []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    totalLoss = 0\n",
    "    \n",
    "    for contextList, targetWord in data:\n",
    "        ids = wordsToTensor(contextList, wordToIndex)\n",
    "        targetTensor = wordsToTensor([targetWord], wordToIndex, \n",
    "                                   dtype=torch.LongTensor)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output = model(ids)\n",
    "        \n",
    "        loss = lossFunction(output, targetTensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # NOTE: Error resolved by changing loss.data[0] to loss.item(), and replacing\n",
    "        # the .data[0] with .item() everywhere else in the code\n",
    "        # SOURCE: https://github.com/NVIDIA/flownet2-pytorch/issues/113\n",
    "        totalLoss += loss.item()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        accuracy = checkAccuracy(model)\n",
    "        print(\"Accuracy after epoch {} is {}\".format(epoch, accuracy))\n",
    "        \n",
    "    losses.append(totalLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLosses(lossesList):\n",
    "    fig, ax = plt.subplots(facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_title('Losses per Epoch')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.plot(lossesList)\n",
    "    plt.show()\n",
    "\n",
    "plotLosses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
