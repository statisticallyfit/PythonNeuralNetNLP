{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Source: [xssChauhan/word2vec] (https://github.com/xssChauhan/word2vec/blob/master/pytorch/CBOW.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "import functools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabSize, embeddingSize):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocabSize, embeddingSize)\n",
    "        \n",
    "        if CUDA: \n",
    "            self.embedding = self.embedding.cuda()\n",
    "            \n",
    "        self.hidden = nn.Linear(embeddingSize, vocabSize)\n",
    "        self.op = nn.LogSoftmax\n",
    "        \n",
    "    def forward(self, X):\n",
    "        p = self.embedding(X.long())\n",
    "        q = torch.mean(p, dim=0).view(1, -1)\n",
    "        r = self.hidden(q)\n",
    "        s = self.op(r)\n",
    "        \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToTrain(text, contextWindowSize):\n",
    "    \"\"\"\n",
    "    Convert text to data for training CBOW model\n",
    "    :param text: \n",
    "    :param contextWindowSize: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for i in range(contextWindowSize, len(text) - contextWindowSize):\n",
    "        # creating context as words around the target\n",
    "        context = [\n",
    "            text[i + e] for e in range(-contextWindowSize, contextWindowSize + 1) \n",
    "            if i+e != i\n",
    "        ]\n",
    "        # target as the word at (i) in text\n",
    "        target = text[i]\n",
    "        \n",
    "        data.append((context, target))\n",
    "        \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for text excerpt: \n",
    "# https://www.advancedwriters.com/blog/descriptive-essay-on-nature/\n",
    "\n",
    "text = '''Man has appreciated nature and still does. He is both challenged \n",
    "and pacified by it. Not only is nature beautiful, it is every changing through \n",
    "different seasons, or timelessly unchanged in it fixed elements such as its \n",
    "great mountain ranges. It has a wild beauty to it. There is a valley in central \n",
    "Africa that when you are there it seems as if you went back in time. This is \n",
    "the Zambezi river valley that starts in the wetlands of the Okavango swamps. \n",
    "The valley is 1500 miles of wilderness, totally unspoiled by man’s encroachment. You see only the wildness of nature. The river flows proudly through the valley. It is a surging force as it goes through rocky rapids, or wide and tranquil where it finds space. On its banks are mud flats and reeds, where crocodiles lie in the sun, and further away dense trees and forests of Mopani trees, interspersed with huge grey prehistoric baobab trees with branches that look like roots. In the day, the sun is a burning yellow fire, and everything wilts under it. Even the wild life finds shade and lies down. As the evening comes the setting sun paints the sky with streaks of pink and orange, and the animals emerge.\n",
    "\n",
    "They come individually or in groups. In the water large hippopotamus frolic, \n",
    "not intimidated by the presence of crocodiles. Nervous buck come dancing to \n",
    "the river.\n",
    "\n",
    "Large tan colored kudu, as tall as a horse, with their white flashes and meter \n",
    "long spiral horns, smaller dark brown impala with short spiked horns, tiny \n",
    "brown duiker.\n",
    "\n",
    "They carefully approach; stopping to be sure, no predators are near. They dip \n",
    "their heads gracefully to drink. Some suddenly will jump and struggle as a \n",
    "crocodile grabs it and drags it under the water. Elephants come and splash \n",
    "around squirting water over themselves with their long trunks, or rolling in \n",
    "the mud, which is to them a treat.\n",
    "\n",
    "Lions eventually arrive in a pride, causing the buck to move nervously away. \n",
    "The dusk gives way to the sudden blackness of the night sky studded with silver \n",
    "stars and a huge silver moon. Soon the animals were gone; the river flows on \n",
    "into the night.\n",
    "\n",
    "Not far away there was a noise like thunder that sounded constantly. In the \n",
    "early morning, flowing the river alive and sparkling in the sun, crocodiles \n",
    "basking in the warmth, animals drinking while it was still cool, the river \n",
    "broadened and flowed in channels around green islands. Then it fell down a \n",
    "100-meter chasm as a magnificent waterfall, 1708 meters wide. As the river \n",
    "fell down the chasm the sound was as thunder, and water spray rose high in \n",
    "the sky, white like the smoke of a bush fire. The bush is like a tropical \n",
    "forest as the spray rains down on it continually, and it is untouched by man. \n",
    "From here, it flows into a great lake and thence to the Indian Ocean.'''\\\n",
    "    .lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(text)\n",
    "wordToIndex = {w:i for i, w in enumerate(vocabulary)}\n",
    "indexToWord = {i:w for i, w in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'struggle': 0, 'under': 1, 'around': 2, 'then': 3, 'man.': 4, 'heads': 5, 'sound': 6, 'man': 7, 'lies': 8, 'setting': 9, 'baobab': 10, 'sky': 11, 'blackness': 12, 'individually': 13, 'wide.': 14, 'does.': 15, 'green': 16, 'went': 17, 'pride,': 18, 'lake': 19, 'dark': 20, 'swamps.': 21, 'rose': 22, 'squirting': 23, 'this': 24, 'mud,': 25, 'as': 26, 'and': 27, 'africa': 28, 'emerge.': 29, 'move': 30, 'presence': 31, 'fixed': 32, 'buck': 33, 'look': 34, 'far': 35, 'yellow': 36, 'changing': 37, 'zambezi': 38, 'further': 39, 'it.': 40, 'drink.': 41, 'wide': 42, 'man’s': 43, 'such': 44, 'smaller': 45, 'jump': 46, 'it': 47, 'horse,': 48, 'sounded': 49, 'water.': 50, 'indian': 51, 'dusk': 52, 'nervously': 53, '100-meter': 54, 'where': 55, 'will': 56, 'gives': 57, 'chasm': 58, 'streaks': 59, 'unchanged': 60, 'mountain': 61, 'rocky': 62, 'white': 63, 'goes': 64, 'comes': 65, 'crocodiles': 66, 'they': 67, 'groups.': 68, 'colored': 69, 'treat.': 70, 'while': 71, 'timelessly': 72, 'from': 73, 'surging': 74, 'silver': 75, 'prehistoric': 76, 'miles': 77, 'even': 78, 'sudden': 79, 'life': 80, 'sky,': 81, 'gone;': 82, 'trunks,': 83, 'arrive': 84, 'moon.': 85, 'drags': 86, 'every': 87, 'thunder': 88, 'branches': 89, 'causing': 90, 'come': 91, 'duiker.': 92, 'still': 93, 'long': 94, 'dancing': 95, 'banks': 96, 'some': 97, 'way': 98, 'reeds,': 99, 'sun': 100, 'through': 101, 'thunder,': 102, 'wildness': 103, 'evening': 104, 'animals': 105, 'wilts': 106, 'bush': 107, 'river': 108, 'early': 109, 'appreciated': 110, 'wilderness,': 111, 'ocean.': 112, 'rains': 113, 'hippopotamus': 114, 'cool,': 115, 'shade': 116, 'was': 117, 'dense': 118, 'wetlands': 119, 'sparkling': 120, 'spiral': 121, 'themselves': 122, 'elephants': 123, 'see': 124, 'gracefully': 125, 'pink': 126, 'time.': 127, 'lions': 128, 'kudu,': 129, 'great': 130, 'intimidated': 131, 'ranges.': 132, 'splash': 133, '1500': 134, 'fire.': 135, 'in': 136, 'drinking': 137, 'are': 138, 'nature': 139, 'near.': 140, 'meters': 141, 'mud': 142, 'approach;': 143, 'rolling': 144, 'to': 145, 'challenged': 146, 'tall': 147, 'flowing': 148, 'crocodile': 149, 'lie': 150, 'or': 151, 'warmth,': 152, 'carefully': 153, 'into': 154, 'down': 155, 'high': 156, 'away.': 157, 'paints': 158, 'flows': 159, 'river.': 160, 'studded': 161, 'trees,': 162, 'no': 163, 'sure,': 164, 'impala': 165, 'not': 166, 'soon': 167, 'mopani': 168, 'alive': 169, 'elements': 170, 'be': 171, 'flowed': 172, 'constantly.': 173, 'is': 174, 'only': 175, 'nature.': 176, 'back': 177, 'wild': 178, 'orange,': 179, 'crocodiles.': 180, 'seasons,': 181, 'horns,': 182, 'fire,': 183, 'their': 184, 'unspoiled': 185, 'a': 186, 'eventually': 187, 'sun,': 188, 'nervous': 189, 'suddenly': 190, 'spray': 191, 'continually,': 192, 'there': 193, 'interspersed': 194, 'beauty': 195, 'burning': 196, 'day,': 197, 'the': 198, 'islands.': 199, 'magnificent': 200, 'untouched': 201, 'starts': 202, 'rapids,': 203, 'seems': 204, 'everything': 205, 'he': 206, 'you': 207, 'stopping': 208, 'here,': 209, 'has': 210, 'tropical': 211, 'them': 212, 'basking': 213, 'encroachment.': 214, 'forests': 215, 'channels': 216, 'forest': 217, 'that': 218, 'flats': 219, 'which': 220, 'huge': 221, 'noise': 222, 'stars': 223, 'okavango': 224, 'meter': 225, 'grey': 226, 'pacified': 227, 'waterfall,': 228, 'brown': 229, 'if': 230, 'short': 231, 'valley.': 232, 'proudly': 233, 'thence': 234, 'like': 235, 'dip': 236, 'over': 237, 'morning,': 238, 'force': 239, 'with': 240, 'frolic,': 241, 'grabs': 242, 'totally': 243, 'both': 244, 'beautiful,': 245, 'on': 246, 'valley': 247, 'central': 248, 'space.': 249, 'down.': 250, 'night': 251, 'water': 252, 'finds': 253, 'of': 254, 'large': 255, 'flashes': 256, 'spiked': 257, 'predators': 258, 'were': 259, 'away': 260, 'roots.': 261, 'broadened': 262, 'fell': 263, 'tranquil': 264, '1708': 265, 'by': 266, 'different': 267, 'its': 268, 'tan': 269, 'tiny': 270, 'smoke': 271, 'night.': 272, 'trees': 273, 'when': 274}\n"
     ]
    }
   ],
   "source": [
    "print(wordToIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = textToTrain(text=text, contextWindowSize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['man', 'has', 'nature', 'and'], 'appreciated'),\n (['has', 'appreciated', 'and', 'still'], 'nature'),\n (['appreciated', 'nature', 'still', 'does.'], 'and'),\n (['nature', 'and', 'does.', 'he'], 'still'),\n (['and', 'still', 'he', 'is'], 'does.'),\n (['still', 'does.', 'is', 'both'], 'he'),\n (['does.', 'he', 'both', 'challenged'], 'is'),\n (['he', 'is', 'challenged', 'and'], 'both'),\n (['is', 'both', 'and', 'pacified'], 'challenged'),\n (['both', 'challenged', 'pacified', 'by'], 'and')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "# these are (context, target) tuples in a list\n",
    "data[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsToTensor(words: list, wordToIndexMap: dict, dtype=torch.FloatTensor):\n",
    "    tensor = dtype([\n",
    "        wordToIndexMap[word] for word in words\n",
    "    ])\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(contextList, model):\n",
    "    model.eval()\n",
    "    prediction = model(wordsToTensor(contextList, wordToIndex))\n",
    "    _, index = torch.max(prediction, 1)\n",
    "    \n",
    "    return indexToWord[index.data[0]]\n",
    "\n",
    "def checkAccuracy(model):\n",
    "    numCorrect = 0\n",
    "    for contextList, targetWord in data:\n",
    "        prediction = getPrediction(contextList, model)\n",
    "        if prediction == targetWord:\n",
    "            numCorrect += 1\n",
    "            \n",
    "    return numCorrect / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['man', 'has', 'nature', 'and'], 'appreciated')\ntensor([  7., 210., 139.,  27.])\ntensor([110])\nLogSoftmax()\n"
     ]
    }
   ],
   "source": [
    "contextList_0, targetWord_0 = data[0]\n",
    "print(data[0])\n",
    "\n",
    "ids_0 = wordsToTensor(contextList_0, wordToIndex)\n",
    "print(ids_0)\n",
    "\n",
    "tensorTarget_0 = wordsToTensor([targetWord_0], wordToIndex, dtype=torch.LongTensor)\n",
    "print(tensorTarget_0)\n",
    "\n",
    "output_0 = model(ids_0)\n",
    "print(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4196fda58e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/development/bin/python/conda3_ana/envs/pynlp_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "### Training the model\n",
    "\n",
    "learningRate = 0.001\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "model = CBOW(vocabSize = len(vocabulary), embeddingSize=100)\n",
    "\n",
    "lossFunction = torch.nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learningRate)\n",
    "losses = []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    totalLoss = 0\n",
    "    \n",
    "    for contextList, targetWord in data:\n",
    "        ids = wordsToTensor(contextList, wordToIndex)\n",
    "        targetTensor = wordsToTensor([targetWord], wordToIndex, \n",
    "                                   dtype=torch.LongTensor)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output = model(ids)\n",
    "        \n",
    "        loss = lossFunction(output, targetTensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        totalLoss += loss.data[0]\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        accuracy = checkAccuracy(model)\n",
    "        print(\"Accuracy after epoch {} is {}\".format(epoch, accuracy))\n",
    "        \n",
    "    losses.append(totalLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
