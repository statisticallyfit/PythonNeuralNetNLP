{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Tutorial 2: Tagging your Text\n",
    "## Tagging with Pre-Trained Sequence Tagging Models\n",
    "Using a pre-trained model for named entity recognition (NER), trained over the English CoNLL-03 task , and can recognize 4 different entity types. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/development/bin/python/miniconda3/envs/pynlp_clone_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence \n",
    "from flair.models import MultiTagger\n",
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SegtokSentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:40:46,724 loading file /home/statisticallyfit/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "tagger: SequenceTagger = SequenceTagger.load(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): WordEmbeddings('/home/aakbik/.flair/embeddings/glove.gensim')\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Using the `predict()` method of the tagger on a sentence will add predicted tags to the tokens in the sentence. \n",
    "\n",
    "Using a sentence with two named entities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = Sentence(\"George Washington went to Washington.\")\n",
    "\n",
    "# Predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Getting Annotated Spans\n",
    "Many sequence labeling methods annotate spans that consist of multiple words like \"George Washington\" in the example sentence. \n",
    "\n",
    "To directly get such spans in a tagged sentence, do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [1,2]: \"George Washington\"   [− Labels: PER (0.9968)]\n",
      "Span [5]: \"Washington\"   [− Labels: LOC (0.9994)]\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans(\"ner\"):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Another (longer) Example for Getting Annotated Spans: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"When she does n't answer , I fugre there 's no more point in conversation . I steer her toward the kitchens . We 'll have to pass by guards ; there 's no other way out . She has pasted on a horrible rictus of a smile , but at least she has enough self-possession for that . More worrying is the way she ca n't stop staring at things . As we walkt toward the guards , the intensity of her gaze is impossible to disguise . I improvise , trying to sound as though I am reciting a memorized message , without inflection in the words . ' Prince Cardan says we are to attend him . ' One of the guards turns to the other . ' Balekin wo n't like that . ' I try not to react , but it 's hard . I just stand there and wait . If they lunge at us , I am going to have to kill them . ' Very well ,' the first guard says . ' Go . But inform Cardan that his brother demands he brings both of you back this time . '\"   [− Tokens: 200]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folkAirSentence = Sentence(\"When she doesn't answer, I fugre there's no more point in conversation. I steer her toward the kitchens. We'll have to pass by guards; there's no other way out. She has pasted on a horrible rictus of a smile, but at least she has enough self-possession for that. More worrying is the way she can't stop staring at things. As we walkt toward the guards, the intensity of her gaze is impossible to disguise. I improvise, trying to sound as though I am reciting a memorized message, without inflection in the words. 'Prince Cardan says we are to attend him.' One of the guards turns to the other. 'Balekin won't like that.' I try not to react, but it's hard. I just stand there and wait. If they lunge at us, I am going to have to kill them. 'Very well,' the first guard says. 'Go. But inform Cardan that his brother demands he brings both of you back this time.' \")\n",
    "\n",
    "folkAirSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When she does n't answer , I fugre there 's no more point in conversation . I steer her toward the kitchens . We 'll have to pass by guards ; there 's no other way out . She has pasted on a horrible rictus of a smile , but at least she has enough self-possession for that . More worrying is the way she ca n't stop staring at things . As we walkt toward the guards , the intensity of her gaze is impossible to disguise . I improvise , trying to sound as though I am reciting a memorized message , without inflection in the words . ' Prince Cardan <S-PER> says we are to attend him . ' One of the guards turns to the other . ' Balekin <S-PER> wo n't like that . ' I try not to react , but it 's hard . I just stand there and wait . If they lunge at us , I am going to have to kill them . ' Very well ,' the first guard says . ' Go . But inform Cardan <S-PER> that his brother demands he brings both of you back this time . '\n"
     ]
    }
   ],
   "source": [
    "tagger.predict(folkAirSentence)\n",
    "print(folkAirSentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [113]: \"Cardan\"   [− Labels: PER (0.9991)]\n",
      "Span [132]: \"Balekin\"   [− Labels: PER (0.9969)]\n",
      "Span [186]: \"Cardan\"   [− Labels: PER (0.9679)]\n"
     ]
    }
   ],
   "source": [
    "# Getting the annotated spans: \n",
    "for entity in folkAirSentence.get_spans(\"ner\"):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"When she doesn't answer, I fugre there's no more point in conversation. I steer her toward the kitchens. We'll have to pass by guards; there's no other way out. She has pasted on a horrible rictus of a smile, but at least she has enough self-possession for that. More worrying is the way she can't stop staring at things. As we walkt toward the guards, the intensity of her gaze is impossible to disguise. I improvise, trying to sound as though I am reciting a memorized message, without inflection in the words. 'Prince Cardan says we are to attend him.' One of the guards turns to the other. 'Balekin won't like that.' I try not to react, but it's hard. I just stand there and wait. If they lunge at us, I am going to have to kill them. 'Very well,' the first guard says. 'Go. But inform Cardan that his brother demands he brings both of you back this time.'\", 'labels': [], 'entities': [{'text': 'Cardan', 'start_pos': 521, 'end_pos': 527, 'labels': [PER (0.9991)]}, {'text': 'Balekin', 'start_pos': 595, 'end_pos': 602, 'labels': [PER (0.9969)]}, {'text': 'Cardan', 'start_pos': 790, 'end_pos': 796, 'labels': [PER (0.9679)]}]}\n"
     ]
    }
   ],
   "source": [
    "print(folkAirSentence.to_dict(tag_type = \"ner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Hemalurgy <S-LOC> , the type of metal used in a spike is important , as is the positioning of that spike on the body . For instance , steel spikes take physical Allomantic <S-MISC> powers — the ability to burn pewter , tin , steel , or iron — and bestow them upon the person receiving the spike . Which of these four is granted , however , depends on where the spike is placed . Spikes made from other metals steal Feruchemical <S-MISC> abilities . For example , all of the original Inquisitors were given a pewter spike , which — after first being pounded through the body of a Feruchemist <S-MISC> — gave the Inquisitor <S-ORG> the ability to store up healing power . ( Though they could n't do so as quickly as a real Feruchemist <S-MISC> , as per the law of Hemalurgic <S-MISC> decay . ) This , obviously , is where the Inquisitors got their infamous ability to recover from wounds quickly , and was also why they needed to rest so much .\n"
     ]
    }
   ],
   "source": [
    "mistbornSentence = Sentence(\"In Hemalurgy, the type of metal used in a spike is important, as is the positioning of that spike on the body. For instance, steel spikes take physical Allomantic powers—the ability to burn pewter, tin, steel, or iron—and bestow them upon the person receiving the spike. Which of these four is granted, however, depends on where the spike is placed. Spikes made from other metals steal Feruchemical abilities. For example, all of the original Inquisitors were given a pewter spike, which—after first being pounded through the body of a Feruchemist—gave the Inquisitor the ability to store up healing power. (Though they couldn't do so as quickly as a real Feruchemist, as per the law of Hemalurgic decay.) This, obviously, is where the Inquisitors got their infamous ability to recover from wounds quickly, and was also why they needed to rest so much.\")\n",
    "\n",
    "tagger.predict(mistbornSentence)\n",
    "\n",
    "print(mistbornSentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [2]: \"Hemalurgy\"   [− Labels: LOC (0.8381)]\n",
      "Span [33]: \"Allomantic\"   [− Labels: MISC (0.8186)]\n",
      "Span [82]: \"Feruchemical\"   [− Labels: MISC (0.9868)]\n",
      "Span [110]: \"Feruchemist\"   [− Labels: MISC (0.7525)]\n",
      "Span [114]: \"Inquisitor\"   [− Labels: ORG (0.4601)]\n",
      "Span [135]: \"Feruchemist\"   [− Labels: MISC (0.9532)]\n",
      "Span [142]: \"Hemalurgic\"   [− Labels: MISC (0.9086)]\n"
     ]
    }
   ],
   "source": [
    "# Not all correct - Hemalurgy is not a location, it is a type of skill. \n",
    "for entity in mistbornSentence.get_spans(\"ner\"):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Multi-Tagging\n",
    "Sometimes you want to predict several types of annotation at once, like NER and POS tags. You can use a `MultiTagger` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:41:12,024 loading file /home/statisticallyfit/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:41:15,589 loading file /home/statisticallyfit/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flair.models.sequence_tagger_model.MultiTagger at 0x7f81548b8fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from flair.models import MultiTagger\n",
    "\n",
    "# load tagger for POS and NER\n",
    "tagger = MultiTagger.load(['pos', 'ner'])\n",
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"In Hemalurgy , the type of metal used in a spike is important , as is the positioning of that spike on the body . For instance , steel spikes take physical Allomantic powers — the ability to burn pewter , tin , steel , or iron — and bestow them upon the person receiving the spike . Which of these four is granted , however , depends on where the spike is placed . Spikes made from other metals steal Feruchemical abilities . For example , all of the original Inquisitors were given a pewter spike , which — after first being pounded through the body of a Feruchemist — gave the Inquisitor the ability to store up healing power . ( Though they could n't do so as quickly as a real Feruchemist , as per the law of Hemalurgic decay . ) This , obviously , is where the Inquisitors got their infamous ability to recover from wounds quickly , and was also why they needed to rest so much .\"   [− Tokens: 174  − Token-Labels: \"In <IN> Hemalurgy <S-LOC/NNP> , <,> the <DT> type <NN> of <IN> metal <NN> used <VBN> in <IN> a <DT> spike <NN> is <VBZ> important <JJ> , <,> as <IN> is <VBZ> the <DT> positioning <NN> of <IN> that <DT> spike <NN> on <IN> the <DT> body <NN> . <,> For <IN> instance <NN> , <,> steel <NN> spikes <NNS> take <VBP> physical <JJ> Allomantic <S-MISC/JJ> powers <NNS> — <``> the <DT> ability <NN> to <TO> burn <VB> pewter <NN> , <,> tin <NN> , <,> steel <NN> , <,> or <CC> iron <NN> — <NN> and <CC> bestow <VB> them <PRP> upon <IN> the <DT> person <NN> receiving <VBG> the <DT> spike <NN> . <,> Which <WDT> of <IN> these <DT> four <CD> is <VBZ> granted <VBN> , <,> however <RB> , <,> depends <VBZ> on <IN> where <WRB> the <DT> spike <NN> is <VBZ> placed <VBN> . <,> Spikes <NNS> made <VBN> from <IN> other <JJ> metals <NNS> steal <VBP> Feruchemical <S-MISC/JJ> abilities <NNS> . <,> For <IN> example <NN> , <,> all <DT> of <IN> the <DT> original <JJ> Inquisitors <NNPS> were <VBD> given <VBN> a <DT> pewter <NN> spike <NN> , <,> which <WDT> — <VBD> after <IN> first <RB> being <VBG> pounded <VBN> through <IN> the <DT> body <NN> of <IN> a <DT> Feruchemist <S-MISC/NNP> — <NN> gave <VBD> the <DT> Inquisitor <S-ORG/NNP> the <DT> ability <NN> to <TO> store <VB> up <RP> healing <NN> power <NN> . <,> ( <,> Though <IN> they <PRP> could <MD> n't <RB> do <VB> so <RB> as <RB> quickly <RB> as <IN> a <DT> real <JJ> Feruchemist <S-MISC/NNP> , <,> as <IN> per <IN> the <DT> law <NN> of <IN> Hemalurgic <S-MISC/NNP> decay <NN> . <.> ) <-RRB-> This <DT> , <,> obviously <RB> , <,> is <VBZ> where <WRB> the <DT> Inquisitors <NNPS> got <VBD> their <PRP$> infamous <JJ> ability <NN> to <TO> recover <VB> from <IN> wounds <NNS> quickly <RB> , <,> and <CC> was <VBD> also <RB> why <WRB> they <PRP> needed <VBD> to <TO> rest <VB> so <RB> much <RB> . <.>\"]\n"
     ]
    }
   ],
   "source": [
    "# Predict sentence with both models\n",
    "tagger.predict(mistbornSentence)\n",
    "print(mistbornSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## [List of Pre-Trained Sequence Tagger Models](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md#list-of-pre-trained-sequence-tagger-models)\n",
    "Can choose which pre-trained model you load by passing appropriate string to the `load()` method of the `SequenceTagger` class. \n",
    "\n",
    "**Example: Chunking**\n",
    "\n",
    "[Meaning of the chunk tags](https://huggingface.co/flair/chunk-english-fast?text=The+happy+man+has+been+eating+at+the+diner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:41:44,020 loading file /home/statisticallyfit/.flair/models/en-chunk-conll2000-fast-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25, inplace=False)\n",
       "        (encoder): Embedding(275, 100)\n",
       "        (rnn): LSTM(100, 1024)\n",
       "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25, inplace=False)\n",
       "        (encoder): Embedding(275, 100)\n",
       "        (rnn): LSTM(100, 1024)\n",
       "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (rnn): LSTM(2048, 256, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkTagger: SequenceTagger = SequenceTagger.load(\"chunk-fast\")\n",
    "chunkTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"When she does n't answer , I fugre there 's no more point in conversation . I steer her toward the kitchens . We 'll have to pass by guards ; there 's no other way out . She has pasted on a horrible rictus of a smile , but at least she has enough self-possession for that . More worrying is the way she ca n't stop staring at things . As we walkt toward the guards , the intensity of her gaze is impossible to disguise . I improvise , trying to sound as though I am reciting a memorized message , without inflection in the words . ' Prince Cardan says we are to attend him . ' One of the guards turns to the other . ' Balekin wo n't like that . ' I try not to react , but it 's hard . I just stand there and wait . If they lunge at us , I am going to have to kill them . ' Very well ,' the first guard says . ' Go . But inform Cardan that his brother demands he brings both of you back this time . '\"   [− Tokens: 200  − Token-Labels: \"When <S-ADVP> she <S-NP> does <B-VP> n't <I-VP> answer <E-VP> , I <S-NP> fugre <S-VP> there <S-NP> 's <S-VP> no <B-NP> more <I-NP> point <E-NP> in <S-PP> conversation <S-NP> . I <S-NP> steer <S-VP> her <S-NP> toward <S-PP> the <B-NP> kitchens <E-NP> . We <S-NP> 'll <B-VP> have <I-VP> to <I-VP> pass <E-VP> by <S-PP> guards <S-NP> ; there <S-NP> 's <S-VP> no <B-NP> other <I-NP> way <E-NP> out <S-PRT> . She <S-NP> has <B-VP> pasted <E-VP> on <S-PP> a <B-NP> horrible <I-NP> rictus <E-NP> of <S-PP> a <B-NP> smile <E-NP> , but at <B-ADVP> least <E-ADVP> she <S-NP> has <S-VP> enough <B-NP> self-possession <E-NP> for <S-PP> that <S-NP> . More <B-ADJP> worrying <E-ADJP> is <S-VP> the <B-NP> way <E-NP> she <S-NP> ca <B-VP> n't <I-VP> stop <I-VP> staring <E-VP> at <S-PP> things <S-NP> . As <S-SBAR> we <S-NP> walkt <S-VP> toward <S-PP> the <B-NP> guards <E-NP> , the <B-NP> intensity <E-NP> of <S-PP> her <B-NP> gaze <E-NP> is <S-VP> impossible <S-ADJP> to <B-VP> disguise <E-VP> . I <S-NP> improvise <S-VP> , trying <B-VP> to <I-VP> sound <E-VP> as <B-SBAR> though <E-SBAR> I <S-NP> am <B-VP> reciting <E-VP> a <B-NP> memorized <I-NP> message <E-NP> , without <S-PP> inflection <S-NP> in <S-PP> the <B-NP> words <E-NP> . ' Prince <B-NP> Cardan <S-PER/E-NP> says <S-VP> we <S-NP> are <B-VP> to <I-VP> attend <E-VP> him <S-NP> . ' One <S-NP> of <S-PP> the <B-NP> guards <E-NP> turns <S-VP> to <S-PP> the <B-NP> other <E-NP> . ' Balekin <S-PER/S-NP> wo <B-VP> n't <I-VP> like <E-VP> that <S-NP> . ' I <S-NP> try <S-VP> not to <B-VP> react <E-VP> , but it <S-NP> 's <S-VP> hard <S-ADJP> . I <S-NP> just <S-ADVP> stand <S-VP> there <S-ADVP> and wait <S-VP> . If <S-SBAR> they <S-NP> lunge <S-VP> at <S-PP> us <S-NP> , I <S-NP> am <B-VP> going <I-VP> to <I-VP> have <I-VP> to <I-VP> kill <E-VP> them <S-NP> . ' Very <B-ADVP> well <E-ADVP> ,' the <B-NP> first <I-NP> guard <E-NP> says <S-VP> . ' Go <S-VP> . But inform <S-VP> Cardan <S-PER/S-NP> that <S-SBAR> his <B-NP> brother <E-NP> demands <S-VP> he <S-NP> brings <S-VP> both <S-NP> of <S-PP> you <S-NP> back <S-ADVP> this <B-NP> time <E-NP> . '\"]\n"
     ]
    }
   ],
   "source": [
    "chunkTagger.predict(folkAirSentence)\n",
    "print(folkAirSentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Experimental: Semantic Frame Detection\n",
    "\n",
    "For English, Flair provides a pre-trained model that detects semantic frames in text using Propbank 3.0 frames. \n",
    "\n",
    "Provides a word sense disambiguation for frame evoking words. \n",
    "\n",
    "### Example 1: George and Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:41:54,480 loading file /home/statisticallyfit/.flair/models/en-frame-ontonotes-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "semanticFrameTagger = SequenceTagger.load('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): BytePairEmbeddings(model=bpe-en-100000-50)\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=5196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semanticFrameTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George returned <return.01> to Berlin to return <return.02> his hat .\n",
      "He had <have.03> a look <look.01> at different hats .\n"
     ]
    }
   ],
   "source": [
    "# Make English sentence\n",
    "s1 = Sentence(\"George returned to Berlin to return his hat.\")\n",
    "s2 = Sentence(\"He had a look at different hats.\")\n",
    "\n",
    "\n",
    "# Predict NER tags  \n",
    "semanticFrameTagger.predict(s1)\n",
    "semanticFrameTagger.predict(s2)\n",
    "\n",
    "# Print sentence with predicted tags\n",
    "print(s1.to_tagged_string())\n",
    "print(s2.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Example 2: Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:42:00,148 loading file /home/statisticallyfit/.flair/models/en-frame-ontonotes-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): BytePairEmbeddings(model=bpe-en-100000-50)\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=5196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "semanticFrameTagger = SequenceTagger.load(\"frame\")\n",
    "semanticFrameTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marie drove <drive.01> the cart through the countryside , admiring <admire.01> the drive <drive.01> of the plodding horses pulling <pull.01> it . She drove <drive.01> a nail through the tarp to protect <protect.01> the lumber from rain . The farmer drove <drive.01> away gophers from his crop . The mayor drove <drive.02> people into poverty with the new tax rules <rule.01> . The storms and tides drove <drive.01> the boats toward shore .\n"
     ]
    }
   ],
   "source": [
    "# Make English sentence\n",
    "#kiwiSentence = Sentence(\"The girl sliced open the furry brown kiwi to reveal a juicy green interior, while the kiwi sang merrily on the branch in the tropical forest where kiwi hung from branches.\")\n",
    "\n",
    "\n",
    "# checkSentence = Sentence(\"Sally left the porcelain on the table before she left to visit her grandmother.\")\n",
    "\n",
    "#sentence = Sentence(\"While Marie drove the cart, she admired the driving ambition of the steady, plodding horses pulling her through the country as the pull of ocean waves tugged her eyes to the store.\")\n",
    "\n",
    "sentence = Sentence(\"Marie drove the cart through the countryside, admiring the drive of the plodding horses pulling it. She drove a nail through the tarp to protect the lumber from rain. The farmer drove away gophers from his crop. The mayor drove people into poverty with the new tax rules. The storms and tides drove the boats toward shore. \")\n",
    "\n",
    "#checkSentence = Sentence(\"The girl checked her arrow before letting it fly, and after watching it whip smoothly into the target, she checked her watch for the time of day, and then remembering an urgent appointment, she hurriedly checked to make sure her equipment was packed away before cashing a check in the bank and leaving to see her friend. \")\n",
    "\n",
    "# Predict NER tags for semantic frames\n",
    "semanticFrameTagger.predict(sentence)\n",
    "\n",
    "# Print sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Example 3: Firing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general fired <fire.01> four gunshot rounds , while the second general fired <fire.01> the lieutenants.Curiosity sparked <spark.01> my imagination <imagine.01> . The flame sparked <spark.01> the bonfire that ravaged <destroy.01> the forest .\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(\"The general fired four gunshot rounds, while the second general fired the lieutenants.Curiosity sparked my imagination. The flame sparked the bonfire that ravaged the forest.\")\n",
    "\n",
    "semanticFrameTagger.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Absorb\n",
    "sentence = Sentence(\"The villagers were absorbed in their own affairs so did not notice how the fortifications were absorbing the floodwaters.\")\n",
    "\n",
    "semanticFrameTagger.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Tagging a List of Sentences\n",
    "Often, you want to tag an entire text corpus. Then you need to split the corpus into sentences and pass a list of `Sentence` objects to the `.predict()` method. \n",
    "\n",
    "For instance, can use the sentence splitter of segtok: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flair.models import SequenceTagger\n",
    "#from flair.tokenization import SegtokSentenceSplitter\n",
    "\n",
    "# Example 5: Text (\"Fell\") with many sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:42:11,569 loading file /home/statisticallyfit/.flair/models/en-frame-ontonotes-v0.4.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rock fell <fall.01> through the air .\n",
      "The responsibility fell <fall.01> on his shoulders to protect <protect.01> the herd from the thunderstorm .\n",
      "Multiple animals fell <fall.01> into order to evade <deter.01> lightning strikes <strike.01> .\n"
     ]
    }
   ],
   "source": [
    "text: str = \"The rock fell through the air. The responsibility fell on his shoulders to protect the herd from the thunderstorm. Multiple animals fell into order to evade lightning strikes.\"\n",
    "\n",
    "# initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "# Use splitter to split text into multiple (list) of sentences\n",
    "sentences = splitter.split(text)\n",
    "\n",
    "# Predict tags for sentences\n",
    "tagger = SequenceTagger.load(\"frame\")\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# Iterate through sentences and print predicted labels\n",
    "for sentence in sentences: \n",
    "    print(sentence.to_tagged_string())\n",
    "\n",
    "# TODO HELP: why doesn't this Frame model differentiate the different senses of the word \"fell\"?\n",
    "# 1) \"fell\" as in object falling through the air\n",
    "# 2) \"fell\" as in an intangible weight being laid on someone.\n",
    "# 3) \"fell\" as in organize themselves in line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Tagging with Pre-Trained Text Classification Models\n",
    "Using pre-trained mdoel for detecting positive or negative comments. This model is trained over a mix of product and movie review datasets and can recognize positive and negative sentiment in english text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-01 21:42:19,183 loading file /home/statisticallyfit/.flair/models/sentiment-en-mix-distillbert.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (document_embeddings): TransformerDocumentEmbeddings(\n",
       "    (model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "# load tagger\n",
    "classifier = TextClassifier.load(\"sentiment\")\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "All required is to use `predict()` method of the classifier on a sentence. This adds the predicted label to the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"enormously entertaining for moviegoers of any age\"   [− Tokens: 7  − Sentence-Labels: {'label': [POSITIVE (0.9979)]}]\n"
     ]
    }
   ],
   "source": [
    "# Predict for example sentence\n",
    "sentence = Sentence(\"enormously entertaining for moviegoers of any age\")\n",
    "classifier.predict(sentence)\n",
    "\n",
    "# check prediction\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"A real critical thinker of this day and age ; offers deeper insights than any other film about the sad , horrifying state of humanity today\"   [− Tokens: 26  − Sentence-Labels: {'label': [POSITIVE (0.9999)]}]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(\"A real critical thinker of this day and age; offers deeper insights than any other film about the sad, horrifying state of humanity today\")\n",
    "\n",
    "classifier.predict(sentence)\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Communicative Functions Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "# TODO doesn't work now\n",
    "#functionsClassifier = TextClassifier.load('communicative-functions')\n",
    "#functionsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all"
  },
  "kernelspec": {
   "display_name": "pynlp_clone_env",
   "language": "python",
   "name": "pynlp_clone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
